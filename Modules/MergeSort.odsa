<div id="content">
<ODSAtitle>Mergesort</ODSAtitle>
<ODSAprereq "Sorting" />
<ODSAprereq "ExchangeSort" />

<p>
A natural approach to problem solving is divide and conquer.
In terms of sorting, we might consider breaking the list to be sorted
into pieces, process the pieces, and then put them back together
somehow.
A simple way to do this would be to split the list in half, sort
the halves, and then merge the sorted halves together.
This is the idea behind <ODSAdef>Mergesort</ODSAdef>.
</p>

<p>
Mergesort is one of the simplest sorting algorithms conceptually,
and has good performance both in the asymptotic 
sense and in empirical running time.
Surprisingly, even though it is based on a simple concept,
it is relatively difficult to implement in practice.
Figure <ODSAref "MergeFig" \> illustrates Mergesort.
A pseudocode sketch of Mergesort is as follows:
<p>

<pre>
List mergesort(List inlist) {
  if (inlist.length() <= 1) return inlist;;
  List L1 = half of the items from inlist;
  List L2 = other half of the items from inlist;
  return merge(mergesort(L1), mergesort(L2));
}
</pre>

<figure>
<center>
<img src="Images/MrgSort.png" width=600 alt="Mergesort" />
<br/>
</center>

<figcaption>
<ODSAfig "MergeFig" />
An illustration of Mergesort.
The first row shows eight numbers that are to be sorted.
Mergesort will recursively subdivide the list into
sublists of one element each, then recombine the sublists.
The second row shows the four sublists of size 2 created by the
first merging pass.
The third row shows the two sublists of size 4 created by the next
merging pass on the sublists of row 2.
The last row shows the final sorted list created by merging the two
sublists of row 3.
</figcaption>
</figure>

<p>
Before discussing how to implement Mergesort, we will first examine
the merge function.
Merging two sorted sublists is quite simple.
Function <code>merge</code> examines the first element of each
sublist and picks the smaller value as the smallest element overall.
This smaller value is removed from its sublist and placed into the
output list.
Merging continues in this way, comparing the front
elements of the sublists and continually appending the smaller to the
output list until no more input elements remain.
</p>

<center>
 <iframe src="../AV/mergesort-av.html"
	 type="text/javascript" width="825" height="670"
	 frameborder="0" marginwidth="0" marginheight="0"
	 scrolling="no" style="overflow-y: auto">
</iframe>
</center>

<p>
Implementing Mergesort presents a number of technical difficulties.
The first decision is how to represent the lists.
Mergesort lends itself well to sorting a singly linked list because
merging does not require random access to the list elements.
Thus, Mergesort is the method of choice when the input is in the form
of a linked list.
Implementing <code>merge</code> for linked lists is straightforward,
because we need only remove items from the front of the input lists
and append items to the output list.
Breaking the input list into two equal halves presents some
difficulty.
Ideally we would just break the lists into front and back halves.
However, even if we know the length of the list in advance, it would
still be necessary to traverse halfway down the linked list to reach
the beginning of the second half.
A simpler method, which does not rely on knowing the length of the
list in advance, assigns elements of the input list alternating
between the two sublists.
The first element is assigned to the first sublist, the
second element to the second sublist, the third to first sublist, the
fourth to the second sublist, and so on.
This requires one complete pass through the input list to build the
sublists.
</p>

<p>
When the input to Mergesort is an array, splitting input into two
subarrays is easy if we know the array bounds.
Merging is also easy if we merge the subarrays into a second array.
Note that this approach requires twice the amount of space as any of
the sorting methods presented so far, which is a serious disadvantage
for Mergesort.
It is possible to merge the subarrays without using a second array,
but this is extremely difficult to do efficiently and is
not really practical.
Merging the two subarrays into a second array, while
simple to implement, presents another difficulty.
The merge process ends with the sorted list in the auxiliary array.
Consider how the recursive nature of Mergesort breaks
the original array into subarrays, as shown in
Figure <ODSAref "MergeFig" \>.
Mergesort is recursively called until subarrays of size 1 have been
created, requiring log <i>n</i> levels of recursion.
These subarrays are merged into subarrays of size 2, which are in
turn merged into subarrays of size 4, and so on.
We need to avoid having each merge operation
require a new array.
With some difficulty, an algorithm can be
devised that alternates between two arrays.  A much simpler approach
is to copy the sorted sublists to the auxiliary array first, and then
merge them back to the original array.
Figure <ODSAref "Mergesortbasic" \> is a complete implementation for
mergesort following this approach.

<figure>
<pre>
static &lt;E extends Comparable&lt;? super E>>
void mergesort(E[] A, E[] temp, int l, int r) {
  int mid = (l+r)/2;                // Select midpoint
  if (l == r) return;               // List has one element
  mergesort(A, temp, l, mid);   // Mergesort first half
  mergesort(A, temp, mid+1, r); // Mergesort second half
  for (int i=l; i&lt;=r; i++)          // Copy subarray to temp
    temp[i] = A[i];
  // Do the merge operation back to A
  int i1 = l; int i2 = mid + 1;
  for (int curr=l; curr&lt;=r; curr++) {
    if (i1 == mid+1)              // Left sublist exhausted
      A[curr] = temp[i2++];
    else if (i2 > r)              // Right sublist exhausted
      A[curr] = temp[i1++];
    else if (temp[i1].compareTo(temp[i2])&lt;0) // Get smaller
      A[curr] = temp[i1++];
    else A[curr] = temp[i2++];
  }
}
</pre>

<figcaption>
<ODSAfig "MergsortBasic" />
Standard implementation for Mergesort.
</figcaption>
</figure.

<p>
An optimized Mergesort implementation is shown in
Figure <ODSAref "MergsortOpt" \>.
It reverses the order of the second subarray during the initial copy.
Now the current positions of the two subarrays work inwards from the
ends, allowing the end of each subarray to act as a sentinel for the
other.
Unlike the previous implementation, no test is needed to check for
when one of the two subarrays becomes empty.
This version also uses Insertion Sort to sort small subarrays.
</p>

<figure>
<pre>
static &lt;E extends Comparable&lt;? super E>>
void mergesort(E[] A, E[] temp, int l, int r) {
  int i, j, k, mid = (l+r)/2;  // Select the midpoint
  if (l == r) return;          // List has one element
  if ((mid-l) >= THRESHOLD) mergesort(A, temp, l, mid);
  else inssort(A, l, mid-l+1);
  if ((r-mid) > THRESHOLD) mergesort(A, temp, mid+1, r);
  else inssort(A, mid+1, r-mid);
  // Do the merge operation.  First, copy 2 halves to temp.
  for (i=l; i<=mid; i++) temp[i] = A[i];
  for (j=1; j<=r-mid; j++) temp[r-j+1] = A[j+mid];
  // Merge sublists back to array
  for (i=l,j=r,k=l; k<=r; k++)
    if (temp[i].compareTo(temp[j])<0) A[k] = temp[i++];
    else A[k] = temp[j--];
}
</pre>

<figcaption>
<ODSAfig "MergsortOpt" />
Optimized implementation for Mergesort.
</figcaption>
</figure>

<p>
Analysis of Mergesort is straightforward, despite the fact that it is
a recursive
The merging part takes time &Theta;(<i>i</i>) where <i>i</i>
is the total length of the two subarrays being merged.
The array to be sorted is repeatedly split in half until subarrays of
size 1 are reached, at which time they are merged to be of size 2,
these merged to subarrays of size 4, and so on as shown in
Figure <ODSAref "MergeFig" />.
Thus, the depth of the recursion is log <i>n</i> for <i>n</i> elements
(assume for simplicity that <i>n</i> is a power of two).
The first level of recursion can be thought of as working on one array
of size <i>n</i>, the next level working on two arrays of size
<i>n</i>/2, the next on four arrays of size <i>n</i>/4, and so on.
The bottom of the recursion has <i>n</i> arrays of size 1.
Thus, <i>n</i> arrays of size 1 are merged (requiring
&Theta;(<i>n</i>) total steps), <i>n</i>/2 arrays of size 2
(again requiring &Theta;(n) total steps), <i>n</i>/4 arrays of size 4,
and so on.
At each of the log <i>n</i> levels of recursion, &Theta;(<i>n</i>)
work is done, for a total cost of &Theta;(<i>n</i> log <i>n</i>).
This cost is unaffected by the relative order of the
values being sorted, thus this analysis holds for the best, average,
and worst cases.
</p>

</div>
