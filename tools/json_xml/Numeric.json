{"document": {"@ids": "number-problems", "@names": "number\\ problems", "@source": "<string>", "@title": "Number Problems", "title": "Number Problems", "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2013 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": {"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, "section": [{"@ids": "introduction", "@names": "introduction", "title": "Introduction", "paragraph": ["This moudle presents a variety of algorithms related to mathematical\ncomputations on numbers.\nExamples are activities like multiplying two numbers or raising a\nnumber to a given power.\nIn particular, we are concerned with situations where built-in integer\nor floating-point operations cannot be used because the values being\noperated on are too large.\nSimilar concerns arise for operations on polynomials or matrices.", {"math": ["n \\times m", "m", "n"], "#text": "Since we cannot rely on the hardware to process the inputs in a single\nconstant-time operation, we are concerned with how to most effectively\nimplement the operation to minimize the time cost.\nThis begs a question as to how we should apply our normal measures of\nasymptotic cost in terms of growth rates on input size.\nFirst, what is an instance of addition or multiplication?\nEach value of the operands yields a different problem instance.\nAnd what is the input size when multiplying two numbers?\nIf we view the input size as two (since two numbers are input),\nthen any non-constant-time algorithm has a growth rate that is\ninfinitely high compared to the growth of the input.\nThis makes no sense, especially in light of the fact that we know from\ngrade school arithmetic that adding or multiplying numbers does seem\nto get more difficult as the value of the numbers involved increases.\nIn fact, we know from standard grade school algorithms that the cost\nof\nstandard addition is linear on the number of digits being added, and\nmultiplication has cost  when multiplying an\n -digit\nnumber by an  -digit number."}, "The number of digits for the operands does appear to be a key\nconsideration when we are performing a numeric algorithm that is\nsensitive to input size.\nThe number of digits is simply the log of the value, for a suitable\nbase of the log.\nThus, for the purpose of calculating asymptotic growth rates of\nalgorithms, we will consider the \"size\" of an input value to be the\nlog of that value.\nGiven this view, there are a number of features that seem to relate\nsuch operations."], "bullet_list": {"@bullet": "*", "list_item": [{"paragraph": "Arithmetic operations on large values are not cheap."}, {"paragraph": "There is only one instance of value $n$."}, {"paragraph": {"math": ["2^k", "k"], "#text": "There are  instances of length  or less."}}, {"paragraph": {"math": ["n", "\\log n"], "#text": "The size (length) of value  is ."}}, {"paragraph": {"math": ["n", "2^k-1", "2^k", "2^k+1", "n"], "#text": "The cost of a particular algorithm can decrease when \nincreases in value (say when going from a value of \nto  to ),\nbut generally increases when  increases in length."}}]}}, {"@ids": "exponentiation", "@names": "exponentiation", "title": "Exponentiation", "paragraph": [{"math": ["m^n", "m", "n-1", "n", "m^n = m^{n/2}m^{n/2}", "n", "m^n = m^{\\lfloor n/2\\rfloor}m^{\\lfloor n/2\\rfloor}m"], "#text": "We will start our examination of standard numerical algorithms by\nconsidering how to perform exponentiation.\nThat is, how do we compute ?\nWe could multiply by  a total of  times.\nCan we do better?\nYes, there is a simple divide and conquer approach that we can use.\nWe can recognize that, when  is even,\n.\nIf  is odd, then\n.\nThis leads to the following recursive algorithm:"}, {"title_reference": "Power", "#text": "Function  has recurrence relation"}, "This has solution", {"math": ["\\beta", "n"], "#text": "where  is the number of 1's in the binary\nrepresentation of ."}, {"math": ["\\log m + \\log n", "\\log n", "n-1"], "#text": "How does this cost compare with the problem size?\nThe original problem size is ,\nand the number of multiplications required is .\nThis is far better (in fact, exponentially better) than performing\n multiplications."}], "literal_block": {"@xml:space": "preserve", "#text": "int Power(int base, int exp) {\n  int half, total;\n  if exp = 0 return 1;\n  half = Power(base, exp/2);\n  total = half * half;\n  if (odd(exp)) then total = total * base;\n  return total;\n}"}, "math_block": [{"@xml:space": "preserve", "#text": "f(n) = \\left\\{\n\\begin{array}{ll}\n0&n=1\\\\\nf(\\lfloor n/2\\rfloor) + 1 + n \\bmod 2&n>1\n\\end{array}\n\\right."}, {"@xml:space": "preserve", "#text": "f(n) = \\lfloor \\log n\\rfloor + \\beta(n) - 1"}]}, {"@ids": "largest-common-factor", "@names": "largest\\ common\\ factor", "title": "Largest Common Factor", "paragraph": ["We will next present Euclid's algorithm for finding the largest common\nfactor (LCF) for two integers.\nThe LCF is the largest integer that divides both inputs evenly.", {"math": ["k", "n", "m", "k", "n - m", "k", "n", "n = ak", "a", "k", "m", "m = bk", "b", "LCF(n, m) = LCF(n-m, n) = LCF(m, n-m) = LCF(m, n)"], "#text": "First we make this observation: If  divides  and\n, then  divides .\nWe know this is true because if  divides  then\n for some integer , and if  divides\n then  for some integer .\nSo, ."}, {"math": ["n", "k", "l"], "#text": "Now, for any value  there exists  and  such\nthat"}, {"math": "\\bmod", "#text": "From the definition of the  function, we can derive\nthe fact that"}, {"math": ["n", "m", "n = km + l", "km", "l", "LCF(n, m) = LCF(m, l) = LCF(m, n \\bmod m)"], "#text": "Since the LCF is a factor of both  and ,\nand since , the LCF must therefore be a factor of both\n and  , and also the largest common factor of each\nof these terms.\nAs a consequence, ."}, {"math": ["n \\geq m", "n", "m", "m", "n \\bmod m", "m"], "#text": "This observation leads to a simple algorithm.\nWe will assume that .\nAt each iteration we replace  with  and\n with  until we have driven  to\nzero:"}, {"math": ["n", "n \\bmod m", "n \\bmod m", "n"], "#text": "To determine how expensive this algorithm is, we need to know how much\nprogress we are making at each step.\nNote that after two iterations, we have replaced\n with .\nSo the key question becomes:\nHow big is  relative to ?"}, {"math": "O(\\log n)", "#text": "Thus, function LCF will halve its first parameter in no more than 2\niterations.\nThe total cost is then ."}], "math_block": [{"@xml:space": "preserve", "#text": "n = km + l\\ \\mbox{where}\\ m > l \\geq 0."}, {"@xml:space": "preserve", "#text": "n = \\lfloor n/m \\rfloor m + n \\bmod m."}, {"@xml:space": "preserve", "#text": "\\begin{eqnarray*}\nn \\geq m &\\Rightarrow& n/m \\geq 1\\\\\n&\\Rightarrow& 2\\lfloor n/m\\rfloor > n/m\\\\\n&\\Rightarrow& m\\lfloor n/m\\rfloor > n/2\\\\\n&\\Rightarrow& n - n/2 > n - m\\lfloor n/m\\rfloor = n \\bmod m\\\\\n&\\Rightarrow& n/2 > n \\bmod m\n\\end{eqnarray*}"}], "literal_block": {"@xml:space": "preserve", "#text": "int LCF(int n, int m) {\n  if (m == 0) return n;\n  return LCF(m, n % m);\n}"}}]}}