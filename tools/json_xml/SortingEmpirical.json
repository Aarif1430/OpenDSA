{"document": {"@dupnames": "an\\ empirical\\ comparison\\ of\\ sorting\\ algorithms", "@ids": "an-empirical-comparison-of-sorting-algorithms", "@source": "<string>", "@title": "An Empirical Comparison of Sorting Algorithms", "title": "An Empirical Comparison of Sorting Algorithms", "subtitle": {"@dupnames": "an\\ empirical\\ comparison\\ of\\ sorting\\ algorithms", "@ids": "id1", "#text": "An Empirical Comparison of Sorting Algorithms"}, "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@xml:space": "preserve", "index": "null"}, {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "ka", "@exer_name": "SortAlgCompSumm", "@long_name": "SortAlgCompSumm", "@points": "1.0", "@required": "True", "@threshold": "5"}}], "paragraph": [{"title_reference": ["Theta(n^2)", "Theta(n log n)"], "#text": "Which sorting algorithm is fastest?  Asymptotic complexity analysis\nlets us distinguish between  and\n algorithms, but it does not help distinguish\nbetween algorithms with the same asymptotic complexity.\nNor does asymptotic analysis say anything about which algorithm is\nbest for sorting small lists.\nFor answers to these questions, we can turn to empirical testing."}, {"title_reference": ["#SortCompTable", "Insertion Sort <insertion sort> <InsertionSort>", "Bubble Sort <bubble sort> <BubbleSort>", "Selection Sort <selection sort> <SelectionSort>", "Shellsort <Shellsort> <Shellsort>", "Quicksort <Quicksort> <Quicksort>", "Mergesort <Mergesort> <Mergesort>", "Heapsort <Heapsort> <Heapsort>", "Radix Sort <radix sort> <Radixsort>"], "#text": "Table  shows timing results for\nactual implementations of the sorting algorithms presented in this\nchapter.\nThe algorithms compared include\n,\n,\n,\n,\n,\n,\n,\n."}, "Shellsort compares times for both the basic version and a version with\nincrements based on division by three.\nMergesort compares both the basic array-based implementation and an\noptimized version (which includes calls to Insertion Sort for lists of\nlength below nine).\nFor Quicksort, two versions are compared: the basic implementation\nand an optimized version that does not partition sublists below length\nnine (with Insertion Sort performed at the end).\nThe first Heapsort version uses a standard class definition with\nmethods to implement access functions like \"parent\".\nThe second version removes all the method definitions and operates\ndirectly on the array using inlined code for all access functions.", "Except for the rightmost columns,\nthe input to each algorithm is a random array of integers.\nThis affects the timing for some of the sorting algorithms.\nFor example, Selection Sort is not being used to best advantage\nbecause the record size is small, so it does not get the best possible\nshowing.\nThe Radix Sort implementation certainly takes advantage of this\nkey range in that it does not look at more digits than necessary.\nOn the other hand, it was not optimized to use bit shifting instead of\ndivision, even though the bases used would permit this.", "The various sorting algorithms are shown for lists of sizes\n10, 100, 1000, 10,000, 100,000, and 1,000,000.\nThe final two columns of each table show the performance for the\nalgorithms on inputs of size 10,000 where the numbers are in\nascending (sorted) and descending (reverse sorted) order,\nrespectively.\nThese columns demonstrate best-case performance for some\nalgorithms and worst-case performance for others.\nThey also show that for some algorithms, the order of input\nhas little effect.", {"title_reference": ["O(n^2)", "O(n^2)", "O(n log n)"], "#text": "These figures show a number of interesting results.\nAs expected, the  sorts are quite poor performers for\nlarge arrays.\nInsertion Sort is by far the best of this group, unless the array is\nalready reverse sorted.\nShellsort is clearly superior to any of these  sorts for\nlists of even 100 records.\nOptimized Quicksort is clearly the best overall algorithm for all but\nlists of 10 records.\nEven for small arrays, optimized Quicksort performs well because\nit does one partition step before calling Insertion Sort.\nCompared to the other  sorts, unoptimized Heapsort\nis quite slow due to the overhead of the class structure.\nWhen all of this is stripped away and the algorithm is implemented to\nmanipulate an array directly, it is still somewhat slower than\nmergesort.\nIn general, optimizing the various algorithms makes a\nnoticeable improvement for larger array sizes."}, "Overall, Radix Sort is a surprisingly poor performer.\nIf the code had been tuned to use bit shifting of the key value, it\nwould likely improve substantially;\nbut this would seriously limit the range of record types that the\nsort could support.", "Here are a few multiple choice questions that ask you to\ncompare the sorting algorithms that we learned about in this chapter."], "target": {"@refid": "sortcomptable"}, "topic": {"@ids": "sortcomptable", "@names": "sortcomptable", "title": "Table", "paragraph": "Empirical comparison of sorting algorithms run on a 3.4 GHz Intel\nPentium 4 CPU running Linux.\nAll times shown are milliseconds.", "math_block": {"@xml:space": "preserve", "#text": "\\begin{array}{l|rrrrrrrr}\n\\hline\n\\textbf{Sort} & \\textbf{10}& \\textbf{100} & \\textbf{1K}&\n\\textbf{10K} & \\textbf{100K}& \\textbf{1M}& \\textbf{Up} & \\textbf{Down}\\\\\n\\hline\n\\textrm{Insertion} & .00023 & .007 & 0.66 &  64.98 &  7381.0 &  674420 & 0.04 & 129.05\\\\\n\\textrm{Bubble}    & .00035 & .020 & 2.25 & 277.94 & 27691.0 & 2820680 &  70.64 & 108.69\\\\\n\\textrm{Selection} & .00039 & .012 & 0.69 &  72.47 &  7356.0 &  780000 &  69.76 &  69.58\\\\\n\\textrm{Shell}     & .00034 & .008 & 0.14 &   1.99 &    30.2 &     554 &   0.44 &   0.79\\\\\n\\textrm{Shell/O}   & .00034 & .008 & 0.12 &   1.91 &    29.0 &     530 &   0.36 &   0.64\\\\\n\\textrm{Merge}     & .00050 & .010 & 0.12 &   1.61 &    19.3 &     219 &   0.83 &   0.79\\\\\n\\textrm{Merge/O}   & .00024 & .007 & 0.10 &   1.31 &    17.2 &     197 &   0.47 &   0.66\\\\\n\\textrm{Quick}     & .00048 & .008 & 0.11 &   1.37 &    15.7 &     162 &   0.37 &   0.40\\\\\n\\textrm{Quick/O}   & .00031 & .006 & 0.09 &   1.14 &    13.6 &     143 &   0.32 &   0.36\\\\\n\\textrm{Heap}      & .00050 & .011 & 0.16 &   2.08 &    26.7 &     391 &   1.57 &   1.56\\\\\n\\textrm{Heap/O}    & .00033 & .007 & 0.11 &   1.61 &    20.8 &     334 &   1.01 &   1.04\\\\\n\\textrm{Radix/4}   & .00838 & .081 & 0.79 &   7.99 &    79.9 &     808 &   7.97 &   7.97\\\\\n\\textrm{Radix/8}   & .00799 & .044 & 0.40 &   3.99 &    40.0 &     404 &   4.00 &   3.99\\\\\n\\hline\n\\end{array}"}}}}