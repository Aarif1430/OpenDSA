{"document": {"@dupnames": "growth\\ rates\\ review", "@ids": "growth-rates-review", "@source": "<string>", "@title": "Growth Rates Review", "title": "Growth Rates Review", "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": {"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, "section": [{"@dupnames": "growth\\ rates\\ review", "@ids": "id1", "title": "Growth Rates Review", "paragraph": [{"math": ["n", "n"], "title_reference": "growth rates <growth rate>", "#text": "Two functions of  have different\n if as  goes to infinity\ntheir ratio either goes to infinity or goes to zero."}, {"math": "(1.618)^n", "#text": "Where does  go on here?"}, "Exact equations relating program operations to running time require\nmachine-dependent constants.\nSometimes, the equation for exact running time is complicated to\ncompute.\nUsually, we are satisfied with knowing an approximate growth rate.", {"math": ["c_1n", "c_2 2^{n!}", "c_1", "c_2"], "#text": "Example: Given two algorithms with growth rate  and\n, do we need to know the values of \nand ?"}, {"math": ["n^2", "3n", "n^2"], "#text": "Consider  and .\nPROVE that  must eventually become (and remain) bigger."}, {"math": ["r", "s", "n", "n^2 < rn + s", "n < r + s/n", "n", "s/n"], "#text": "Proof by Contradiction:\nAssume there are some values for constants  and \nsuch that, for all values of ,\n.\nThen, .\nBut, as  grows, what happens to ?\nIt goes to zero."}, {"math": ["n", "n \\rightarrow \\infty"], "#text": "Since  grows toward infinity, the assumption must be false.\nConclusion: In the limit, as , constants\ndon't matter.\nLimits are the typical way to prove that one function grows faster\nthan another."}, "Here are some useful observatios.", {"math": ["n^2", "n"], "#text": "Since  grows faster than ,"}, {"math": ["n!", "2^n"], "#text": "Since  grows faster than ,"}, {"math": ["f", "g", "\\sqrt{f}", "\\sqrt{g}"], "#text": "If  grows faster than , then\nmust  grow faster than ?\nYes."}, {"math": ["\\log f", "\\log g", "\\log n \\approx \\log n^2"], "strong": "rate", "#text": "Must  grow faster than ?\nNo.\n within a constant factor, that is, the\ngrowth  is the same!"}, {"math": ["\\log n", "n", "n", "2^n"], "#text": "is related to  in exactly the same way that\n is related to ."}, {"math": "2^{\\log n} = n", "#text": "."}], "target": {"@refid": "runtimegraph"}, "raw": {"@format": "xml", "@ids": "runtimegraph", "@names": "runtimegraph", "@xml:space": "preserve", "odsafig": "null"}, "bullet_list": [{"@bullet": "*", "list_item": [{"paragraph": {"math": ["2^{n^2}", "2^n"], "#text": "grows faster than .\n(Take antilog of both sides.)"}}, {"paragraph": {"math": ["n^4", "n^2"], "#text": "grows faster than .\n(Square boths sides.)"}}, {"paragraph": {"math": ["n", "\\sqrt{n}", "n = (\\sqrt{n})^2", "n", "\\sqrt{n}"], "#text": "grows faster than .\n(.\nReplace  with .)"}}, {"paragraph": {"math": ["2 \\log n", "\\log n", "\\log"], "emphasis": "no slower", "#text": "grows  than .\n(Take  of both sides. Log \"flattens\" growth rates.)"}}]}, {"@bullet": "*", "list_item": [{"paragraph": {"math": ["n!!", "2^n!"], "#text": "grows faster than .\n(Apply factorial to both sides.)"}}, {"paragraph": {"math": ["2^{n!}", "2^{2^n}"], "#text": "grows faster than .\n(Take antilog of both sides.)"}}, {"paragraph": {"math": ["n!^2", "2^{2n}"], "#text": "grows faster than .\n(Square both sides.)"}}, {"paragraph": {"math": ["\\sqrt{n!}", "\\sqrt{2^n}"], "#text": "grows faster than .\n(Take square root of both sides.)"}}, {"paragraph": {"math": ["\\log n!", "n", "\\log n! = \\Theta(n \\log n)"], "emphasis": "no slower", "#text": "grows  than .\n(Take log of both sides.\nActually, it grows faster since .)"}}]}]}, {"@ids": "asymptotic-notation", "@names": "asymptotic\\ notation", "title": "Asymptotic Notation", "math_block": {"@xml:space": "preserve", "#text": "\\begin{array}{llcl}\n\\mathrm{little\\ oh}&f(n) \\in o(g(n))&<&\\lim f(n)/g(n) = 0\\\\\n\\mathrm{big\\ oh}&f(n) \\in O(g(n))&\\leq\\\\\n\\mathrm{Theta}&f(n) = \\Theta(g(n))&=&f=O(g) and\\\\\n&&& g=O(f)\\\\\n\\mathrm{Big\\ Omega}&f(n) \\in \\Omega(g(n))&\\geq\\\\\n\\mathrm{Little Omega}&f(n) \\in \\omega(g(n))&>&\\lim g(n)/f(n) = 0\n\\end{array}"}, "paragraph": [{"math": ["f \\in O(n^2)", "f = O(n^2)", "n \\in O(n^2)", "n^2 \\in O(n^2)", "O(n) \\neq O(n^2)"], "#text": "I prefer \"\" to \"\"\nWhile  and ,\n."}, {"strong": "can", "#text": "Note: Big oh does not say how good an algorithm is\nonly how bad it  be."}, {"math": ["\\mathcal{A}\\in O(n)", "\\mathcal{B} \\in O(n^2)", "\\mathcal{A}", "\\mathcal{B}", "\\mathcal{A} = \\Theta(n)", "\\mathcal{B} = \\Theta(\\log n)"], "#text": "If  and ,\nis  better than ?\nPerhaps... but perhaps better analysis will show that\n while\n."}, {"math": ["\\log n^2 (= 2 \\log n)", "\\log^2 n (= (\\log n)^2)", "\\log \\log n"], "#text": "Order Notation has practical limits.\nNotation:  vs.\n\nvs. ."}, {"math": "\\log 16^2 = 2 \\log 16 = 8", "#text": "."}, {"math": "\\log^2 16 = 4^2 = 16", "#text": "."}, {"math": "\\log \\log 16 = \\log 4 = 2", "#text": "."}, {"math": ["\\mathcal{A}", "\\mathcal{B}"], "#text": "Statement: Resource requirements for Algorithm \ngrow slower than resource requirements for Algorithm ."}, {"math": ["\\mathcal{A}", "\\mathcal{B}"], "#text": "Is  better than ?"}, "Potential problems:", "It is not always practical to reduce an algorithm's growth rate\n\"Practical\" here means that the constants might become too\nmuch higher when we shave off the minor asymptotic growth.", {"math": ["n", "\\log \\log n"], "#text": "Shaving a factor of  reduces cost by a factor of a million\nfor input size of a million.\nShaving a factor of  saves only a factor of 4-5."}, {"strong": ["model", "usually", "useful"], "#text": "There is the concept of a \"Practicality Window\".\nIn general, (1) we have limited time to solve a problem,\nand (2) input can only get so big before the computer chokes.\nFortunately, algorithm growth rates are USUALLY well behaved, so that\nOrder Notation gives practical indications.\n\"Practical\" is the keyword.\nWe use asymptotics because they provide a simple  that\n mirrors reality.\nThis is  to simplify our thinking."}], "bullet_list": {"@bullet": "*", "list_item": [{"paragraph": "How big must the input be?"}, {"paragraph": {"math": ["\\Theta(\\log^2 n)", "\\Theta(n^{1/10})", "n", "10^{12} (\\approx 2^{40})", "\\log^2 n \\approx 1600", "n^{1/10} = 16", "n^{1/10}", "\\log^2 n", "n", "2^{150}", "n^{1/10}", "\\log^2 n"], "#text": "Some growth rate differences are trivial\nExample:  vs. .\nIf  is  then\n,  even though\n grows faster than .\n must be enormous (like ) for\n to be bigger than ."}}]}}]}}