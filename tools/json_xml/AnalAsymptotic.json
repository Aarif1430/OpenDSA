{"document": {"@dupnames": "asymptotic\\ analysis\\ and\\ upper\\ bounds", "@ids": "asymptotic-analysis-and-upper-bounds", "@source": "<string>", "@title": "Asymptotic Analysis and Upper Bounds", "title": "Asymptotic Analysis and Upper Bounds", "subtitle": {"@dupnames": "asymptotic\\ analysis\\ and\\ upper\\ bounds", "@ids": "id1", "#text": "Asymptotic Analysis and Upper Bounds"}, "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@xml:space": "preserve", "odsalink": "AV/AlgAnal/UpperBoundCON.css"}, {"@format": "xml", "@ids": "runtimegraph2", "@names": "runtimegraph2", "@xml:space": "preserve", "odsafig": "null"}], "target": {"@refid": "runtimegraph2"}, "paragraph": [{"title_reference": ["10 n", "2 n^2", "n = 5", "20 n", "2 n^2", "n = 10", "growth rate", "x"], "emphasis": ["where", "whether"], "#text": "Despite the larger constant for the curve labeled  in\nthe figure above,  crosses it at the\nrelatively small value of .\nWhat if we double the value of the constant in front of the linear\nequation?\nAs shown in the graph,  is surpassed by \nonce .\nThe additional factor of two for the linear  does\nnot much matter.\nIt only doubles the -coordinate for the intersection point.\nIn general, changes to a constant factor in either equation only\nshift  the two curves cross, not \nthe two curves cross."}, {"title_reference": "asymptotic algorithm analysis", "#text": "When you buy a faster computer or a faster compiler,\nthe new problem size that can be run in a given amount of time for a\ngiven growth rate is\nlarger by the same factor, regardless of the constant on the\nrunning-time equation.\nThe time curves for two algorithms with different growth rates\nstill cross, regardless of their running-time equation constants.\nFor these reasons, we usually ignore the constants when we want an\nestimate of the growth rate for the running time or other resource\nrequirements of an algorithm.\nThis simplifies the analysis and keeps us thinking about the most\nimportant aspect: the growth rate.\nThis is called .\nTo be precise, asymptotic analysis refers to the study of an\nalgorithm as the input size \"gets big\" or reaches\na limit (in the calculus sense).\nHowever, it has proved to be so useful to ignore all constant factors\nthat asymptotic analysis is used for most algorithm comparisons."}, {"title_reference": ["n", "estimation <estimation> <Estimation>"], "#text": "In rare situations, it is not reasonable to ignore the constants.\nWhen comparing algorithms meant to run on small values of ,\nthe constant can have a large effect.\nFor example, if the problem requires you to sort many collections of\nexactly five records, then a sorting algorithm designed for sorting\nthousands of records is probably not appropriate, even if its\nasymptotic analysis indicates good performance.\nThere are rare cases where the constants for two algorithms under\ncomparison can differ by a factor of 1000 or more, making the one\nwith lower growth rate impractical for typical problem sizes due to\nits large constant.\nAsymptotic analysis is a form of \"back of the envelope\"\n for algorithm resource\nconsumption.\nIt provides a simplified model of the running time or\nother resource needs of an algorithm.\nThis simplification usually helps you understand the behavior of your\nalgorithms.\nJust be aware of the limitations to asymptotic analysis in the\nrare situation where the constant is important."}], "section": [{"@ids": "upper-bounds", "@names": "upper\\ bounds", "title": "Upper Bounds", "paragraph": [{"title_reference": "upper bound", "#text": "Several terms are used to describe the running-time equation for an\nalgorithm.\nThese terms  and their associated symbols  indicate\nprecisely what aspect of the algorithm's behavior is being described.\nOne is the  for the growth of the algorithm's\nrunning time.\nIt indicates the upper or highest growth rate that\nthe algorithm can have."}, {"title_reference": ["f(n)", "big-Oh notation", "O(f(n))", "O(f(n))", "n^2", "mathbf{T}(n)", "O(n^2)"], "#text": "Because the phrase\n\"has an upper bound to its growth rate of \"\nis long and often used when discussing algorithms, we adopt a\nspecial notation, called .\nIf the upper bound for an algorithm's growth rate (for, say, the\nworst case) is (f(n)), then we would write that this algorithm is\n\"in the set  in the worst case\"\n(or just \"in  in the worst case\").\nFor example, if  grows as fast as \n(the running time of our algorithm) for the worst-case input,\nwe would say the algorithm is \"in  in the worst case\"."}, {"title_reference": ["mathbf{T}(n)", "f(n)"], "#text": "The following is a precise definition for an upper bound.\n represents the true running time of the\nalgorithm.\n is some expression for the upper bound."}, {"title_reference": ["n_0", "n", "n_0", "c", "c", "n", "n > n_0", "cf(n)", "c"], "emphasis": ["all", "always"], "#text": "Constant  is the smallest value of  for which the\nclaim of an upper bound holds true.\nUsually  is small, such as 1, but does not need to be.\nYou must also be able to pick some constant ,\nbut it is irrelevant what the value for  actually is.\nIn other words, the definition says that for  inputs of the\ntype in question (such as the worst case for all inputs of size\n) that are large enough (i.e., ),\nthe algorithm  executes in less than or equal to \nsteps for some constant ."}, {"title_reference": ["n", "n^2", "n^2"], "emphasis": "in the average case", "#text": "If someone asked you out of the blue \"Who is the best?\" your natural\nreaction should be to reply \"Best at what?\"\nIn the same way, if you are asked \"What is the growth rate of this\nalgorithm\", you would need to ask \"When? Best case? Average case? Or\nworst case?\"\nSome algorithms have the same behavior no matter which input instance\nof a given size that they receive.\nAn example is finding the maximum in an array of integers.\nBut for many algorithms, it makes a big difference which particular\ninput of a given size is involved, such as when\nsearching an unsorted array for a particular value.\nSo any statement about the upper bound of an algorithm\nmust be in the context of some specific class of inputs of size\n.\nWe measure this upper bound nearly always on the best-case,\naverage-case, or worst-case inputs.\nThus, we cannot say, \"this algorithm has an upper bound to its growth\nrate of \" because that is an incomplete statement.\nWe must say something like, \"this algorithm has an upper bound to its\ngrowth rate of  \"."}, {"title_reference": ["O(f(n))", "O(n)", "O(n^2)", "n", "O(n^2)", "O(n)", "O(f(n))", "in O(f(n))", "O(f(n))", "= O(f(n))", "O(n)", "O(n^2)", "O(n^2)", "O(n)"], "#text": "Knowing that something is in  says only how bad things\ncan be.\nPerhaps things are not nearly so bad.\nBecause sequential search is in  in the worst case,\nit is also true to say that sequential search is in .\nBut sequential search is practical for large  in a way that\nis not true for some other algorithms in .\nWe always seek to define the running time of an algorithm\nwith the tightest (lowest) possible upper bound.\nThus, we prefer to say that sequential search is in .\nThis also explains why the phrase \"is in \" or the\nnotation \"\" is used instead of \"is \"\nor \"\".\nThere is no strict equality to the use of big-Oh notation.\n is in , but  is not in\n."}], "block_quote": {"paragraph": {"title_reference": ["mathbf{T}(n)", "mathbf{T}(n)", "O(f(n))", "c", "n_0", "mathbf{T}(n) leq cf(n)", "n > n_0"], "#text": "For  a non-negatively valued function,\n is in set  if there exist two\npositive constants  and  such that\n for all ."}}, "topic": [{"title": "Example", "paragraph": {"title_reference": ["c_s", "c_s", "mathbf{T}(n) = c_s n/2", "n > 1", "c_s n/2 leq c_s n", "mathbf{T}(n)", "O(n)", "n_0 = 1", "c = c_s"], "#text": "Consider the sequential search algorithm for finding a specified\nvalue in an array of integers.\nIf visiting and examining one value in the array requires\n steps where  is a positive number,\nand if the value we search for has equal probability of appearing\nin any position in the array,\nthen in the average case .\nFor all values of , .\nTherefore, by the definition,  is in\n for  and ."}}, {"title": "Example", "paragraph": [{"title_reference": ["mathbf{T}(n) = c_1 n^2 + c_2 n", "c_1", "c_2"], "#text": "For a particular algorithm, \nin the average case where  and  are positive\nnumbers.\nThen,"}, {"title_reference": ["n > 1", "mathbf{T}(n) leq c n^2", "c = c_1 + c_2", "n_0 = 1", "mathbf{T}(n)", "O(n^2)"], "#text": "for all .\nSo,  for ,\nand .\nTherefore,  is in  by the second\ndefinition."}], "math_block": {"@xml:space": "preserve", "#text": "c_1 n^2 + c_2 n \\leq c_1 n^2 + c_2 n^2 \\leq (c_1 + c_2)n^2"}}, {"title": "Example", "paragraph": {"title_reference": ["mathbf{T}(n) = c", "mathbf{T}(n)", "O(c)", "O(1)"], "#text": "Assigning the value from the first position of an array to a\nvariable takes constant time regardless of the size of the\narray.\nThus,  (for the best, worst, and average\ncases).\nWe could say in this case that  is in\n.\nHowever, it is traditional to say that an algorithm whose running\ntime has a constant upper bound is in ."}}]}, {"@ids": "simplifying-rules", "@names": "simplifying\\ rules", "title": "Simplifying Rules", "paragraph": ["Once you determine the running-time equation for an algorithm,\nit really is a simple matter to derive the big-Oh\nexpressions from the equation.\nYou do not need to resort to the formal definitions of asymptotic\nanalysis.\nInstead, you can use the following rules to\ndetermine the simplest form.", {"title_reference": ["g(n)", "g(n)"], "#text": "The first rule says that if some function  is an upper\nbound for your cost function, then any upper bound for \nis also an upper bound for your cost function."}, "The significance of rule (2) is that you can ignore any multiplicative\nconstants in your equations when using big-Oh notation.", "Rule (3) says that given two parts of a program run in sequence\n(whether two statements or two sections of code),\nyou need consider only the more expensive part.", "Rule (4) is used to analyze simple loops in programs.\nIf some action is repeated some number of times,\nand each repetition has the same cost, then the total cost\nis the cost of the action multiplied by the number of times that the\naction takes place.", {"title_reference": ["mathbf{T}(n) = 3 n^4 + 5 n^2", "mathbf{T}(n)", "O(n^4)", "n^2", "n"], "#text": "Taking the first three rules collectively, you can ignore all\nconstants and all lower-order terms to determine the asymptotic growth\nrate for any cost function.\nThe advantages and dangers of ignoring constants were discussed near\nthe beginning of this section.\nIgnoring lower-order terms is reasonable when performing an\nasymptotic analysis.\nThe higher-order terms soon swamp the lower-order terms in their\ncontribution to the total cost as (n) becomes larger.\nThus, if , then\n is in .\nThe  term contributes relatively little to the total cost\nfor large ."}, "From now on, we will use these simplifying\nrules when discussing the cost for a program or algorithm."], "enumerated_list": {"@enumtype": "arabic", "@prefix": "", "@suffix": ".", "list_item": [{"paragraph": {"title_reference": ["f(n)", "O(g(n))", "g(n)", "O(h(n))", "f(n)", "O(h(n))"], "#text": "If  is in  and  is in\n, then  is in ."}}, {"paragraph": {"title_reference": ["f(n)", "O(k g(n))", "k > 0", "f(n)", "O(g(n))"], "#text": "If  is in  for any constant\n, then  is in ."}}, {"paragraph": {"title_reference": ["f_1(n)", "O(g_1(n))", "f_2(n)", "O(g_2(n))", "f_1(n) + f_2(n)", "O(max(g_1(n), g_2(n)))"], "#text": "If  is in  and  is in\n, then  is in\n."}}, {"paragraph": {"title_reference": ["f_1(n)", "O(g_1(n))", "f_2(n)", "O(g_2(n))", "f_1(n) f_2(n)", "O(g_1(n) g_2(n))"], "#text": "If  is in  and  is in\n, then  is in\n."}}]}, "comment": {"@xml:space": "preserve", "#text": "For books that do not include the lower bounds/Theta material"}, "raw": {"@format": "xml", "@xml:space": "preserve", "only": "null"}}, {"@ids": "summary", "@names": "summary", "title": "Summary", "raw": {"@format": "xml", "@xml:space": "preserve", "inlineav": {"@type": "ss", "@exer_name": "UpperBoundCON", "@long_name": "UpperBoundCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}}, {"@ids": "practice-questions", "@names": "practice\\ questions", "title": "Practice Questions", "raw": [{"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "ka", "@exer_name": "UpperBoundsSumm", "@long_name": "UpperBoundsSumm", "@points": "1.0", "@required": "True", "@threshold": "5"}}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/AlgAnal/UpperBoundCON.js"}]}]}}