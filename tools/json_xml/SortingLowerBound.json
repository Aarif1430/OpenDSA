{"document": {"@dupnames": "lower\\ bounds\\ for\\ sorting", "@ids": "lower-bounds-for-sorting", "@source": "<string>", "@title": "Lower Bounds for Sorting", "title": "Lower Bounds for Sorting", "subtitle": {"@dupnames": "lower\\ bounds\\ for\\ sorting", "@ids": "id1", "#text": "Lower Bounds for Sorting"}, "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@xml:space": "preserve", "index": "null"}, {"@format": "xml", "@xml:space": "preserve", "odsalink": "AV/Development/SortingLowerBoundCON.css"}, {"@format": "xml", "@xml:space": "preserve", "inlineav": {"@type": "ss", "@exer_name": "SortingLowerBoundCON", "@long_name": "SortingLowerBoundCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}, {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "ka", "@exer_name": "SortBoundSumm", "@long_name": "SortBoundSumm", "@points": "1.0", "@required": "True", "@threshold": "5"}}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/Development/SortingLowerBoundCON.js"}], "paragraph": [{"emphasis": ["problem", "algorithm", "any"], "#text": "By now you have seen many analyses for algorithms.\nThese analyses generally define the upper and lower bounds for\nalgorithms in their worst and average cases.\nFor many of the algorithms presented so far, analysis has been easy.\nThis module considers a more difficult task: An analysis for\nthe cost of a  as opposed to an .\nThe upper bound for a problem can be defined as the asymptotic cost of\nthe fastest known algorithm.\nThe lower bound defines the best possible cost for \nalgorithm that solves the problem, including algorithms not yet\ninvented.\nOnce the upper and lower bounds for the problem meet, we know that no\nfuture algorithm can possibly be (asymptotically) more efficient."}, {"emphasis": ["any", "problem"], "math": ["\\Omega(n)", "n", "n", "\\Omega(n)", "O(n \\log n)"], "#text": "A simple estimate for a problem's lower bound can be obtained by\nmeasuring the size of the input that must be read and the output\nthat must be written.\nCertainly no algorithm can be more efficient than the problem's\nI/O time.\nFrom this we see that the sorting problem cannot be solved by\n algorithm in less than  time because it\ntakes at least  steps to read and write the  values\nto be sorted.\nAlternatively, any sorting algorithm must at least look at every input\nvalue to recognize whether the input values are in sorted order.\nSo, based on our current knowledge of sorting algorithms and the\nsize of the input, we know that the  of sorting is\nbounded by  and ."}, {"math": "O(n \\log n)", "#text": "Computer scientists have spent much time devising efficient\ngeneral-purpose sorting algorithms, but no one has ever found one\nthat is faster than  in the worst or average\ncases.\nShould we keep searching for a faster sorting algorithm?\nOr can we prove that there is no faster sorting algorithm by finding\na tighter lower bound?"}, {"math": ["\\Omega(n \\log n)", "O(n)"], "title_reference": "reduction <reduction> <Reductions>", "#text": "This section presents one of the most important and most useful\nproofs in computer science:\nNo sorting algorithm based on key comparisons can possibly be\nfaster than  in the worst case.\nThis proof is important for three reasons.\nFirst, knowing that widely used sorting algorithms are asymptotically\noptimal is reassuring.\nIn particular, it means that you need not bang your head against\nthe wall searching for an  sorting algorithm.\n(Or at least not one that is in any way based on key comparisons.\nBut it is hard to imagine how to sort without any comparisons.\nEven Radix Sort is does comparisons, though in quite a different way.)\nSecond, this proof is one of the few non-trivial lower-bounds proofs\nthat we have for any problem; that is, this proof provides one of the\nrelatively few instances where our lower bound is tighter than simply\nmeasuring the size of the input and output.\nAs such, it provides a useful model for proving lower bounds on other\nproblems.\nFinally, knowing a lower bound for sorting gives us a lower\nbound in turn for other problems whose solution could be made to work\nas the basis for a sorting algorithm.\nThe process of deriving asymptotic bounds for one problem from the\nasymptotic bounds of another is called a\n."}, "Except for the Radix Sort and Binsort, all of the sorting algorithms\nwe have studied make decisions based on the direct comparison of two\nkey values.\nFor example, Insertion Sort sequentially compares the value to be\ninserted into the sorted list until a comparison against the next\nvalue in the list fails.\nIn contrast, Radix Sort has no direct comparison of key values.\nAll decisions are based on the value of specific digits in the key\nvalue,\nso it is possible to take approaches to sorting that do not involve\ndirect key comparisons.\nOf course, Radix Sort in the end does not provide a more efficient\nsorting algorithm than comparison-based sorting.\nThus, empirical evidence suggests that comparison-based sorting is a\ngood approach.", {"math": "\\Omega(n \\log n)", "#text": "(Actually, the truth is stronger than this statement implies.\nIn reality, Radix Sort relies on comparisons as well and so can be\nmodeled by the technique used in this section.\nThe result is an  bound in the general case\neven for algorithms that look like Radix Sort.)"}, {"math": ["\\Omega(n \\log n)", "n", "n!", "\\Omega(n \\log n)"], "#text": "The proof that any comparison sort requires \ncomparisons in the worst case is structured as follows.\nFirst, comparison-based decisions can be modeled as the\nbranches in a tree.\nThis means that any sorting algorithm based on comparisons between\nrecords can be viewed as a binary tree whose nodes correspond to the\ncomparisons, and whose branches correspond to the possible outcomes.\nNext, the minimum number of leaves in the resulting tree is\nshown to be the factorial of .\nFinally, the minimum depth of a tree with  leaves is shown\nto be in ."}, {"math": "\\Omega(n \\log n)", "title_reference": "decision tree", "#text": "Before presenting the proof of an  lower bound\nfor sorting, we first must define the concept of a\n.\nA decision tree is a binary tree that can model the processing for any\nalgorithm that makes binary decisions.\nEach (binary) decision is represented by a branch in the tree.\nFor the purpose of modeling sorting algorithms, we count all\ncomparisons of key values as decisions.\nIf two keys are compared and the first is less than the second, then\nthis is modeled as a left branch in the decision tree.\nIn the case where the first value is greater than the second, the\nalgorithm takes the right branch."}, "Here is a Visualization that illustrates decision trees and the\nsorting lower bound proof.", {"math": ["\\Omega(n \\log n)", "\\Omega(n \\log n)", "\\Omega(n \\log n)", "\\Omega(n \\log n)", "O(n \\log n)", "\\Theta(n \\log n)", "\\Theta(n \\log n)"], "#text": "Any sorting algorithm requiring  comparisons\nin the worst case requires  running time in\nthe worst case.\nBecause any sorting algorithm requires  running\ntime,\nthe problem of sorting also requires  time.\nWe already know of sorting algorithms with  running\ntime, so we can conclude that the problem of sorting requires\n time.\nAs a corollary, we know that no comparison-based sorting algorithm can\nimprove on existing  time sorting algorithms by\nmore than a constant factor."}, "Here are some review questions to check that you understand\nthis proof."]}}