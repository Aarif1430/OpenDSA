{"document": {"@ids": "optimizing-sort-algorithms-with-code-tuning", "@names": "optimizing\\ sort\\ algorithms\\ with\\ code\\ tuning", "@source": "<string>", "@title": "Optimizing Sort Algorithms with Code Tuning", "title": "Optimizing Sort Algorithms with Code Tuning", "subtitle": {"@ids": "code-tuning-for-simple-sorting-algorithms", "@names": "code\\ tuning\\ for\\ simple\\ sorting\\ algorithms", "#text": "Code Tuning for Simple Sorting Algorithms"}, "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@xml:space": "preserve", "todo": "null"}, {"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "pe", "@exer_name": "insertionSortWithoutSwapPRO", "@long_name": "insertionSortWithoutSwapPRO", "@points": "1.0", "@required": "True", "@threshold": "0.9"}}, {"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}], "paragraph": [{"math": "\\Theta(n^2)", "#text": "Since sorting is such an important application,\nit is natural for programmers to want\nto optimize their sorting code to run faster.\nOf course all quadratic sorts (Insertion Sort, Bubble Sort and\nSelection Sort) are relatively slow.\nEach has (as the name \"quadratic suggests)\n worst case running time.\nThe best way to speed them up is to find a better sorting algorithm.\nNonetheless, there have been many suggestions given over the years\nabout how to speed up one or another of these particular algorithms.\nThere are useful lessons to be learned about code tuning by\nseeing which of these ideas actually turn out to give better\nperformance.\nIt is also interesting to see the relative performance of the three\nalgorithms, as well as how various programming languages compare."}, "We start by trying to speed up Insertion Sort.\nRecall that Insertion Sort repeatedly moves an element toward the\nbeginning of the sorted part of the list until it encounters a key\nwith lesser value.\nIn the original code, this is done with a series of swap operations.\nThere is a better alternative than continuously swapping the\nrecord to the left until a smaller value is found.\nThis is to move the current record to a temporary\nvariable, and then shift all of the records with greater value one\nstep to the right.\nSince swap requires three assignments per element and shifting\nrequires only one assignment per element,\nwe can hope that this will yield a big improvement.\nOf course, the amount of improvement that we actually get will depend\non how much movement there is among the records.\nIf the list is already nearly sorted, then there will be few swaps\nanyway.\nHere is an implementation for Insertion Sort using this optimization.", "Now, you can test whether you understand how this works.", {"title_reference": "#OptimizeTable", "#text": "Table  shows the relative costs for\na number of optimizations in four programming languages: Java,\nJavaScipt, Processing, and Python."}, "The programming language that you use can have a big influence on the\nruntime for a program.\nPerhaps the greatest distinction is whether your language is compiled\nor not.\nJava, C++, and Processing are normally compiled, while JavaScript and\nPython are normally interpreted.\nThis can make a huge difference in whether a given code change will\nactually speed the program up or not.\nIn the case of the \"shift\" vs \"swap\" choice, shifting always turns out\nto be a big improvement.\nThis is more true for the interpreted languages JavaScript and\nPython than for Java and Processing, but still an improvement\neither way.\nBut the biggest effect that we see is that Python takes\nover 100 times as long to execute the same program as Java.", {"literal": ["i < n", "i != n"], "#text": "Some languages have peculiarities that it pays to be aware of.\nIt turns out that there is a big difference in JavaScript between\nusing  or  to test termination of a loop."}, {"math": ["i", "i+1", "i"], "#text": "Turning to Bubble Sort, the first thing we should notice from this\ntable is that it is far slower on random input than Insertion Sort.\nLet's consider a possible improvement that is sometimes suggested\nfor Bubble Sort.\nThat is to check during each iteration of the outer loop to see if any\nswaps took place during that iteration, and quit if not\n(since we know the list is ordered at this point).\nWe can improve on this idea even more by recognizing that if the last\nswap done affects the values at positions  and ,\nno swaps could happen to values a positions greater than .\nThus, we never need to check higher-positioned values again, which\ncould save many iterations even if there are a few swaps lower down.\nHere is code to implement this approach."}, "The problem with this idea is that a considerable amount of effort\n(relatively speaking) is required to track the position for the last\nswap within the inner loop.\nThis tracking process has a cost, and that cost is worthwhile only if\nthe amount of work it saves is greater than the amout of work that it\ncauses.\nUnfortunately, as the table shows, in the average case it just is not\nworth the time.\nModifying the code simply by removing the tracking steps (and so not\ngetting either the cost of tracking or the benefit of avoiding some of\nthe key comparisons) is faster in the average case.\nOf course, whether this is always true will depend on how much it\ncosts to extract the record keys and compare them, which depends on\nthe details of the record type and the sort implementation.\nIn our test implementation we are sorting integer values and so the\ncost to compare records is lower than it would be if we had to get a\nfield out of a more complex object.", {"math": ["\\Theta(n)", "\\Theta(n)", "\\Theta(n)"], "emphasis": "any", "#text": "It is also true that tracking the last swap position can substantially\nimprove the best case cost.\nIn fact, tracking the last swap position makes the best case cost of\nBubble Sort to be only .\nBut going out of one's way to artificially improve the best case has\ndubious value if doing so imposes additional cost on nearly all other\ninputs.\nNote that we could nominally convert  sorting algorithm to\nhave a best-case cost of  by simply adding code at\nthe beginning that checks if the list is already sorted.\nIt should be obvious that this is a waste of time, even though it has\nthe (small) possibility of winning big.\nUnlike Insertion Sort whose best case cost is naturally\n and whose time increases in proportion to how \"out\nof order\" the list is,\nthe number of iterations avoided by swap checking in Bubble Sort\nis sensitive to the detailed placements of the out-of-order records.\nIn fact, if we took a sorted list and moved the smallest value to the\nend, then there would be no benefit from swap checking whatsoever."}, "Finally, let's consider Selection Sort.\nThe table shows foremost that Selection Sort can be viewed as a far\nbetter optimization to Bubble Sort than tracking the last swap\nposition.\nThat is, tracking the position of the largest element and performing\none swap to put it into place is a far better optimization to Bubble\nSort than tracking the position of the last swap seen.\nThe table also shows that Selection Sort is faster in the average case\nthan Insertion Sort when implemented in Python.\nEvidently, the cost to swap is high for Python.", {"literal": ["swap", "selsort", "swap", "swap", "swap"], "math": ["n-1", "\\Theta(n)", "\\Theta(n^2)"], "#text": "Our original Selection Sort implementation is written to make a call\nto  even if the current record is already in its correct\nlocation.\nFor example, if the record with the largest value is already in the\nrightmost array position, then  will still call \nwith the two position parameters being the same.\nThe net effect is that the work done by  will not change\nanything in the array, and this is a waste of time.\nThus, the total number of swaps done by Selection Sort is always\n in the best, average and worst cases.\nIt might seem like a good idea to test if the positions are the same\nbefore calling , especially since Selection Sort's claim to\nfame is its low number of swaps.\nActually, we can't expect this to ever make much difference since we\nare talking about  actions within \ntotal steps, an inconsequential fraction.\nThe other consideration is whether this is could typically be expected\nto save time even when just considering the time needed to do the\nswaps.\nDoing the check to see if a swap is necessary also takes some time.\nIt is only worthwhile to test if the time required by the test is more\nthan made up for by the work saved when the unnecessary swap was\navoided.\nFor randomly ordered input, it is probably more expensive to test\nthis condition before every swap than to just do the swap.\nIf the input records are already sorted, then all of the swaps are\nunnecessary and it would be (trivially) faster to test.\nBut in the average case, few swaps will be saved this way and the\n\"optimization\" might actually slow down the program (but only\nslightly)."}, {"literal": "swap", "#text": "For all of these sorting algorithms, the  function call might\nbe a key part of the cost since it is called so many times.\nA simple way to speed things up is to replace this function call with\nthe code that the function would perform.\nDepending on the language, compiler, and operating system, one might\nexpect to save between 5 and 10 percent of the total time by doing so."}, {"literal": ["int", "KVPair"], "#text": "Another important consideration is the type of data object being\nused.\nFor Processing and Java, we use a simple Integer wrapper object that\nsupports the Comparable interface.\nThis means that some dereferencing of the key value from an object is\nrequired, which is a typical expectation in a realistic application of\na sorting function.\nHowever, if we were to sort a simple array of  values, the cost\nfor all sorting algorithms will be less than half that shown.\nIf we use a the more complicated  objects, the costs will\nmore than double over those shown in the table."}], "target": {"@refid": "optimizetable"}, "topic": {"@ids": "optimizetable", "@names": "optimizetable", "title": "Table", "paragraph": "Empirical comparison of proposed optimizations to quadratic sort\nimplementations.\nEach sorting algorithm is run on a random integer\narray with 10,000 items. Times are in milliseconds.\nThe arrays being sorted use the Comparable interface in\nlanguages that support this.", "math_block": {"@xml:space": "preserve", "#text": "\\begin{array}{l|rrrr}\n\\hline\n\\textbf{Sort} & \\textbf{Java}& \\textbf{Processing} & \\textbf{JavaScript}&\n\\textbf{Python}\\\\\n\\hline\n\\textbf{Insertion Sort}\\\\\n\\textrm{Standard}    &  60 &  26 & 118 & 11,220\\\\\n\\textrm{Shifting}    &  41 &  18 &  77 &  5,100\\\\\n\\hline\n\\textbf{Bubble Sort}\\\\\n\\textrm{Standard}    & 202 & 149 & 303 & 12,700\\\\\n\\textrm{Check Swaps} & 230 & 152 & 327 & 13,275\\\\\n\\hline\n\\textbf{Selection Sort}\\\\\n\\textrm{Standard}    & 104 &  65 & 158 &  4,000\\\\\n\\textrm{Check Swaps} & 104 &  65 & 155 &  4,050\\\\\n\\hline\n\\end{array}"}}}}