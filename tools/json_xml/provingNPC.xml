<?xml version="1.0" encoding="utf8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.13.1 -->
<document dupnames="np-completeness\ proofs" ids="np-completeness-proofs" source="&lt;string&gt;" title="NP-Completeness Proofs"><title>NP-Completeness Proofs</title><subtitle dupnames="np-completeness\ proofs" ids="id1">NP-Completeness Proofs</subtitle><comment xml:space="preserve">This file is part of the OpenDSA eTextbook project. See</comment><comment xml:space="preserve">http://algoviz.org/OpenDSA for more details.</comment><comment xml:space="preserve">Copyright (c) 2012-2013 by the OpenDSA Project Contributors, and</comment><comment xml:space="preserve">distributed under an MIT open source license.</comment><raw format="xml" xml:space="preserve"><avmetadata>null</avmetadata></raw><paragraph>To start the process of being able to prove problems are NP-complete,
we need to prove just one problem <title_reference>H</title_reference> is NP-complete.
After that, to show that any problem <title_reference>X</title_reference> is NP-hard, we just
need to reduce <title_reference>H</title_reference> to <title_reference>X</title_reference>.
When doing NP-completeness proofs, it is very important not to get
this reduction backwards!
If we reduce candidate problem <title_reference>X</title_reference> to known hard problem
<title_reference>H</title_reference>, this means that we use <title_reference>H</title_reference> as a step to solving
<title_reference>X</title_reference>.
All that means is that we have found a (known) hard way to
solve <title_reference>X</title_reference>.
However, when we reduce known hard problem <title_reference>H</title_reference> to candidate
problem <title_reference>X</title_reference>, that means we are using <title_reference>X</title_reference> as a step to
solve <title_reference>H</title_reference>.
And if we know that <title_reference>H</title_reference> is hard, that means <title_reference>X</title_reference> must also
be hard (because if <title_reference>X</title_reference> were not hard, then neither would
<title_reference>H</title_reference> be hard).</paragraph><paragraph>So a crucial first step to getting this whole theory off the ground is
finding one problem that is NP-hard.
The first proof that a problem is NP-hard (and because it is in NP,
therefore NP-complete) was done by Stephen Cook.
For this feat, Cook won the first Turing award, which is the closest
Computer Science equivalent to the Nobel Prize.
The "grand-daddy" NP-complete problem that Cook used is called
SATISFIABILITY (or SAT for short).</paragraph><paragraph>A <title_reference>Boolean expression</title_reference> includes Boolean variables combined
using the operators AND (<title_reference>cdot</title_reference>), OR (<title_reference>+</title_reference>), and NOT
(to negate Boolean variable <title_reference>x</title_reference> we write <title_reference>overline{x}</title_reference>).
A <title_reference>literal</title_reference> is a Boolean variable or its negation.
A <title_reference>clause</title_reference> is one or more literals OR'ed together.
Let <title_reference>E</title_reference> be a Boolean expression over variables
<title_reference>x_1, x_2, ..., x_n</title_reference>.
Then we define <title_reference>Conjunctive Normal Form</title_reference> (CNF) to be a Boolean
expression written as a series of clauses that are AND'ed together.
For example,</paragraph><math_block xml:space="preserve">E = (x_5 + x_7 + \overline{x_8} + x_{10}) \cdot (\overline{x_2} + x_3)
\cdot (x_1 + \overline{x_3} + x_6)</math_block><paragraph>is in CNF, and has three clauses.
Now we can define the problem SAT.</paragraph><topic><title>Problem</title><paragraph>SATISFIABILITY (SAT)</paragraph><paragraph><strong>Input:</strong> A Boolean expression <title_reference>E</title_reference> over variables
<title_reference>x_1, x_2, ...</title_reference> in Conjunctive Normal Form.</paragraph><paragraph><strong>Output:</strong> YES if there is an assignment to the
variables that makes <title_reference>E</title_reference> true, NO otherwise.</paragraph></topic><paragraph>Cook proved that SAT is NP-hard.
Explaining Cook's proof is beyond the scope of this course.
But we can briefly summarize it as follows.
Any decision problem <title_reference>F</title_reference> can be recast as some language
acceptance problem <title_reference>L</title_reference>:</paragraph><math_block xml:space="preserve">F(I) = \mbox{YES} \Leftrightarrow L(I') = \mbox{ACCEPT}.</math_block><paragraph>That is, if a decision problem <title_reference>F</title_reference> yields YES on
input <title_reference>I</title_reference>, then there is a language <title_reference>L</title_reference> containing
string <title_reference>I'</title_reference> where <title_reference>I'</title_reference> is some suitable
transformation of input <title_reference>I</title_reference>.
Conversely, if <title_reference>F</title_reference> would give answer NO for input <title_reference>I</title_reference>,
then <title_reference>I</title_reference> 's transformed version <title_reference>I'</title_reference> is not in the
language <title_reference>L</title_reference>.</paragraph><paragraph>Turing machines are a simple model of computation for writing
programs that are language acceptors.
There is a "universal" Turing machine that can take as input a
description for a Turing machine, and an input string, and return the
execution of that machine on that string.
This Turing machine in turn can be cast as a Boolean expression such
that the expression is satisfiable if and only if the Turing machine
yields ACCEPT for that string.
Cook used Turing machines in his proof because they are simple enough
that he could develop this transformation of Turing machines to
Boolean expressions, but rich enough to be able to compute any
function that a regular computer can compute.
The significance of this transformation is that <emphasis>any</emphasis> decision
problem that is performable by the Turing machine is transformable to
SAT.
Thus, SAT is NP-hard.</paragraph><paragraph>To show that a decision problem <title_reference>X</title_reference>
is NP-complete, we prove that <title_reference>X</title_reference> is in NP (normally easy, and
normally done by giving a suitable polynomial-time, non-deterministic
algorithm) and then prove that <title_reference>X</title_reference> is NP-hard.
To prove that <title_reference>X</title_reference> is NP-hard, we choose a known NP-complete
problem, say <title_reference>A</title_reference>.
We describe a polynomial-time transformation that takes an
<emphasis>arbitrary</emphasis> instance <title_reference>I</title_reference> of <title_reference>A</title_reference> to an instance
<title_reference>I'</title_reference> of <title_reference>X</title_reference>.
We then describe a polynomial-time transformation from
<title_reference>SLN'</title_reference> to <title_reference>SLN</title_reference> such that <title_reference>SLN</title_reference> is the solution
for <title_reference>I</title_reference>.</paragraph><paragraph>The following modules show a number of known NP-complete problems, and
also some proofs that they are NP-complete.
The various proofs will link the problems together as shown here:</paragraph><target refid="npcreduction"></target><raw format="xml" ids="npcreduction" names="npcreduction" xml:space="preserve"><inlineav
    type="dgm"
    exer_name="NPCProofDiagramCON"
    long_name="NPCProofDiagramCON"
    points="0"
    required="True"
    threshold="1.0">
</inlineav>
</raw><raw format="xml" xml:space="preserve"><odsascript>AV/Development/NP/NPCProofDiagramCON.js</odsascript></raw></document>