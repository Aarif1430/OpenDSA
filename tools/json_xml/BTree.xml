<?xml version="1.0" encoding="utf8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.13.1 -->
<document dupnames="b-trees" ids="b-trees" source="&lt;string&gt;" title="B-Trees"><title>B-Trees</title><comment xml:space="preserve">This file is part of the OpenDSA eTextbook project. See</comment><comment xml:space="preserve">http://algoviz.org/OpenDSA for more details.</comment><comment xml:space="preserve">Copyright (c) 2012-2013 by the OpenDSA Project Contributors, and</comment><comment xml:space="preserve">distributed under an MIT open source license.</comment><raw format="xml" xml:space="preserve"><avmetadata>null</avmetadata></raw><section dupnames="b-trees" ids="id1"><title>B-Trees</title><paragraph>This section presents the B-tree.
B-trees are usually attributed to R. Bayer and E. McCreight
who described the B-tree in a 1972 paper.
By 1979, B-trees had replaced virtually all large-file access
methods other than hashing.
B-trees, or some variant of B-trees, are <emphasis>the</emphasis> standard file
organization for applications requiring insertion, deletion, and key
range searches.
They are used to implement most modern file systems.
B-trees address effectively all of the major problems encountered
when implementing disk-based search trees:</paragraph><enumerated_list enumtype="arabic" prefix="" suffix="."><list_item><paragraph>B-trees are always height balanced, with all leaf nodes at the same
level.</paragraph></list_item><list_item><paragraph>Update and search operations affect only a few disk blocks.
The fewer the number of disk blocks affected, the less disk I/O is
required.</paragraph></list_item><list_item><paragraph>B-trees keep related records (that is, records with similar key
values) on the same disk block, which helps to minimize disk I/O on
searches due to locality of reference.</paragraph></list_item><list_item><paragraph>B-trees  guarantee that every node in the tree will be
full at least to a certain minimum percentage.
This improves space efficiency while reducing the typical number of
disk fetches necessary during a search or update operation.</paragraph></list_item></enumerated_list><paragraph>A B-tree of order <math>m</math> is defined to have
the following shape properties:</paragraph><bullet_list bullet="*"><list_item><paragraph>The root is either a leaf or has at least two children.</paragraph></list_item><list_item><paragraph>Each internal node, except for the root, has between
<math>\lceil m/2 \rceil</math> and <math>m</math> children.</paragraph></list_item><list_item><paragraph>All leaves are at the same level in the tree, so the tree is always
height balanced.</paragraph></list_item></bullet_list><paragraph>The B-tree  is a generalization of the 2-3 tree.
Put another way, a 2-3 tree is a B-tree of order three.
Normally, the size of a node in the B-tree is chosen to fill a disk
block.
A B-tree node implementation typically allows 100 or more children.
Thus, a B-tree node is equivalent to a disk block, and a "pointer"
value stored in the tree is actually the number of the block
containing the child node (usually interpreted as an offset from the
beginning of the corresponding disk file).
In a typical application, the B-tree's access to the disk file will be
managed using a <title_reference>buffer pool &lt;buffer pool&gt; &lt;BuffPool&gt;</title_reference>
and a block-replacement scheme such as <title_reference>LRU</title_reference>.</paragraph><paragraph>Figure <title_reference>Figure #BTexamp</title_reference> shows a B-tree of order four.
Each node contains up to three keys, and
internal nodes have up to four children.</paragraph><target refid="btexamp"></target><raw format="xml" ids="btexamp" names="btexamp" xml:space="preserve"><odsafig>null</odsafig></raw><paragraph>Search in a B-tree is a generalization of search in a 2-3 tree.
It is an alternating two-step process, beginning with the root node of
the B-tree.</paragraph><enumerated_list enumtype="arabic" prefix="" suffix="."><list_item><paragraph>Perform a binary search on the records in the
current node.
If a record with the search key is found, then return that record.
If the current node is a leaf node and the key is not found,
then report an unsuccessful search.</paragraph></list_item><list_item><paragraph>Otherwise, follow the proper branch and repeat the process.</paragraph></list_item></enumerated_list><paragraph>For example, consider a search for the record with key value 47 in the
tree of Figure <title_reference>Figure #BTexamp</title_reference>.
The root node is examined and the second (right) branch taken.
After examining the node at level 1, the third branch is taken to the
next level to arrive at the leaf node containing a record with key
value 47.</paragraph><paragraph>B-tree insertion is a generalization of 2-3 tree insertion.
The first step is to find the leaf node that should contain the
key to be inserted, space permitting.
If there is room in this node, then insert the key.
If there is not, then split the node into two and promote the middle
key to the parent.
If the parent becomes full, then it is split in turn, and its middle
key promoted.</paragraph><paragraph>Note that this insertion process is guaranteed to keep all nodes at
least half full.
For example, when we attempt to insert into a full internal node of a
B-tree  of order four, there will now be five children that must be
dealt with.
The node is split into two nodes containing two keys each, thus
retaining the B-tree property.
The middle of the five children is promoted to its parent.</paragraph></section><section ids="id2" names="b+\ trees"><title>B+ Trees</title><paragraph>The previous section mentioned that B-trees are universally used
to implement large-scale disk-based systems.
Actually, the B-tree as described in the previous section is almost
never implemented.
What is most commonly implemented is a variant of the B-tree,
called the <math>\mathrm{B}^+</math> tree.
When greater efficiency is required, a more complicated
variant known as the <math>\mathrm{B}^*</math> tree is used.</paragraph><paragraph>Consider again the <title_reference>linear index</title_reference>.
When the collection of records will not change, a linear index
provides an extremely efficient way to search.
The problem is how to handle those pesky inserts and deletes.
We could try to keep the core idea of storing a sorted array-based
list, but make it more flexible by breaking the list into manageable
chunks that are more easily updated.
How might we do that?
First, we need to decide how big the chunks should be.
Since the data are on disk, it seems reasonable to store a chunk that
is the size of a disk block, or a small multiple of the disk block
size.
If the next record to be inserted belongs to a chunk that hasn't
filled its block then we can just insert it there.
The fact that this might cause other records in that chunk to move a
little bit in the array is not important, since this does not cause
any extra disk accesses so long as we move data within that chunk.
But what if the chunk fills up the entire block that contains it?
We could just split it in half.
What if we want to delete a record?
We could just take the deleted record out of the chunk, but we might
not want a lot of near-empty chunks.
So we could put adjacent chunks together if they have only a small
amount of data between them.
Or we could shuffle data between adjacent chunks that together contain
more data.
The big problem would be how to find the desired chunk when processing
a record with a given key.
Perhaps some sort of tree-like structure could be used to locate the
appropriate chunk.
These ideas are exactly what motivate the <math>\mathrm{B}^+</math> tree.
The <math>\mathrm{B}^+</math> tree is essentially a mechanism for managing a sorted
array-based list, where the list is broken into chunks.</paragraph><paragraph>The most significant difference between the <math>\mathrm{B}^+</math> tree
and the BST or the standard B-tree is that
the <math>\mathrm{B}^+</math> tree  stores records only at the leaf nodes.
Internal nodes store key values, but these
are used solely as placeholders to guide the search.
This means that internal nodes are significantly different in
structure from leaf nodes.
Internal nodes store keys to guide the search, associating each key
with a pointer to a child <math>\mathrm{B}^+</math> tree node.
Leaf nodes store actual records, or else keys and pointers to actual
records in a separate disk file if the <math>\mathrm{B}^+</math> tree is
being used purely as an index.
Depending on the size of a record as compared to the size of a key,
a leaf node in a <math>\mathrm{B}^+</math> tree of order <math>m</math> might
have enough room to store more or less than <math>m</math> records.
The requirement is simply that the leaf nodes store enough records to
remain at least half full.
The leaf nodes of a <math>\mathrm{B}^+</math> tree are normally
linked together to form a doubly linked list.
Thus, the entire collection of records can be traversed in sorted
order by visiting all the leaf nodes on the linked list.
Here is a Java-like pseudocode representation for the
<math>\mathrm{B}^+</math> tree node interface.
Leaf node and internal node subclasses would implement this interface.</paragraph><raw format="xml" xml:space="preserve"><codeinclude>null</codeinclude></raw><paragraph>An important implementation detail to note is that while
Figure <title_reference>Figure #BTexamp</title_reference> shows internal nodes containing three
keys and four pointers, class <literal>BPNode</literal> is slightly different in that
it stores key/pointer pairs.
Figure <title_reference>Figure #BTexamp</title_reference> shows the <math>\mathrm{B}^+</math> tree as
it is traditionally drawn.
To simplify implementation in practice, nodes really do
associate a key with each pointer.
Each internal node should be assumed to hold in the leftmost position
an additional key that is less than or equal to any possible key value
in the node's leftmost subtree.
<math>\mathrm{B}^+</math> tree implementations typically store an
additional dummy record in the leftmost leaf node whose key value is
less than any legal key value.</paragraph><paragraph><math>\mathrm{B}^+</math> trees are exceptionally good for range queries.
Once the first record in the range has been found, the rest of the
records with keys in the range can be accessed by sequential
processing of the remaining records in the first node, and then
continuing down the linked list of leaf nodes as far as necessary.
Figure <title_reference>Figure #BPexamp</title_reference> illustrates the <math>\mathrm{B}^+</math>
tree.</paragraph><target refid="bpexamp"></target><raw format="xml" ids="bpexamp" names="bpexamp" xml:space="preserve"><odsafig>null</odsafig></raw><paragraph>Search in a <math>\mathrm{B}^+</math> tree is nearly identical to search in
a regular B-tree, except that the search must always continue to the
proper leaf node.
Even if the search-key value is found in an internal node, this is
only a placeholder and does not provide access to the actual record.
To find a record with key value 33 in the <math>\mathrm{B}^+</math> tree of
Figure <title_reference>Figure #BPexamp</title_reference>, search begins at the root.
The value 33 stored in the root merely serves as a placeholder,
indicating that keys with values greater than or equal to 33 are found
in the second subtree.
From the second child of the root, the first branch is taken to reach
the leaf node containing the actual record (or a pointer to the actual
record) with key value 33.
Here is a pseudocode sketch of the <math>\mathrm{B}^+</math> tree search
algorithm.</paragraph><raw format="xml" xml:space="preserve"><codeinclude>null</codeinclude></raw><paragraph><math>\mathrm{B}^+</math> tree insertion is similar to B-tree insertion.
First, the leaf <math>L</math> that should contain the record is found.
If <math>L</math> is not full, then the new record is added, and no
other <math>\mathrm{B}^+</math> tree nodes are affected.
If <math>L</math> is already full, split it in two (dividing the records
evenly among the two nodes) and promote a copy of the
least-valued key in the newly formed right node.
As with the 2-3 tree, promotion might cause
the parent to split in turn, perhaps eventually leading to splitting
the root and causing the <math>\mathrm{B}^+</math> tree to gain a new
level.
<math>\mathrm{B}^+</math> tree insertion keeps all leaf nodes at equal
depth.
Figure <title_reference>Figure #BPins</title_reference> illustrates the insertion process through
several examples.</paragraph><target refid="bpins"></target><raw format="xml" ids="bpins" names="bpins" xml:space="preserve"><odsafig>null</odsafig></raw><paragraph>Here is a a Java-like pseudocode sketch of the <math>\mathrm{B}^+</math>
tree insert algorithm.</paragraph><raw format="xml" xml:space="preserve"><codeinclude>null</codeinclude></raw><paragraph>Here is an exercise to see if you get the basic idea of
<math>\mathrm{B}^+</math> tree insertion.</paragraph><raw format="xml" xml:space="preserve"><avembed
    type="pe"
    exer_name="bPlusTreeInsertPRO"
    long_name="bPlusTreeInsertPRO"
    points="1.0"
    required="True"
    threshold="0.9">
</avembed>
</raw><paragraph>To delete record <math>R</math> from the <math>\mathrm{B}^+</math> tree,
first locate the leaf <math>L</math> that contains <math>R</math>.
If <math>L</math> is more than half full, then we need only remove <math>R</math>,
leaving <math>L</math> still at least half full.
This is demonstrated by Figure <title_reference>Figure #BPdelsimp</title_reference>.</paragraph><target refid="bpdelsimp"></target><raw format="xml" ids="bpdelsimp" names="bpdelsimp" xml:space="preserve"><odsafig>null</odsafig></raw><paragraph>If deleting a record reduces the number of records in the node below
the minimum threshold (called an <title_reference>underflow</title_reference>), then we must do
something to keep the node sufficiently full.
The first choice is to look at the node's adjacent siblings to
determine if they have a spare record that can be used to fill the
gap.
If so, then enough records are transferred from the
sibling so that both nodes have about the same number of records.
This is done so as to delay as long as possible the next time when a
delete causes this node to underflow again.
This process might require that the parent node has its placeholder
key value revised to reflect the true first key value in each node.
Figure <title_reference>Figure #BPborrow</title_reference> illustrates the process.</paragraph><target refid="bpborrow"></target><raw format="xml" ids="bpborrow" names="bpborrow" xml:space="preserve"><odsafig>null</odsafig></raw><paragraph>If neither sibling can lend a record to the under-full node
(call it <math>N</math>),
then <math>N</math> must give its records to a sibling and be removed
from the tree.
There is certainly room to do this, because the sibling is at most
half full (remember that it had no records to contribute to the
current node), and <math>N</math> has become less than half full because it
is under-flowing.
This merge process combines two subtrees of the parent, which might
cause it to underflow in turn.
If the last two children of the root merge together, then the tree
loses a level.
Figure <title_reference>Figure #BPmerge</title_reference> illustrates the node-merge deletion
process.</paragraph><target refid="bpmerge"></target><raw format="xml" ids="bpmerge" names="bpmerge" xml:space="preserve"><odsafig>null</odsafig></raw><paragraph>Here is a Java-like pseudocode for the <math>\mathrm{B}^+</math> tree
delete algorithm.</paragraph><raw format="xml" xml:space="preserve"><codeinclude>null</codeinclude></raw><paragraph>The <math>\mathrm{B}^+</math> tree requires that all nodes be at least half
full (except for the root).
Thus, the storage utilization must be at least 50%.
This is satisfactory for many implementations, but note that keeping
nodes fuller will result both in
less space required (because there is less empty space in the disk file)
and in more efficient processing (fewer blocks on average will be read
into memory because the amount of information in each block is greater).
Because B-trees have become so popular, many algorithm designers have
tried to improve B-tree performance.
One method for doing so is to use the <math>\mathrm{B}^+</math> tree
variant known as the <math>\mathrm{B}^*</math> tree.
The <math>\mathrm{B}^*</math> tree is identical to the <math>\mathrm{B}^+</math>
tree, except for the rules used to split and merge nodes.
Instead of splitting a node in half when it overflows, the
<math>\mathrm{B}^*</math> tree
gives some records to its neighboring sibling, if possible.
If the sibling is also full, then these two nodes split into three.
Similarly, when a node underflows, it is combined with its two
siblings, and the total reduced to two nodes.
Thus, the nodes are always at least two thirds full. <footnote_reference auto="1" ids="id3" refid="id4">1</footnote_reference></paragraph><paragraph>Here is a visualization for the <math>\mathrm{B}^+</math> tree.</paragraph><raw format="html" xml:space="preserve">&lt;center&gt;
&lt;iframe id="BT_iframe"
     src="//www.cs.usfca.edu/~galles/visualization/BPlusTree.html"
     width="1100" height="800"
     frameborder="1" marginwidth="0" marginheight="0"
     scrolling="no"&gt;
&lt;/iframe&gt;
&lt;/center&gt;</raw><paragraph>This visualization was written by David Galles of the University of
San Francisco as part of his <raw format="html" xml:space="preserve">&lt;a href="http://www.cs.usfca.edu/~galles/visualization/Algorithms.html" target="_blank"&gt;Data Structure Visualizations&lt;/a&gt;</raw> package.</paragraph><substitution_definition names="external_link"><raw format="html" xml:space="preserve">&lt;a href="http://www.cs.usfca.edu/~galles/visualization/Algorithms.html" target="_blank"&gt;Data Structure Visualizations&lt;/a&gt;</raw></substitution_definition><footnote auto="1" backrefs="id3" ids="id4" names="1"><label>1</label><paragraph>This concept can be extended further if higher space
utilization is required.
However, the update routines become much more complicated.
I once worked on a project where we implemented 3-for-4 node
split and merge routines.
This gave better performance than the 2-for-3 node split and
merge routines of the <math>\mathrm{B}^*</math> tree.
However, the spitting and merging routines were so complicated
that even their author could no longer understand them
once they were completed!</paragraph></footnote></section><section ids="b-tree-analysis" names="b-tree\ analysis"><title>B-Tree Analysis</title><paragraph>The asymptotic cost of search, insertion, and deletion of
records from B-trees, <math>\mathrm{B}^+</math> trees, and
<math>\mathrm{B}^*</math> trees is <math>\Theta(\log n)</math>
where <math>n</math> is the total number of records in the tree.
However, the base of the log is the (average) branching factor of the
tree.
Typical database applications use extremely high branching factors,
perhaps 100 or more.
Thus, in practice the B-tree and its variants are extremely shallow.</paragraph><paragraph>As an illustration, consider a <math>\mathrm{B}^+</math> tree of order 100
and leaf nodes that contain up to 100 records.
A B-<math>\mathrm{B}^+</math> tree with height one (that is, just a single
leaf node) can have at most 100 records.
A <math>\mathrm{B}^+</math> tree with height two (a root internal node
whose children are leaves) must have at least 100 records
(2 leaves with 50 records each).
It has at most 10,000 records (100 leaves with 100 records each).
A <math>\mathrm{B}^+</math> tree with height three must have at least 5000
records (two second-level nodes with 50 children containing 50 records
each) and at most one million records (100 second-level nodes with 100
full children each).
A <math>\mathrm{B}^+</math> tree with height four must have at least
250,000 records and at most 100 million records.
Thus, it would require an <emphasis>extremely</emphasis> large database to generate
a <math>\mathrm{B}^+</math> tree of more than height four.</paragraph><paragraph>The <math>\mathrm{B}^+</math> tree split and insert rules guarantee that
every node (except perhaps the root) is at least half full.
So they are on average about 3/4 full.
But the internal nodes are purely overhead, since the keys stored
there are used only by the tree to direct search, rather than store
actual data.
Does this overhead amount to a significant use of space?
No, because once again the high fan-out rate of the tree structure
means that the vast majority of nodes are leaf nodes.
A <title_reference>K-ary tree &lt;K-ary tree&gt; &lt;Kary&gt;</title_reference> has
approximately <math>1/K</math> of its nodes as internal nodes.
This means that while half of a full binary tree's nodes are internal
nodes, in a <math>\mathrm{B}^+</math> tree of order 100 probably only about
<math>1/75</math> of its nodes are internal nodes.
This means that the overhead associated with internal nodes is very
low.</paragraph><paragraph>We can reduce the number of disk fetches required for the B-tree
even more by using the following methods.
First, the upper levels of the tree can be stored in main memory at all
times.
Because the tree branches so quickly, the top two levels
(levels 0 and 1) require relatively little space.
If the B-tree is only height four, then at most two disk fetches
(internal nodes at level two and leaves at level three) are required
to reach the pointer to any given record.</paragraph><paragraph>A buffer pool could be used to manage nodes of the B-tree.
Several nodes of the tree would typically be in main memory at one
time.
The most straightforward approach is to use a standard method such as
LRU to do node replacement.
However, sometimes it might be desirable to "lock" certain nodes
such as the root into the buffer pool.
In general, if the buffer pool is even of modest size (say at least
twice the depth of the tree), no special techniques for node
replacement will be required because the upper-level nodes will
naturally be accessed frequently.</paragraph></section></document>