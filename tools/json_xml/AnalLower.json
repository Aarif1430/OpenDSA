{"document": {"@dupnames": "lower\\ bounds\\ and\\ theta\\ notation", "@ids": "lower-bounds-and-theta-notation", "@source": "<string>", "@title": "Lower Bounds and Theta Notation", "title": {"title_reference": "Theta", "#text": "Lower Bounds and  Notation"}, "subtitle": {"@dupnames": "lower\\ bounds\\ and\\ theta\\ notation", "@ids": "id1", "#text": "Lower Bounds and Theta Notation"}, "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@xml:space": "preserve", "odsalink": "AV/AlgAnal/LowerBoundCON.css"}], "section": [{"@ids": "lower-bounds", "@names": "lower\\ bounds", "title": "Lower Bounds", "paragraph": [{"title_reference": ["Big-Oh notation", "n"], "#text": "describes an upper bound.\nIn other words, big-Oh notation states a claim about the greatest\namount of some resource (usually time) that is required by an\nalgorithm for some class of inputs of size  (typically\nthe worst such input, the average of all possible inputs, or the best\nsuch input)."}, {"title_reference": "n", "#text": "Similar notation is used to describe the least amount of a resource\nthat an algorithm needs for some class of input.\nLike big-Oh notation, this is a measure of the algorithm's\ngrowth rate.\nLike big-Oh notation, it works for any resource, but\nwe most often measure the least amount of time required.\nAnd again, like big-Oh notation, we are measuring the resource\nrequired for some particular class of inputs: the worst-, average-,\nor best-case input of size ."}, {"title_reference": ["lower bound", "Omega", "Omega"], "#text": "The  for an algorithm\n(or a problem, as explained later)\nis denoted by the symbol , pronounced \"big-Omega\" or\njust \"Omega\".\nThe following definition for  is symmetric with the\ndefinition of big-Oh."}, {"title_reference": ["Omega(n)", "Omega", "Omega(n^2)"], "#text": "It is also true that the equation of the example above\nis in .\nHowever, as with big-Oh notation, we wish to get the \"tightest\"\n(for  notation, the largest) bound possible.\nThus, we prefer to say that this running time is in ."}, {"title_reference": ["K", "Omega(n)", "cn", "c"], "emphasis": "at least", "#text": "Recall the sequential search algorithm to find a value \nwithin an array of integers.\nIn the average and worst cases this algorithm is in ,\nbecause in both the average and worst cases we must examine\n  values (where  is 1/2 in the average\ncase and 1 in the worst case)."}], "block_quote": {"paragraph": {"title_reference": ["mathbf{T}(n)", "mathbf{T}(n)", "Omega(g(n))", "c", "n_0", "mathbf{T}(n) geq c g(n)", "n > n_0"], "#text": "For  a non-negatively valued function,\n is in set  if there exist\ntwo positive constants  and  such that\n for all ."}}, "target": {"@refid": "aanalex"}, "topic": {"@ids": "aanalex", "@names": "aanalex", "title": "Example", "paragraph": [{"title_reference": ["mathbf{T}(n) = c_1 n^2 + c_2 n", "c_1", "c_2 > 0"], "#text": "Assume  for  and\n.\nThen,"}, {"title_reference": ["n > 1", "mathbf{T}(n) geq c n^2", "c = c_1", "n_0 = 1", "mathbf{T}(n)", "Omega(n^2)"], "#text": "for all .\nSo,  for  and\n.\nTherefore,  is in  by the\ndefinition."}], "math_block": {"@xml:space": "preserve", "#text": "c_1 n^2 + c_2 n \\geq c_1 n^2"}}, "footnote": {"@auto": "1", "@ids": "id2", "@names": "1", "label": "1", "paragraph": [{"title_reference": "Omega", "#text": "An alternate (non-equivalent) definition for  is"}, {"title_reference": ["c g(n)", "g(n)", "mathbf{T}(n) geq c g(n)", "n", "n"], "emphasis": ["not", "does not"], "#text": "This definition says that for an \"interesting\" number of\ncases, the algorithm takes at least  time.\nNote that this definition is  symmetric with the\ndefinition of big-Oh.\nFor  to be a lower bound,\nthis definition  require that\n for\nall values of  greater than some constant.\nIt only requires that this happen often enough, in particular\nthat it happen for an infinite number of values for .\nMotivation for this alternate definition can be found in the\nfollowing example."}, "Assume a particular algorithm has the following behavior:", {"title_reference": ["n^2/100 geq frac{1}{100} n^2", "n geq 0", "mathbf{T}(n) geq c n^2", "n", "n", "c = 1/100", "mathbf{T}(n)", "Omega(n^2)"], "#text": "From this definition, \nfor all even .\nSo,  for an infinite number of\nvalues of  (i.e., for all even )\nfor .\nTherefore,  is in  by\nthe definition."}, {"title_reference": ["mathbf{T}(n)", "n", "cn", "n", "cn^2", "Omega(n^2)", "Omega(n)", "c", "n_0", "mathbf{T}(n) geq c n^2", "n>n_0", "Omega(n^2)", "Omega"], "#text": "For this equation for , it is true that\nall inputs of size  take at least  time.\nBut an infinite number of inputs of size  take\n time, so we would like to say that the algorithm\nis in .\nUnfortunately, using our first definition will\nyield a lower bound of  because it is not\npossible to pick constants  and  such that\n for all .\nThe alternative definition does result in a lower\nbound of  for this algorithm, which seems to\nfit common sense more closely.\nFortunately, few real algorithms or computer programs display\nthe pathological behavior of this example.\nOur first definition for  generally yields the\nexpected result."}, "As you can see from this discussion, asymptotic bounds notation\nis not a law of nature.\nIt is merely a powerful modeling tool used to describe the\nbehavior of algorithms."], "block_quote": {"paragraph": {"title_reference": ["mathbf{T}(n)", "Omega(g(n))", "c", "mathbf{T}(n) geq c g(n)", "n"], "#text": "is in the set  if\nthere exists a positive constant  such that\n for an infinite number of\nvalues for ."}}, "math_block": {"@xml:space": "preserve", "#text": "\\mathbf{T}(n) = \\left\\{ \\begin{array}{ll}\nn  & \\mbox{for all odd}\\ n \\geq 1\\\\\nn^2/100 & \\mbox{for all even}\\ n \\geq 0\n\\end{array}\n\\right."}}}, {"@ids": "theta-notation", "@names": "theta\\ notation", "title": "Theta Notation", "paragraph": [{"title_reference": ["Omega", "n", "n", "Theta", "Theta(h(n))", "O(h(n))", "Omega(h(n))", "Theta", "Theta", "f(n)", "Theta(g(n))", "g(n)", "Theta(f(n))"], "emphasis": "and", "#text": "The definitions for big-Oh and  give us ways to\ndescribe the upper bound for an algorithm (if we can find an equation\nfor the maximum cost of a particular class of inputs of size\n) and the lower bound for an algorithm\n(if we can find an equation for the minimum cost for\na particular class of inputs of size ).\nWhen the upper and lower bounds are the same within a constant factor,\nwe indicate this by using  (big-Theta) notation.\nAn algorithm is said to be  if it is in\n  it is in .\nNote that we drop the word \"in\" for  notation,\nbecause there is a strict equality for two equations with the\nsame .\nIn other words, if  is , then\n is ."}, {"title_reference": ["O(n)", "Omega(n)", "Theta(n)"], "#text": "Because the sequential search algorithm is both in  and in\n in the average case, we say it is \nin the average case."}, {"title_reference": ["Theta", "NP-Complete <NP-Complete> <LimComp>", "Theta", "Omega"], "#text": "Given an algebraic equation describing the time requirement for\nan algorithm, the upper and lower bounds always meet.\nThat is because in some sense we have a perfect analysis for the\nalgorithm, embodied by the running-time equation.\nFor many algorithms (or their instantiations as programs), it is easy\nto come up with the equation that defines their runtime behavior.\nThe analysis for most commonly used algorithms is well understood and\nwe can almost always give a  analysis for them.\nHowever, the class of \nproblems all have no definitive  analysis, just some\nunsatisfying big-Oh and  analyses.\nEven some \"simple\" programs are hard to analyze.\nNobody currently knows the true upper or lower bounds for the\nfollowing code fragment."}, {"title_reference": ["Theta", "Theta", "Omega", "Theta"], "#text": "While some textbooks and programmers will casually say that an\nalgorithm is \"order of\" or \"big-Oh\" of some cost function,\nit is generally better to use  notation rather than\nbig-Oh notation whenever we have sufficient knowledge about an\nalgorithm to be sure that the upper and lower bounds indeed match.\nOpenDSA modules use  notation in preference to\nbig-Oh notation whenever our state of knowledge makes that possible.\nLimitations on our ability to analyze certain algorithms may require\nuse of big-Oh or  notations.\nIn rare occasions when the discussion is explicitly about the upper or\nlower bound of a problem or algorithm, the corresponding notation will\nbe used in preference to  notation."}], "block_quote": {"raw": {"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}}}, {"@ids": "classifying-functions", "@names": "classifying\\ functions", "title": "Classifying Functions", "paragraph": [{"title_reference": ["f(n)", "g(n)", "n"], "#text": "Given functions  and  whose growth rates are\nexpressed as algebraic equations, we might like to determine if one\ngrows faster than the other.\nThe best way to do this is to take the limit of the two\nfunctions as  grows towards infinity,"}, {"title_reference": ["infty", "f(n)", "Omega(g(n))", "f(n)", "f(n)", "O(g(n))", "g(n)", "f(n) = Theta(g(n))"], "#text": "If the limit goes to , then  is in\n because  grows faster.\nIf the limit goes to zero, then  is in \nbecause  grows faster.\nIf the limit goes to some constant other than zero, then\n because both grow at the same rate."}], "math_block": {"@xml:space": "preserve", "#text": "\\lim_{n \\rightarrow \\infty} \\frac{f(n)}{g(n)}."}, "topic": {"title": "Example", "paragraph": [{"title_reference": ["f(n) = n^2", "g(n) = 2nlog n", "f(n)", "O(g(n))", "Omega(g(n))", "Theta(g(n))"], "#text": "If  and , is  in\n, , or ?\nSince"}, "we easily see that", {"title_reference": ["n", "2log n", "n^2", "Omega(2nlog n)"], "#text": "because  grows faster than .\nThus,  is in ."}], "math_block": [{"@xml:space": "preserve", "#text": "\\frac{n^2}{2n\\log n} = \\frac{n}{2\\log n},"}, {"@xml:space": "preserve", "#text": "\\lim_{n \\rightarrow \\infty} \\frac{n^2}{2n\\log n} = \\infty"}]}, "raw": {"@format": "xml", "@xml:space": "preserve", "inlineav": {"@type": "ss", "@exer_name": "LowerBoundCON", "@long_name": "LowerBoundCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}}, {"@ids": "summary-exercise", "@names": "summary\\ exercise", "title": "Summary Exercise", "raw": [{"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "ka", "@exer_name": "LowerThetaSumm", "@long_name": "LowerThetaSumm", "@points": "1.0", "@required": "True", "@threshold": "5"}}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/AlgAnal/LowerBoundCON.js"}]}]}}