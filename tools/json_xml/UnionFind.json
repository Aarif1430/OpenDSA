{"document": {"@ids": "union-find-and-the-parent-pointer-implementation", "@names": "union/find\\ and\\ the\\ parent\\ pointer\\ implementation", "@source": "<string>", "@title": "Union/Find and the Parent Pointer Implementation", "title": "Union/Find and the Parent Pointer Implementation", "subtitle": {"@ids": "the-union-find-problem", "@names": "the\\ union/find\\ problem", "#text": "The Union/Find Problem"}, "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@xml:space": "preserve", "odsalink": "AV/General/UFCON.css"}], "paragraph": [{"title_reference": ["General trees <general tree>", "internal nodes <internal node>", "children <child>", "binary trees <binary tree>"], "#text": "are trees whose\n have no fixed number of\n.\nCompared to general trees,  are\nrelatively easy to implement because each internal node of a binary\ntree can just store two pointers to reach its (potential) children.\nIn a general tree, we have to deal with the fact that a given node\nmight have no children or few children or many children."}, {"title_reference": ["parent", "parent pointer representation", "FIND"], "strong": "Given two nodes, are they in the same tree?", "#text": "Even in a general tree, each node can have only one .\nIf we didn't need to go from a node to its children, but instead only\nneeded to go from a node to its parent, then implementing a node would\nbe easy.\nA simple way to represent such a general tree would be to store for\neach node only a pointer to that node's parent.\nWe will call this the  for\ngeneral trees.\nClearly this implementation is not general purpose, because it is\ninadequate for such important operations as finding\nthe leftmost child or the right sibling for a node.\nThus, it may seem to be a poor idea to implement a general\ntree in this way.\nHowever, the parent pointer implementation stores precisely the\ninformation required to answer the following, useful question:\n\nTo answer this question, we need only follow the series of parent\npointers from each node to its respective root.\nIf both nodes reach the same root, then they must be in the same tree.\nIf the roots are different, then the two nodes are not in the same\ntree.\nThe process of finding the ultimate root for a given node we will call\n."}], "section": [{"@ids": "parent-pointer-trees", "@names": "parent\\ pointer\\ trees", "title": "Parent Pointer Trees", "paragraph": [{"title_reference": "disjoint sets", "#text": "The parent pointer representation is most often used to maintain a\ncollection of .\nTwo disjoint sets share no members in common (their intersection is\nempty).\nA collection of disjoint sets partitions some objects\nsuch that every object is in exactly one of the disjoint sets.\nThere are two basic operations that we wish to support:"}, {"title_reference": ["UNION", "UNION/FIND"], "#text": "Because two merged sets are united, the merging operation is\ncalled  and the whole process of determining if two\nobjects are in the same set and then merging the sets goes by the name\n."}, "To implement UNION/FIND, we represent each disjoint set with a\nseparate general tree.\nTwo objects are in the same disjoint set if they are in the same tree.\nEvery node of the tree (except for the root) has precisely one parent.\nThus, each node requires the same space to represent it.\nThe collection of objects is typically stored in an array, where each\nelement of the array corresponds to one object, and each element\nstores the object's value (or a pointer to the object).\nThe objects also correspond to nodes in the various disjoint trees\n(one tree for each disjoint set), so we also store the parent value\nwith each object in the array.\nThose nodes that are the roots of their respective trees store an\nappropriate indicator.\nNote that this representation means that a single array is being used\nto implement a collection of trees.\nThis makes it easy to merge trees together with UNION operations.", "Here is an implementation for parent pointer trees and the UNION/FIND\nprocess.", {"literal": ["ParPtrTree", "UNION", "FIND"], "#text": "The  class has an array where each array position\ncorresponds to one object in some collection.\nEach array element stores the array index for its parent.\nThere are two main methods to implement.\nMethod  merges two sets together, where each set corresponds\nto a tree.\nMethod  is used to find the ultimate root for a node."}, {"math": ["n", "n-1"], "literal": ["ParPtrTree", "UNION", "FIND"], "#text": "An application using the UNION/FIND operations\nshould store a set of  objects, where each object is assigned\na unique index in the range 0 to .\nThe indices refer to the corresponding parent pointers in the array.\nClass  creates and initializes the\nUNION/FIND array, and methods  and\n take array indices as inputs."}], "enumerated_list": {"@enumtype": "arabic", "@prefix": "", "@suffix": ".", "list_item": [{"paragraph": "Determine if two objects are in the same set (the FIND operation), and"}, {"paragraph": "Merge two sets together."}]}, "raw": [{"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "xml", "@ids": "uffig", "@names": "uffig", "@xml:space": "preserve", "inlineav": {"@type": "dgm", "@exer_name": "UFfigCON", "@long_name": "UFfigCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}], "target": {"@refid": "uffig"}}, {"@ids": "equivalence-classes", "@names": "equivalence\\ classes", "title": "Equivalence Classes", "paragraph": [{"title_reference": ["equivalence classes <equivalence class>", "equivalence relation <equivalence relation> <SetDef>", "reflexive", "symmetric", "transitive"], "math": ["A", "B", "B", "C", "A", "C", "A", "B", "B", "C", "A", "C"], "#text": "Consider the problem of assigning the members of a set to\ndisjoint subsets called\n.\nRecall that an\n is\n, , and .\nThus, if objects  and  are equivalent, and objects\n and  are equivalent, then we must be able to recognize\nthat objects  and  are also equivalent.\nIn this representation, since  and  are equivalent,\nthey must be in the same tree.\nLikewise for  and .\nWe can recognize that  and  are equivalent because\nthey must also be in the same tree."}, {"math": ["A", "J"], "#text": "There are many practical uses for disjoint sets and representing\nequivalences.\nFor example, consider this graph of ten nodes labeled  through\n."}, {"math": ["A", "I", "J", "A", "H", "E", "J"], "title_reference": "connected component", "#text": "Notice that for nodes  through , there is some\nseries of edges that connects any pair of these nodes, but node\n is disconnected from the rest of the nodes.\nSuch a graph might be used to represent connections such as wires\nbetween components on a circuit board, or roads between cities.\nWe can consider two nodes of the graph to be equivalent if there is a\npath between them.\nThus, nodes , , and  would\nbe considered as equivalent, but  is not\nequivalent to any other.\nA subset of equivalent (connected) edges in a graph is called a\n.\nThe goal is to quickly classify the objects\ninto disjoint sets that correspond to the connected components."}, {"title_reference": ["Kruskal's algorithm", "minimal-cost spanning tree <minimal-cost spanning tree> <MCST>", "graph"], "#text": "Another use for UNION/FIND occurs in  for\ncomputing the\n\nfor a .\nThat algorithm seeks to select the cheapest subset of the edges that\nstill connects all of the nodes in the graph.\nIt does so by processing all edges of the graph from shortest to\nlongest, only adding an edge to the connecting subset if it does not\nconnect two nodes that already have some series of edges connecting\nthem."}, {"math": ["C", "A", "C", "A", "A", "B", "C", "B"], "#text": "The input to the UNION/FIND algorithm is typically  a series of\nequivalence pairs.\nIn the case of the connected components example, the equivalence pairs\nwould simply be the set of edges in the graph.\nAn equivalence pair might say that object  is equivalent to\nobject .\nIf so,  and  are placed in the same subset.\nIf a later equivalence relates  and , then\nby implication  is also equivalent to .\nThus, an equivalence pair may cause two subsets to merge, each of\nwhich contains several objects."}, {"literal": ["FIND", "UNION"], "#text": "Equivalence classes can be managed efficiently with the UNION/FIND\nalgorithm.\nInitially, each object is at the root of its own tree.\nAn equivalence pair is processed by checking to see if both objects\nof the pair are in the same tree by calling   on each of them.\nIf their roots are the same, then no change need be made because the\nobjects are already in the same equivalence class.\nOtherwise, the two equivalence classes should be merged by the\n method."}, "The parent pointer representation places no limit on the number of\nnodes that can share a parent.\nTo make equivalence processing as efficient as possible,\nthe distance from each node to the root of its respective tree should\nbe as small as possible.\nThus, we would like to keep the height of the trees small when merging\ntwo equivalence classes together.\nIdeally, each tree would have all nodes pointing directly to the root.\nAchieving this goal all the time would require too much additional\nprocessing to be worth the effort, so we must settle for getting as\nclose as possible."], "target": {"@refid": "ufconcom"}, "raw": {"@format": "xml", "@ids": "ufconcom", "@names": "ufconcom", "@xml:space": "preserve", "inlineav": {"@type": "dgm", "@exer_name": "UFconcomCON", "@long_name": "UFconcomCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}}, {"@ids": "weighted-union", "@names": "weighted\\ union", "title": "Weighted Union", "paragraph": [{"title_reference": "weighted union rule", "math": ["O(\\log n)", "\\log n", "n"], "#text": "A low-cost approach to reducing the height is to be smart about how\ntwo trees are joined together.\nOne simple technique, called the\n,\njoins the tree with fewer nodes to the tree with more nodes by making\nthe smaller tree's root point to the root of the bigger tree.\nThis will limit the total depth of the tree to ,\nbecause the depth of nodes only in the smaller tree will now increase\nby one, and the depth of the deepest node in the combined tree can\nonly be at most one deeper than the deepest node before the trees were\ncombined.\nThe total number of nodes in the combined tree is therefore at least\ntwice the number in the smaller subtree.\nThus, the depth of any node can be increased at most \ntimes when  equivalences are processed\n(since each addition to the depth must be accompanied by at least\ndoubling the size of the tree)."}, "Here is an implementation for the UNION method when using weighted\nunion.", "The following slideshow illustrates a series of UNION operations with\nweighted union."], "raw": [{"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "xml", "@xml:space": "preserve", "inlineav": {"@type": "ss", "@exer_name": "ufCON", "@long_name": "ufCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}]}, {"@ids": "path-compression", "@names": "path\\ compression", "title": "Path Compression", "paragraph": [{"title_reference": "Path compression <path compression>", "math": ["X", "R", "X", "R", "R", "R", "X", "R", "R"], "literal": "FIND", "#text": "The weighted union rule helps to minimize the depth of the tree, but\nwe can do better than this.\n is a method that tends to\ncreate extremely shallow trees.\nPath compression takes place while finding the root\nfor a given node .\nCall this root .\nPath compression resets the parent of every node on the path from\n to  to point directly to .\nThis can be implemented by first finding .\nA second pass is then made along the path from  to ,\nassigning the parent field of each node encountered to .\nAlternatively, a recursive algorithm can be implemented as follows.\nThis version of  not only returns the root of the\ncurrent node, but also makes all ancestors of the current node point\nto the root."}, "The following slide show illustrates path compression using the last\nstep in the previous example.", "Path compression keeps the cost of each FIND operation very\nclose to constant.", {"math": ["n", "n", "\\Theta(n \\log^* n)", "\\log^* n", "n", "n \\leq 1", "\\log^* 65536", "\\log 65536 = 16, \\log 16 = 4, \\log 4 = 2", "\\log 2 = 1", "\\log^* n", "n", "n"], "emphasis": "very", "#text": "To be more precise about what is meant by \"very close to constant\",\nthe cost of path compression for  FIND operations on\n nodes (when combined with the weighted union rule for\njoining sets) is approximately\n.\nThe notation  means the number of times that\nthe log of  must be taken before .\nFor example,  is 4 because\n, and finally\n.\nThus,  grows  slowly, so the cost for a series\nof  FIND operations is very close to ."}, {"math": ["n", "\\Theta(\\log^* n)", "\\Theta(\\log n)", "n", "\\Theta(n \\log^* n)"], "emphasis": "total", "title_reference": "amortized analysis <amortized analysis> <AmortAnal>", "#text": "Note that this does not mean that the tree resulting from\nprocessing  equivalence pairs necessarily has depth\n.\nOne can devise a series of equivalence operations that yields\n depth for the resulting tree.\nHowever, many of the equivalences in such a series will look only at\nthe roots of the trees being merged, requiring little processing time.\nThe  amount of processing time required for \noperations will be ,\nyielding nearly constant time for each equivalence operation.\nThis is an example of\n."}, {"math": "\\log^* n", "#text": "The expression  is closely related to the inverse of\nAckermann's function.\nFor more information about Ackermann's function and the cost of path\ncompression for UNION/FIND, see .\nThe survey article by Galil & Italiano\ncovers many aspects of the equivalence class problem."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "xml", "@xml:space": "preserve", "inlineav": {"@type": "ss", "@exer_name": "pathcompCON", "@long_name": "pathcompCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}, {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "pe", "@exer_name": "UnionFindPRO", "@long_name": "UnionFindPRO", "@points": "1.0", "@required": "True", "@threshold": "0.9"}}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/General/UFfigCON.js"}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/General/UFconcomCON.js"}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/General/ufCON.js"}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/General/pathcompCON.js"}]}]}}