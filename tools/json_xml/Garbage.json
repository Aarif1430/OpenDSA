{"document": {"@ids": "failure-policies-and-garbage-collection", "@names": "failure\\ policies\\ and\\ garbage\\ collection", "@source": "<string>", "@title": "Failure Policies and Garbage Collection", "title": "Failure Policies and Garbage Collection", "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@ids": "handle", "@names": "handle", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "todo": "null"}, {"@format": "xml", "@ids": "lispex", "@names": "lispex", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@ids": "lispdang", "@names": "lispdang", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "todo": "null"}, {"@format": "xml", "@xml:space": "preserve", "todo": "null"}, {"@format": "xml", "@ids": "dsw", "@names": "dsw", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "todo": "null"}], "paragraph": [{"title_reference": "failure policies <failure policy>", "#text": "At some point during processing, a memory manager could encounter a\nrequest for memory that it cannot satisfy.\nIn some situations, there might be nothing that can be done:\nThere simply might not be enough free memory to service the request,\nand the application may require that the request be serviced\nimmediately.\nIn this case, the memory manager has no option but to return an\nerror, which could in turn lead to a failure of the application\nprogram.\nHowever, in many cases there are alternatives to simply returning an\nerror.\nThe possible options are referred to collectively as\n."}, {"title_reference": "handles <handle>", "#text": "In some cases, there might be sufficient free memory to satisfy the\nrequest, but it is scattered among small blocks.\nThis can happen when using a sequential-fit memory allocation method,\nwhere external fragmentation\nhas led to a series of small blocks\nthat collectively could service the request.\nIn this case, it might be possible to compact memory by moving\nthe reserved blocks around so that the free space is collected into a\nsingle block.\nA problem with this approach is that the application must somehow be\nable to deal with the fact that all of its data have now been moved\nto different locations.\nIf the application program relies on the absolute positions of the\ndata in any way, this would be disastrous.\nOne approach for dealing with this problem is the use of\n.\nA handle is a second level of indirection to a memory location.\nThe memory allocation routine does not return a pointer to the block\nof storage, but rather a pointer to a variable that in turn points to\nthe storage.\nThis variable is the handle.\nThe handle never moves its position, but the position of the block\nmight be moved and the value of the handle updated.\nThis figure illustrates the concept."}, "Another failure policy that might work in some applications is to defer\nthe memory request until sufficient memory becomes available.\nFor example, a multitasking operating system\ncould adopt the strategy of not allowing a process to run until there\nis sufficient memory available.\nWhile such a delay might be annoying to the user, it is better than\nhalting the entire system.\nThe assumption here is that other processes will eventually\nterminate, freeing memory.", {"title_reference": "zoned <zone>", "literal": "new", "#text": "Another option might be to allocate more memory to the memory\nmanager.\nIn a  memory allocation system where the memory\nmanager is part of a larger system, this might be a viable option.\nIn a C++ program that implements its own memory manager, it might be\npossible to get more memory from the system-level  operator,\nsuch as is done by a freelist."}, {"title_reference": "garbage collection", "#text": "The last failure policy that we will consider is\n.\nConsider the following series of statements.:"}, {"literal": ["p", "p", "p"], "title_reference": ["garbage", "memory leak"], "#text": "In some languages, such as C++, this would be considered\nbad form because the original space allocated to \nis lost as a  result of the third assignment.\nThis space cannot be used again by the program.\nSuch lost memory is referred to as , also known as a\n.\nWhen no program variable points to a block of space, no\nfuture access to that space is possible.\nOf course, if another variable had first been assigned to point to\n 's space, then reassigning  would not create garbage."}, {"literal": ["A", "B", "C"], "#text": "Some programming languages take a different view towards garbage.\nIn particular, the LISP programming language uses a multilist\nrepresentation, and all storage is in the form\neither of internal nodes with two pointers or atoms.\nThe figure below shows a typical collection of LISP structures,\nheaded by variables named , , and ,\nalong with a freelist."}, "In LISP, list objects are constantly being put together in\nvarious ways as temporary variables, and then all reference to them\nis lost when the object is no longer needed.\nThus, garbage is normal in LISP, and in fact cannot be\navoided during normal processing.\nWhen LISP runs out of memory, it resorts to a garbage collection\nprocess to recover the space tied up in garbage.\nGarbage collection consists of examining the managed memory\npool to determine which parts are still being used and which parts\nare garbage.\nIn particular, a list is kept of all program variables, and\nany memory locations not reachable from one of these variables are\nconsidered to be garbage.\nWhen the garbage collector executes, all unused memory locations\nare placed in free store for future access.\nThis approach has the advantage that it allows for easy collection of\ngarbage.\nIt has the disadvantage, from a user's point of view, that every so\noften the system must halt while it performs garbage collection.\nFor example, garbage collection is noticeable in the Emacs text\neditor, which is normally implemented in\nLISP.\nOccasionally the user must wait for a moment while the memory\nmanagement system performs garbage collection.", "The Java programming language also makes use of garbage collection.\nAs in LISP, it is common practice in Java to allocate dynamic memory\nas needed, and to later drop all references to that memory.\nThe garbage collector is responsible for reclaiming such unused space\nas necessary.\nThis might require extra time when running the program, but it makes\nlife considerably easier for the programmer.\nIn contrast, many large applications written in C++\n(even commonly used commercial software) contain memory leaks that\nwill in time cause the program to fail.", {"title_reference": "reference count algorithm", "#text": "Several algorithms have been used for garbage collection.\nOne is the .\nHere, every dynamically allocated memory block includes space for a\ncount field.\nWhenever a pointer is directed to a memory block, the reference count\nis increased.\nWhenever a pointer is directed away from a memory block, the reference\ncount is decreased.\nIf the count ever becomes zero, then the memory block is considered\ngarbage and is immediately placed in free store.\nThis approach has the advantage that it does not require an explicit\ngarbage collection phase, because information is put in free store\nimmediately when it becomes garbage."}, "The reference count algorithm is used by the Unix file\nsystem.\nFiles can have multiple names, called links.\nThe file system keeps a count of the number of links to each file.\nWhenever a file is \"deleted\", in actuality its link field is\nsimply reduced by one.\nIf there is another link to the file, then no space is\nrecovered by the file system.\nWhenever the number of links goes to zero, the file's space becomes\navailable for reuse.", "Reference counts have several major disadvantages.\nFirst, a reference count must be maintained for each memory object.\nThis works well when the objects are large, such as a file.\nHowever, it will not work well in a system such as LISP where the\nmemory objects typically consist of two pointers or a value (an atom).\nAnother major problem occurs when garbage contains cycles.\nConsider the figure below.\nHere each memory object is pointed to once, but the collection of\nobjects is still garbage because no pointer points to the collection.\nThus, reference counts only work when the memory objects are linked\ntogether without cycles,\nsuch as the Unix file system where files can only be organized\nas a Directed Acyclic Graph.", {"title_reference": "mark/sweep algorithm", "#text": "Another approach to garbage collection is the\n.\nHere, each memory object needs only a single mark bit rather\nthan a reference counter field.\nWhen free store is exhausted, a separate garbage collection phase\ntakes place as follows."}, "The advantages of the mark/sweep approach are that it needs less\nspace than is necessary for reference counts, and it works for cycles.\nHowever, there is a major disadvantage.\nThis is a \"hidden\" space requirement needed to do the processing.\nDFS is a recursive algorithm:\nEither it must be implemented recursively, in which case the\ncompiler's runtime system maintains a stack,\nor else the memory manager can maintain its own stack.\nWhat happens if all memory is contained in a single linked list?\nThen the depth of the recursion (or the size of the stack) is the\nnumber of memory cells!\nUnfortunately, the space for the DFS stack must be available at the\nworst conceivable time, that is, when free memory has been exhausted.", "Fortunately, a clever technique allows\nDFS to be performed without requiring additional space for a stack.\nInstead, the structure being traversed is used to hold the stack.\nAt each step deeper into the traversal, instead of storing a pointer\non the stack, we \"borrow\" the pointer being followed.\nThis pointer is set to point back to the node we just came from in\nthe previous step, as illustrated by the figure below.\nEach borrowed pointer stores an additional bit to tell us whether we\ncame down the left branch or the right branch of the link node being\npointed to.\nAt any given instant we have passed down only one path from the\nroot, and we can follow the trail of pointers back up.\nAs we return (equivalent to popping the recursion stack), we set the\npointer back to its original position so as to return the\nstructure to its original condition.\nThis is known as the Deutsch-Schorr-Waite garbage\ncollection algorithm."], "target": [{"@refid": "handle"}, {"@refid": "lispex"}, {"@refid": "lispdang"}, {"@refid": "dsw"}], "literal_block": {"@xml:space": "preserve", "#text": "Integer p = new Integer[5];\nInteger q = new Integer[10];\np = q;"}, "enumerated_list": {"@enumtype": "arabic", "@prefix": "", "@suffix": ".", "list_item": [{"paragraph": "Clear all mark bits."}, {"paragraph": "Perform depth-first search (DFS) following pointers from each\nvariable on the system's list of variables.\nEach memory element encountered during the DFS has its mark bit\nturned on."}]}, "definition_list": {"definition_list_item": {"term": ".# A \"sweep\" is made through the memory pool, visiting all elements.", "definition": {"paragraph": "Unmarked elements are considered garbage and placed in\nfree store."}}}}}