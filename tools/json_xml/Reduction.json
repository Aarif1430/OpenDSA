{"document": {"@ids": "reductions", "@names": "reductions", "@source": "<string>", "@title": "Reductions", "title": "Reductions", "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2013 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, {"@format": "xml", "@xml:space": "preserve", "odsalink": "AV/SeniorAlgAnal/ReduceSimpPCON.css"}], "section": [{"@ids": "introduction", "@names": "introduction", "title": "Introduction", "paragraph": [{"title_reference": "reduction", "#text": "This module introduces an important concept for\nunderstanding the relationships between problems, called\n.\nReduction allows us to solve one problem in terms of another.\nEqually importantly, when we wish to understand the difficulty of a\nproblem, reduction allows us to make relative statements about\nupper and lower bounds on the cost of a problem (as opposed to an\nalgorithm or program)."}, "Because the concept of a problem is discussed extensively in this\nchapter, we want notation to simplify problem descriptions.\nThroughout this chapter, a problem will be defined in terms of a\nmapping between inputs and outputs, and the name of the problem will\nbe given in all capital letters.\nThus, a complete definition of the sorting problem could appear as\nfollows:"], "topic": {"title": "SORTING", "paragraph": [{"strong": "Input:", "math": "x_0, x_1, x_2, \\ldots, x_{n-1}", "#text": "A sequence of integers\n."}, {"strong": "Output:", "math": ["y_0, y_1, y_2, \\ldots, y_{n-1}", "y_i \\leq y_j", "i < j"], "#text": "A permutation  of the\nsequence such that  whenever ."}]}}, {"@ids": "example-the-pairing-problem", "@names": "example:\\ the\\ pairing\\ problem", "title": "Example: The Pairing Problem", "paragraph": [{"title_reference": "software reuse", "#text": "When you buy or write a program to solve one problem, such\nas sorting, you might be able to use it to help solve a different\nproblem.\nThis is known in software engineering as .\nTo illustrate this, let us consider another problem."}, {"title_reference": ["Figure #Pair", "reduced <reduction>"], "strong": ["PAIRING", "SORTING"], "#text": "Figure  illustrates PAIRING.\nOne way to solve PAIRING is to use an existing sorting\nprogram to sort each of the two sequences, and then pair off\nitems based on their position in sorted order.\nTechnically we say that in this solution,  is\n to SORTING, because  is used to\nsolve PAIRING."}, {"strong": ["PAIRING", "SORTING", "SORTING", "SORTING", "SORTING", "PAIRING"], "#text": "Notice that reduction is a three-step process.\nThe first step is to convert an instance of\n into two instances of .\nThe conversion step in this example is not very interesting; it simply\ntakes each sequence and assigns it to an array to be passed to\n.\nThe second step is to sort the two arrays (i.e., apply  to\neach array).\nThe third step is to convert the output of  to the output\nfor .\nThis is done by pairing the first elements in the sorted arrays, the\nsecond elements, and so on."}, {"strong": ["PAIRING", "SORTING", "PAIRING", "PAIRING", "SORTING", "SORTING", "PAIRING", "SORTING", "PAIRING", "SORTING", "SORTING", "PAIRING", "PAIRING"], "math": "O(n \\log n)", "#text": "A reduction of  to  helps to establish an upper\nbound on the cost of .\nIn terms of asymptotic notation, assuming that we can find one method\nto convert the inputs to  into inputs to \n\"fast enough\", and a second method to convert the result of\n back to the correct result for  \"fast enough\",\nthen the asymptotic cost of PAIRING cannot be more than the cost of\n.\nIn this case, there is little work to be done to convert from\n to , or to convert the answer from \nback to the answer for , so the dominant cost of this\nsolution is performing the sort operation.\nThus, an upper bound for  is in ."}, {"strong": ["not", "PAIRING", "PAIRING"], "math": "\\Omega(n \\log n)", "#text": "It is important to note that the pairing problem does \nrequire that elements of the two sequences be sorted.\nThis is merely one possible way to solve the problem.\n only requires that the elements of the sequences be paired\ncorrectly.\nPerhaps there is another way to do it?\nCertainly if we use sorting to solve ,\nthe algorithms will require  time.\nBut, another approach might conceivably be faster."}], "topic": {"title": "PAIRING", "paragraph": [{"strong": "Input:", "math": ["X = (x_0, x_1, ..., x_{n-1})", "Y =(y_0, y_1, ..., y_{n-1})"], "#text": "Two sequences of integers\n and\n."}, {"strong": "Output:", "math": ["X", "Y", "X", "Y"], "#text": "A pairing of the elements in the two sequences such that\nthe least value in  is paired with the least value in\n, the next least value in  is paired with the\nnext least value in , and so on."}]}, "target": {"@refid": "pair"}, "raw": [{"@format": "xml", "@ids": "pair", "@names": "pair", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "ss", "@exer_name": "pairToSortReduction", "@long_name": "pairToSortReduction", "@points": "0.0", "@required": "True", "@threshold": "1.0"}}]}, {"@ids": "reduction-and-finding-a-lower-bound", "@names": "reduction\\ and\\ finding\\ a\\ lower\\ bound", "title": "Reduction and Finding a Lower Bound", "paragraph": ["There is another use of reductions aside from applying an old\nalgorithm to solve a new problem (and thereby establishing an upper\nbound for the new problem).\nThat is to prove a lower bound on the cost of a new problem by showing\nthat it could be used as a solution for an old problem with a known\nlower bound.", {"strong": ["SORTING", "PAIRING", "PAIRING", "SORTING"], "title_reference": "lower bound <sorting lower bound> <SortingLowerBound>", "math": ["\\Omega(n \\log n)", "n \\log n"], "#text": "Assume we can go the other way and convert  to \n\"fast enough\".\nWhat does this say about the minimum cost of ?\nWe know that the\n\nfor  in the worst and average cases is\nin .\nIn other words, the best possible algorithm for sorting requires at\nleast  time."}, {"math": ["O(n)", "O(n)", "O(n)", "O(n)", "\\Omega(n \\log n)"], "strong": ["SORTING", "PAIRING", "PAIRING", "SORTING", "SORTING", "PAIRING", "PAIRING", "PAIRING", "SORTING"], "#text": "Assume that PAIRING could be done in  time.\nThen, one way to create a sorting algorithm would be to convert\n into , run the algorithm for ,\nand finally convert the answer back to the answer for .\nProvided that we can convert SORTING to/from PAIRING \"fast enough\",\nthis process would yield an  algorithm for sorting!\nBecause this contradicts what we know about the lower bound for\n, and the only flaw in the reasoning is the initial\nassumption that  can be done in  time, we can\nconclude that there is no  time algorithm for\n.\nThis reduction process tells us that  must be at least as\nexpensive as  and so must itself have a lower bound in\n."}, {"strong": ["PAIRING", "SORTING", "PAIRING", "PAIRING", "SORTING", "PAIRING", "PAIRING", "SORTING", "PAIRING"], "math": ["A", "n", "B", "i", "i", "0 \\leq i < n", "B", "A", "A", "B", "\\Theta(n)", "O(n)", "O(n)"], "title_reference": "Binsort <Binsort> <BinSort>", "#text": "To complete this proof regarding the lower bound for , we\nneed now to find a way to reduce  to .\nThis is easily done.\nTake an instance of SORTING (i.e., an array  of \nelements).\nA second array  is generated that simply stores  in\nposition  for .\nPass the two arrays to .\nTake the resulting set of pairs, and use the value from the \nhalf of the pair to tell which position in the sorted array the\n half should take; that is, we can now reorder the records in\nthe  array using the corresponding value in the \narray as the sort key and running a simple\n\n.\nThe conversion of  to  can be done in\n time, and likewise the conversion of the output of\n can be converted to the correct output for  in\n time.\nThus, the cost of this \"sorting algorithm\" is dominated by the cost\nfor ."}]}, {"@ids": "the-reduction-template", "@names": "the\\ reduction\\ template", "title": "The Reduction Template", "paragraph": [{"strong": ["I", "I", "SLN", "I'", "I'", "SLN'"], "#text": "Consider any two problems for which a suitable reduction from one to\nthe other can be found.\nThe first problem takes an arbitrary instance of its input, which\nwe will call , and transforms  to a solution, which\nwe will call .\nThe second problem takes an arbitrary instance of its input, which\nwe will call , and transforms  to a solution,\nwhich we will call .\nWe can define reduction more formally as a three-step process:"}, {"title_reference": "Figure #BlackBox", "strong": ["SORTING", "PAIRING"], "#text": "Figure  shows a graphical representation of the\ngeneral reduction process, showing the role of the two problems, and\nthe two transformations.\nNext is a slideshow that shows the steps for\nthe reduction of  to ."}, "It is important to note that the reduction process does not give us\nan algorithm for solving either problem by itself.\nIt merely gives us a method for solving the first problem given that\nwe already have a solution to the second.\nMore importantly for the topics to be discussed in the remainder of\nthis chapter, reduction gives us a way to understand the bounds of\none problem in terms of another.\nSpecifically, given efficient transformations,\nthe upper bound of the first problem is at most the upper bound of\nthe second.\nConversely, the lower bound of the second problem is at least the\nlower bound of the first."], "enumerated_list": {"@enumtype": "arabic", "@prefix": "", "@suffix": ".", "list_item": [{"paragraph": {"strong": ["I", "I'"], "#text": "Transform an arbitrary instance of the first problem to an\ninstance of the second problem.\nIn other words, there must be a transformation from any instance\n of the first problem to an instance  of the\nsecond problem."}}, {"paragraph": {"strong": ["I'", "SLN'"], "#text": "Apply an algorithm for the second problem to the instance\n, yielding a solution ."}}, {"paragraph": {"strong": ["SLN'", "I", "SLN", "SLN", "I"], "#text": "Transform  to the solution of , known as .\nNote that  must in fact be the correct solution for \nfor the reduction to be acceptable."}}]}, "target": {"@refid": "blackbox"}, "raw": [{"@format": "xml", "@ids": "blackbox", "@names": "blackbox", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "ss", "@exer_name": "sortToPairReduction", "@long_name": "sortToPairReduction", "@points": "0.0", "@required": "True", "@threshold": "1.0"}}]}, {"@ids": "two-multiplication-examples", "@names": "two\\ multiplication\\ examples", "title": "Two Multiplication Examples", "paragraph": [{"math": ["n", "\\Theta(n)", "\\Theta(n)", "n", "M", "N", "\\Theta(M + N)", "\\Theta(n^2)", "O(n)"], "#text": "As a second example of reduction, consider the simple problem of\nmultiplying two -digit numbers.\nThe standard long-hand method for multiplication is to multiply the\nlast digit of the first number by the second number\n(taking  time), multiply the second digit of the\nfirst number by the second number (again taking \ntime), and so on for each of the  digits of the first\nnumber.\nFinally, the intermediate results are added together.\nNote that adding two numbers of length  and  can\neasily be done in  time.\nBecause each digit of the first number is multiplied against each\ndigit of the second, this algorithm requires \ntime.\nAsymptotically faster (but more complicated) algorithms are known, but\nnone is so fast as to be in ."}, {"math": ["n", "n"], "#text": "Next we ask the question:\nIs squaring an -digit number as difficult as multiplying two\n-digit numbers?\nWe might hope that something about this special case will allow for a\nfaster algorithm than is required by the more general multiplication\nproblem.\nHowever, a simple reduction proof serves to show that squaring is\n\"as hard\" as multiplying."}, "The key to the reduction is the following formula:", "The significance of this formula is that it allows us to\nconvert an arbitrary instance of multiplication to a series of\noperations involving three addition/subtractions (each of which can be\ndone in linear time), two squarings, and a division by 4.\nThis is because", "Note that the division by 4 can be done in linear time (simply convert\nto binary, shift right by two digits, and convert back).\nThis reduction shows that if a linear time algorithm for squaring can\nbe found, it can be used to construct a linear time algorithm for\nmultiplication.", {"math": ["n \\times n", "\\Theta(n)", "n^2", "\\Theta(n^3)", "O(n^2)"], "literal": "int", "title_reference": "Strassen's algorithm <Strassen's algorithm> <Strassen>", "#text": "Our next example of reduction concerns the multiplication of two\n matrices.\nFor this problem, we will assume that the values stored in the\nmatrices are simple integers and that multiplying two simple integers\ntakes constant time (because multiplication of two \nvariables takes a fixed number of machine instructions).\nThe standard algorithm for multiplying two matrices is to multiply\neach element of the first matrix's first row by the corresponding\nelement of the second matrix's first column, then adding the numbers.\nThis takes  time.\nEach of the  elements of the solution are computed in\nsimilar fashion, requiring a total of  time.\nFaster algorithms are known\n(see ),\nbut none are so fast as to be in ."}, {"title_reference": "symmetric matrices <symmetric matrix>", "math": ["ij", "ji", "n \\times n", "A", "B", "2n \\times 2n", "A"], "#text": "Now, consider the case of multiplying two\n.\nA symmetric matrix is one in which entry  is equal to entry\n; that is, the upper-right triangle of the matrix is a\nmirror image of the lower-left triangle.\nIs there something about this restricted case that allows us to\nmultiply two symmetric matrices faster than in the general case?\nThe answer is no, as can be seen by the following reduction.\nAssume that we have been given two  matrices\n and .\nWe can construct a  symmetric matrix from an\narbitrary matrix  as follows:"}, {"math": ["n \\times n", "A", "A^{\\rm T}", "A"], "footnote_reference": {"@auto": "1", "@ids": "id1", "@refid": "id2", "#text": "1"}, "#text": "Here 0 stands for an  matrix composed of zero\nvalues,  is the original matrix, and  stands\nfor the transpose of matrix ."}, {"math": ["B", "\\Theta(n^2)", "n \\times n", "\\Theta(n^2)"], "#text": "Note that the resulting matrix is now symmetric.\nWe can convert matrix  to a symmetric matrix in a similar\nmanner.\nIf symmetric matrices could be multiplied \"quickly\" (in particular,\nif they could be multiplied together in  time),\nthen we could find the result of multiplying two arbitrary\n matrices in  time by taking\nadvantage of the following observation:"}, {"math": ["AB", "A", "B"], "#text": "In the above formula,  is the result of multiplying\nmatrices  and  together."}, "The following slideshow illustrates this reduction process."], "math_block": [{"@xml:space": "preserve", "#text": "X \\times Y = \\frac{(X + Y)^2 - (X - Y)^2}{4}."}, {"@xml:space": "preserve", "#text": "(X + Y)^2 - (X - Y)^2 = X^2 + 2XY + Y^2 - (X^2 - 2XY + Y^2) = 4XY"}, {"@xml:space": "preserve", "#text": "\\left[\n\\begin{array}{cc}\n0 &A\\\\\nA^{\\rm T}& 0\n\\end{array}\n\\right]."}, {"@xml:space": "preserve", "#text": "\\left[\n\\begin{array}{cc}\n0&A\\\\\nA^{\\rm T}&0\n\\end{array}\n\\right]\n\\left[\n\\begin{array}{cc}\n0&B^{\\rm T}\\\\\nB&0\n\\end{array}\n\\right] =\n\\left[\n\\begin{array}{cc}\nAB&0\\\\\n0&A^{\\rm T}B^{\\rm T}\n\\end{array}\n\\right]."}], "raw": {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "ss", "@exer_name": "matrixMulReduction", "@long_name": "matrixMulReduction", "@points": "0.0", "@required": "True", "@threshold": "1.0"}}, "footnote": {"@auto": "1", "@backrefs": "id1", "@ids": "id2", "@names": "1", "label": "1", "paragraph": {"math": ["ij", "ji", "n^2", "n \\times n"], "#text": "The transpose operation\ntakes position  of the original matrix and places it\nin position  of the transpose matrix.\nThis can easily be done in  time for an\n matrix."}}}, {"@ids": "bounds-theorems", "@names": "bounds\\ theorems", "title": "Bounds Theorems", "paragraph": [{"math": ["\\leq_{O(g(n))}", "O(g(n))"], "#text": "We will use the following notation:\n means that a reduction can be done\nwith transformations that cost ."}, {"strong": "Lower Bound Theorem}", "math": ["P_1 \\leq_{O(g(n))} P_2", "\\Omega(h(n))", "P_1", "g(n) = o(h(n))", "\\Omega(h(n))", "P_2"], "#text": ": If ,\nthen there is a lower bound of  on the time\ncomplexity of , and ,\nthen there is a lower bound of  on\n.\n(Notice little-oh, not big-Oh.)"}, {"math": ["\\leq_{O(n)}", "g(n) = n", "h(n) = n \\log n", "g(n) = o(h(n))", "\\Omega(n \\log n)"], "#text": "Example:\nSORTING  PAIRING, because\n, , and\n.\nThe Lower Bound Theorem gives us an \nlower bound on PAIRING."}, "This also goes the other way.", {"strong": "Upper Bound Theorem", "math": ["P_2", "O(h(n))", "P_1 \\leq_{O(g(n))} P_2", "P_1", "O(g(n) + h(n))"], "#text": ": If  has time complexity\n and , then\n has time complexity ."}, {"math": ["\\Omega(P_1)", "O(P_2)"], "#text": "So, given good transformations, both problems take at least\n and at most ."}]}, {"@ids": "the-cost-of-making-a-simple-polygon", "@names": "the\\ cost\\ of\\ making\\ a\\ simple\\ polygon", "title": "The Cost of Making a Simple Polygon", "paragraph": [{"math": ["n", "\\leq_{O(n)}"], "#text": "SIMPLE POLYGON: Given a set of  points in the plane,\nfind a simple polygon with those points as vertices.\n(Here, \"simple\" means that no lines cross.)\nWe will show that SORTING  SIMPLE POLYGON."}, {"math": ["\\{x_1, x_2, \\cdots, x_n\\}", "M = \\max|x_i|", "C", "M"], "#text": "We start with an instance of SORTING: .\nIn linear time, find .\nLet  be a circle centered at the origin, of radius ."}, "We will generate an instance of SIMPLE POLYGON by replacing each value\nin the array to be sorted with a corresponding point defined as", {"math": ["C", "C", "\\Omega(n \\log n)"], "#text": "It is an important fact that all of these points fall on .\nFurthermore, when we find a simple polygon, the points all fall along\nthe circle in sort order.\nThis is because\nthe only simple polygon having all of its points on  as\nvertices is the convex one.\nTherefore, by the Lower Bound Theorem, SIMPLE POLYGON is in\n."}], "math_block": {"@xml:space": "preserve", "#text": "\\{(x_1, \\sqrt{M^2 - x_i^2}), \\cdots, (x_n, \\sqrt{M^2 - x_n^2})\\}."}, "raw": [{"@format": "xml", "@xml:space": "preserve", "inlineav": {"@type": "dgm", "@exer_name": "ReduceSimpPCON", "@long_name": "ReduceSimpPCON", "@points": "0", "@required": "True", "@threshold": "1.0"}}, {"@format": "xml", "@xml:space": "preserve", "odsascript": "AV/SeniorAlgAnal/ReduceSimpPCON.js"}]}]}}