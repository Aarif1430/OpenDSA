{"document": {"@dupnames": "b-trees", "@ids": "b-trees", "@source": "<string>", "@title": "B-Trees", "title": "B-Trees", "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2013 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": {"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, "section": [{"@dupnames": "b-trees", "@ids": "id1", "title": "B-Trees", "paragraph": [{"emphasis": "the", "#text": "This section presents the B-tree.\nB-trees are usually attributed to R. Bayer and E. McCreight\nwho described the B-tree in a 1972 paper.\nBy 1979, B-trees had replaced virtually all large-file access\nmethods other than hashing.\nB-trees, or some variant of B-trees, are  standard file\norganization for applications requiring insertion, deletion, and key\nrange searches.\nThey are used to implement most modern file systems.\nB-trees address effectively all of the major problems encountered\nwhen implementing disk-based search trees:"}, {"title_reference": "m", "#text": "A B-tree of order  is defined to have\nthe following shape properties:"}, {"title_reference": ["buffer pool <buffer pool> <BuffPool>", "LRU"], "#text": "The B-tree  is a generalization of the 2-3 tree.\nPut another way, a 2-3 tree is a B-tree of order three.\nNormally, the size of a node in the B-tree is chosen to fill a disk\nblock.\nA B-tree node implementation typically allows 100 or more children.\nThus, a B-tree node is equivalent to a disk block, and a \"pointer\"\nvalue stored in the tree is actually the number of the block\ncontaining the child node (usually interpreted as an offset from the\nbeginning of the corresponding disk file).\nIn a typical application, the B-tree's access to the disk file will be\nmanaged using a \nand a block-replacement scheme such as ."}, {"title_reference": "Figure #BTexamp", "#text": "Figure  shows a B-tree of order four.\nEach node contains up to three keys, and\ninternal nodes have up to four children."}, "Search in a B-tree is a generalization of search in a 2-3 tree.\nIt is an alternating two-step process, beginning with the root node of\nthe B-tree.", {"title_reference": "Figure #BTexamp", "#text": "For example, consider a search for the record with key value 47 in the\ntree of Figure .\nThe root node is examined and the second (right) branch taken.\nAfter examining the node at level 1, the third branch is taken to the\nnext level to arrive at the leaf node containing a record with key\nvalue 47."}, "B-tree insertion is a generalization of 2-3 tree insertion.\nThe first step is to find the leaf node that should contain the\nkey to be inserted, space permitting.\nIf there is room in this node, then insert the key.\nIf there is not, then split the node into two and promote the middle\nkey to the parent.\nIf the parent becomes full, then it is split in turn, and its middle\nkey promoted.", "Note that this insertion process is guaranteed to keep all nodes at\nleast half full.\nFor example, when we attempt to insert into a full internal node of a\nB-tree  of order four, there will now be five children that must be\ndealt with.\nThe node is split into two nodes containing two keys each, thus\nretaining the B-tree property.\nThe middle of the five children is promoted to its parent."], "enumerated_list": [{"@enumtype": "arabic", "@prefix": "", "@suffix": ".", "list_item": [{"paragraph": "B-trees are always height balanced, with all leaf nodes at the same\nlevel."}, {"paragraph": "Update and search operations affect only a few disk blocks.\nThe fewer the number of disk blocks affected, the less disk I/O is\nrequired."}, {"paragraph": "B-trees keep related records (that is, records with similar key\nvalues) on the same disk block, which helps to minimize disk I/O on\nsearches due to locality of reference."}, {"paragraph": "B-trees  guarantee that every node in the tree will be\nfull at least to a certain minimum percentage.\nThis improves space efficiency while reducing the typical number of\ndisk fetches necessary during a search or update operation."}]}, {"@enumtype": "arabic", "@prefix": "", "@suffix": ".", "list_item": [{"paragraph": "Perform a binary search on the records in the\ncurrent node.\nIf a record with the search key is found, then return that record.\nIf the current node is a leaf node and the key is not found,\nthen report an unsuccessful search."}, {"paragraph": "Otherwise, follow the proper branch and repeat the process."}]}], "bullet_list": {"@bullet": "*", "list_item": [{"paragraph": "The root is either a leaf or has at least two children."}, {"paragraph": {"title_reference": ["lceil m/2 rceil", "m"], "#text": "Each internal node, except for the root, has between\n and  children."}}, {"paragraph": "All leaves are at the same level in the tree, so the tree is always\nheight balanced."}]}, "target": {"@refid": "btexamp"}, "raw": {"@format": "xml", "@ids": "btexamp", "@names": "btexamp", "@xml:space": "preserve", "odsafig": "null"}}, {"@ids": "id2", "@names": "b+\\ trees", "title": "B+ Trees", "paragraph": [{"title_reference": ["mathrm{B}^+", "mathrm{B}^*"], "#text": "The previous section mentioned that B-trees are universally used\nto implement large-scale disk-based systems.\nActually, the B-tree as described in the previous section is almost\nnever implemented.\nWhat is most commonly implemented is a variant of the B-tree,\ncalled the  tree.\nWhen greater efficiency is required, a more complicated\nvariant known as the  tree is used."}, {"title_reference": ["linear index", "mathrm{B}^+", "mathrm{B}^+"], "#text": "Consider again the .\nWhen the collection of records will not change, a linear index\nprovides an extremely efficient way to search.\nThe problem is how to handle those pesky inserts and deletes.\nWe could try to keep the core idea of storing a sorted array-based\nlist, but make it more flexible by breaking the list into manageable\nchunks that are more easily updated.\nHow might we do that?\nFirst, we need to decide how big the chunks should be.\nSince the data are on disk, it seems reasonable to store a chunk that\nis the size of a disk block, or a small multiple of the disk block\nsize.\nIf the next record to be inserted belongs to a chunk that hasn't\nfilled its block then we can just insert it there.\nThe fact that this might cause other records in that chunk to move a\nlittle bit in the array is not important, since this does not cause\nany extra disk accesses so long as we move data within that chunk.\nBut what if the chunk fills up the entire block that contains it?\nWe could just split it in half.\nWhat if we want to delete a record?\nWe could just take the deleted record out of the chunk, but we might\nnot want a lot of near-empty chunks.\nSo we could put adjacent chunks together if they have only a small\namount of data between them.\nOr we could shuffle data between adjacent chunks that together contain\nmore data.\nThe big problem would be how to find the desired chunk when processing\na record with a given key.\nPerhaps some sort of tree-like structure could be used to locate the\nappropriate chunk.\nThese ideas are exactly what motivate the  tree.\nThe  tree is essentially a mechanism for managing a sorted\narray-based list, where the list is broken into chunks."}, {"title_reference": ["mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^+", "m", "m", "mathrm{B}^+", "mathrm{B}^+"], "#text": "The most significant difference between the  tree\nand the BST or the standard B-tree is that\nthe  tree  stores records only at the leaf nodes.\nInternal nodes store key values, but these\nare used solely as placeholders to guide the search.\nThis means that internal nodes are significantly different in\nstructure from leaf nodes.\nInternal nodes store keys to guide the search, associating each key\nwith a pointer to a child  tree node.\nLeaf nodes store actual records, or else keys and pointers to actual\nrecords in a separate disk file if the  tree is\nbeing used purely as an index.\nDepending on the size of a record as compared to the size of a key,\na leaf node in a  tree of order  might\nhave enough room to store more or less than  records.\nThe requirement is simply that the leaf nodes store enough records to\nremain at least half full.\nThe leaf nodes of a  tree are normally\nlinked together to form a doubly linked list.\nThus, the entire collection of records can be traversed in sorted\norder by visiting all the leaf nodes on the linked list.\nHere is a Java-like pseudocode representation for the\n tree node interface.\nLeaf node and internal node subclasses would implement this interface."}, {"title_reference": ["Figure #BTexamp", "Figure #BTexamp", "mathrm{B}^+", "mathrm{B}^+"], "literal": "BPNode", "#text": "An important implementation detail to note is that while\nFigure  shows internal nodes containing three\nkeys and four pointers, class  is slightly different in that\nit stores key/pointer pairs.\nFigure  shows the  tree as\nit is traditionally drawn.\nTo simplify implementation in practice, nodes really do\nassociate a key with each pointer.\nEach internal node should be assumed to hold in the leftmost position\nan additional key that is less than or equal to any possible key value\nin the node's leftmost subtree.\n tree implementations typically store an\nadditional dummy record in the leftmost leaf node whose key value is\nless than any legal key value."}, {"title_reference": ["mathrm{B}^+", "Figure #BPexamp", "mathrm{B}^+"], "#text": "trees are exceptionally good for range queries.\nOnce the first record in the range has been found, the rest of the\nrecords with keys in the range can be accessed by sequential\nprocessing of the remaining records in the first node, and then\ncontinuing down the linked list of leaf nodes as far as necessary.\nFigure  illustrates the \ntree."}, {"title_reference": ["mathrm{B}^+", "mathrm{B}^+", "Figure #BPexamp", "mathrm{B}^+"], "#text": "Search in a  tree is nearly identical to search in\na regular B-tree, except that the search must always continue to the\nproper leaf node.\nEven if the search-key value is found in an internal node, this is\nonly a placeholder and does not provide access to the actual record.\nTo find a record with key value 33 in the  tree of\nFigure , search begins at the root.\nThe value 33 stored in the root merely serves as a placeholder,\nindicating that keys with values greater than or equal to 33 are found\nin the second subtree.\nFrom the second child of the root, the first branch is taken to reach\nthe leaf node containing the actual record (or a pointer to the actual\nrecord) with key value 33.\nHere is a pseudocode sketch of the  tree search\nalgorithm."}, {"title_reference": ["mathrm{B}^+", "L", "L", "mathrm{B}^+", "L", "mathrm{B}^+", "mathrm{B}^+", "Figure #BPins"], "#text": "tree insertion is similar to B-tree insertion.\nFirst, the leaf  that should contain the record is found.\nIf  is not full, then the new record is added, and no\nother  tree nodes are affected.\nIf  is already full, split it in two (dividing the records\nevenly among the two nodes) and promote a copy of the\nleast-valued key in the newly formed right node.\nAs with the 2-3 tree, promotion might cause\nthe parent to split in turn, perhaps eventually leading to splitting\nthe root and causing the  tree to gain a new\nlevel.\n tree insertion keeps all leaf nodes at equal\ndepth.\nFigure  illustrates the insertion process through\nseveral examples."}, {"title_reference": "mathrm{B}^+", "#text": "Here is a a Java-like pseudocode sketch of the \ntree insert algorithm."}, {"title_reference": "mathrm{B}^+", "#text": "Here is an exercise to see if you get the basic idea of\n tree insertion."}, {"title_reference": ["R", "mathrm{B}^+", "L", "R", "L", "R", "L", "Figure #BPdelsimp"], "#text": "To delete record  from the  tree,\nfirst locate the leaf  that contains .\nIf  is more than half full, then we need only remove ,\nleaving  still at least half full.\nThis is demonstrated by Figure ."}, {"title_reference": ["underflow", "Figure #BPborrow"], "#text": "If deleting a record reduces the number of records in the node below\nthe minimum threshold (called an ), then we must do\nsomething to keep the node sufficiently full.\nThe first choice is to look at the node's adjacent siblings to\ndetermine if they have a spare record that can be used to fill the\ngap.\nIf so, then enough records are transferred from the\nsibling so that both nodes have about the same number of records.\nThis is done so as to delay as long as possible the next time when a\ndelete causes this node to underflow again.\nThis process might require that the parent node has its placeholder\nkey value revised to reflect the true first key value in each node.\nFigure  illustrates the process."}, {"title_reference": ["N", "N", "N", "Figure #BPmerge"], "#text": "If neither sibling can lend a record to the under-full node\n(call it ),\nthen  must give its records to a sibling and be removed\nfrom the tree.\nThere is certainly room to do this, because the sibling is at most\nhalf full (remember that it had no records to contribute to the\ncurrent node), and  has become less than half full because it\nis under-flowing.\nThis merge process combines two subtrees of the parent, which might\ncause it to underflow in turn.\nIf the last two children of the root merge together, then the tree\nloses a level.\nFigure  illustrates the node-merge deletion\nprocess."}, {"title_reference": "mathrm{B}^+", "#text": "Here is a Java-like pseudocode for the  tree\ndelete algorithm."}, {"title_reference": ["mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^*", "mathrm{B}^*", "mathrm{B}^+", "mathrm{B}^*"], "#text": "The  tree requires that all nodes be at least half\nfull (except for the root).\nThus, the storage utilization must be at least 50%.\nThis is satisfactory for many implementations, but note that keeping\nnodes fuller will result both in\nless space required (because there is less empty space in the disk file)\nand in more efficient processing (fewer blocks on average will be read\ninto memory because the amount of information in each block is greater).\nBecause B-trees have become so popular, many algorithm designers have\ntried to improve B-tree performance.\nOne method for doing so is to use the  tree\nvariant known as the  tree.\nThe  tree is identical to the \ntree, except for the rules used to split and merge nodes.\nInstead of splitting a node in half when it overflows, the\n tree\ngives some records to its neighboring sibling, if possible.\nIf the sibling is also full, then these two nodes split into three.\nSimilarly, when a node underflows, it is combined with its two\nsiblings, and the total reduced to two nodes.\nThus, the nodes are always at least two thirds full."}, {"title_reference": "mathrm{B}^+", "#text": "Here is a visualization for the  tree."}, {"raw": {"@format": "html", "@xml:space": "preserve", "#text": "<a href=\"http://www.cs.usfca.edu/~galles/visualization/Algorithms.html\" target=\"_blank\">Data Structure Visualizations</a>"}, "#text": "This visualization was written by David Galles of the University of\nSan Francisco as part of his  package."}], "raw": [{"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "xml", "@ids": "bpexamp", "@names": "bpexamp", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "xml", "@ids": "bpins", "@names": "bpins", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "xml", "@xml:space": "preserve", "avembed": {"@type": "pe", "@exer_name": "bPlusTreeInsertPRO", "@long_name": "bPlusTreeInsertPRO", "@points": "1.0", "@required": "True", "@threshold": "0.9"}}, {"@format": "xml", "@ids": "bpdelsimp", "@names": "bpdelsimp", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@ids": "bpborrow", "@names": "bpborrow", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@ids": "bpmerge", "@names": "bpmerge", "@xml:space": "preserve", "odsafig": "null"}, {"@format": "xml", "@xml:space": "preserve", "codeinclude": "null"}, {"@format": "html", "@xml:space": "preserve", "#text": "<center>\n<iframe id=\"BT_iframe\"\n     src=\"//www.cs.usfca.edu/~galles/visualization/BPlusTree.html\"\n     width=\"1100\" height=\"800\"\n     frameborder=\"1\" marginwidth=\"0\" marginheight=\"0\"\n     scrolling=\"no\">\n</iframe>\n</center>"}], "target": [{"@refid": "bpexamp"}, {"@refid": "bpins"}, {"@refid": "bpdelsimp"}, {"@refid": "bpborrow"}, {"@refid": "bpmerge"}], "substitution_definition": {"@names": "external_link", "raw": {"@format": "html", "@xml:space": "preserve", "#text": "<a href=\"http://www.cs.usfca.edu/~galles/visualization/Algorithms.html\" target=\"_blank\">Data Structure Visualizations</a>"}}, "footnote": {"@auto": "1", "@ids": "id3", "@names": "1", "label": "1", "paragraph": {"title_reference": "mathrm{B}^*", "#text": "This concept can be extended further if higher space\nutilization is required.\nHowever, the update routines become much more complicated.\nI once worked on a project where we implemented 3-for-4 node\nsplit and merge routines.\nThis gave better performance than the 2-for-3 node split and\nmerge routines of the  tree.\nHowever, the spitting and merging routines were so complicated\nthat even their author could no longer understand them\nonce they were completed!"}}}, {"@ids": "b-tree-analysis", "@names": "b-tree\\ analysis", "title": "B-Tree Analysis", "paragraph": [{"title_reference": ["mathrm{B}^+", "mathrm{B}^*", "Theta(log n)", "n"], "#text": "The asymptotic cost of search, insertion, and deletion of\nrecords from B-trees,  trees, and\n trees is \nwhere  is the total number of records in the tree.\nHowever, the base of the log is the (average) branching factor of the\ntree.\nTypical database applications use extremely high branching factors,\nperhaps 100 or more.\nThus, in practice the B-tree and its variants are extremely shallow."}, {"title_reference": ["mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^+", "mathrm{B}^+"], "emphasis": "extremely", "#text": "As an illustration, consider a  tree of order 100\nand leaf nodes that contain up to 100 records.\nA B- tree with height one (that is, just a single\nleaf node) can have at most 100 records.\nA  tree with height two (a root internal node\nwhose children are leaves) must have at least 100 records\n(2 leaves with 50 records each).\nIt has at most 10,000 records (100 leaves with 100 records each).\nA  tree with height three must have at least 5000\nrecords (two second-level nodes with 50 children containing 50 records\neach) and at most one million records (100 second-level nodes with 100\nfull children each).\nA  tree with height four must have at least\n250,000 records and at most 100 million records.\nThus, it would require an  large database to generate\na  tree of more than height four."}, {"title_reference": ["mathrm{B}^+", "K-ary tree <K-ary tree> <Kary>", "1/K", "mathrm{B}^+", "1/75"], "#text": "The  tree split and insert rules guarantee that\nevery node (except perhaps the root) is at least half full.\nSo they are on average about 3/4 full.\nBut the internal nodes are purely overhead, since the keys stored\nthere are used only by the tree to direct search, rather than store\nactual data.\nDoes this overhead amount to a significant use of space?\nNo, because once again the high fan-out rate of the tree structure\nmeans that the vast majority of nodes are leaf nodes.\nA  has\napproximately  of its nodes as internal nodes.\nThis means that while half of a full binary tree's nodes are internal\nnodes, in a  tree of order 100 probably only about\n of its nodes are internal nodes.\nThis means that the overhead associated with internal nodes is very\nlow."}, "We can reduce the number of disk fetches required for the B-tree\neven more by using the following methods.\nFirst, the upper levels of the tree can be stored in main memory at all\ntimes.\nBecause the tree branches so quickly, the top two levels\n(levels 0 and 1) require relatively little space.\nIf the B-tree is only height four, then at most two disk fetches\n(internal nodes at level two and leaves at level three) are required\nto reach the pointer to any given record.", "A buffer pool could be used to manage nodes of the B-tree.\nSeveral nodes of the tree would typically be in main memory at one\ntime.\nThe most straightforward approach is to use a standard method such as\nLRU to do node replacement.\nHowever, sometimes it might be desirable to \"lock\" certain nodes\nsuch as the root into the buffer pool.\nIn general, if the buffer pool is even of modest size (say at least\ntwice the depth of the tree), no special techniques for node\nreplacement will be required because the upper-level nodes will\nnaturally be accessed frequently."]}]}}