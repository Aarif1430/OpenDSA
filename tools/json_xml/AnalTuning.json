{"document": {"@ids": "code-tuning-and-empirical-analysis", "@names": "code\\ tuning\\ and\\ empirical\\ analysis", "@source": "<string>", "@title": "Code Tuning and Empirical Analysis", "title": "Code Tuning and Empirical Analysis", "comment": [{"@xml:space": "preserve", "#text": "This file is part of the OpenDSA eTextbook project. See"}, {"@xml:space": "preserve", "#text": "http://algoviz.org/OpenDSA for more details."}, {"@xml:space": "preserve", "#text": "Copyright (c) 2012-2016 by the OpenDSA Project Contributors, and"}, {"@xml:space": "preserve", "#text": "distributed under an MIT open source license."}], "raw": {"@format": "xml", "@xml:space": "preserve", "avmetadata": "null"}, "section": [{"@ids": "introduction", "@names": "introduction", "title": "Introduction", "paragraph": [{"math": ["\\Theta(n)", "\\Theta(n \\log n)", "\\Theta(n \\log n)", "\\Theta(n^2)", "\\Theta(n^2)", "\\Theta(n \\log n)"], "#text": "In practice, there is not such a big difference in running time\nbetween an algorithm with growth rate  and another\nwith growth rate .\nThere is, however, an enormous difference in running time between\nalgorithms with growth rates of  and\n.\nAs you shall see during the course of your study of common data\nstructures and algorithms, there are many problems\nwhose obvious solution requires  time,\nbut that also have a solution requiring \ntime.\nExamples include sorting and searching, two of the most important\ncomputer problems."}, "While not nearly so important as changing an algorithm to reduce\nits growth rate, \"code tuning\" can also lead to dramatic\nimprovements in running time.\nCode tuning is the art of hand-optimizing a program to run faster\nor require less storage.\nFor many programs, code tuning can reduce running time or cut the\nstorage requirements by a factor of two or more.\nEven speedups by a factor of five to ten are not uncommon.\nOccasionally, you can get an even bigger speedup\nby converting from a symbolic representation of the data\nto a numeric coding scheme on which you can do direct computation.", "Here are some suggestions for ways to speed up your\nprograms by code tuning.\nThe most important thing to realize is that most statements in a\nprogram do not have much effect on the running time of that program.\nThere are normally just a few key subroutines, possibly even key\nlines of code within the key subroutines, that account for most of\nthe running time.\nThere is little point to cutting in half the running time of a\nsubroutine that accounts for only 1% of the total running time.\nFocus your attention on those parts of the program that have the most\nimpact.", "When tuning code, it is important to gather good timing statistics.\nMany compilers and\noperating systems\ninclude profilers and other special tools to help gather information\non both time and space use.\nThese are invaluable when trying to make a program more efficient,\nbecause they can tell you where to invest your effort.", "A lot of code tuning is based on the principle of avoiding work rather\nthan speeding up work.\nA common situation occurs when we can test for a condition that lets\nus skip some work.\nHowever, such a test is never completely free.\nCare must be taken that the cost of the test does not exceed the\namount of work saved.\nWhile one test might be cheaper than the work potentially saved, the\ntest must always be made and the work can be avoided only some\nfraction of the time.", "Be careful not to use tricks that make the program unreadable.\nMost code tuning is simply cleaning up a carelessly written program,\nnot taking a clear program and adding tricks.\nIn particular, you should develop an appreciation for the\ncapabilities of modern compilers to make extremely good optimizations\nof expressions.\n\"Optimization of expressions\" here means a rearrangement of\narithmetic or logical expressions to run more efficiently.\nBe careful not to damage the compiler's ability to do such\noptimizations for you in an effort to optimize the expression\nyourself.\nAlways check that your \"optimizations\" really do improve the\nprogram by running the program before and after the change on a\nsuitable benchmark set of input.\nMany times I have been wrong about the positive effects of code\ntuning in my own programs.\nMost often I am wrong when I try to optimize an expression.\nIt is hard to do better than the compiler.", "The greatest time and space improvements come from a better\ndata structure or algorithm.\nThe most important rule of code tuning is:"], "raw": {"@format": "xml", "@xml:space": "preserve", "todo": "null"}, "topic": {"title": "Example", "paragraph": {"title_reference": "bounding box", "math": ["x", "y"], "#text": "A common operation in computer graphics applications is to find\nwhich among a set of complex objects contains a given point in\nspace.\nMany useful data structures and algorithms have been developed to\ndeal with variations of this problem.\nMost such implementations involve the following tuning step.\nDirectly testing whether a given complex object contains the point\nin question is relatively expensive.\nInstead, we can screen for whether the point is contained within a\n for the object.\nThe bounding box is simply the smallest rectangle (usually defined\nto have sides perpendicular to the  and  axes)\nthat contains the object.\nIf the point is not in the bounding box, then it cannot be in the\nobject.\nIf the point is in the bounding box, only then would we conduct the\nfull comparison of the object versus the point.\nNote that if the point is outside the bounding box, we saved time\nbecause the bounding box test is cheaper than the comparison of the\nfull object versus the point.\nBut if the point is inside the bounding box, then that test is\nredundant because we still have to compare the point against the\nobject.\nTypically the amount of work avoided by making this test is greater\nthan the cost of making the test on every object."}}, "block_quote": {"paragraph": {"strong": "First tune the algorithm, then tune the code."}}}, {"@ids": "empirical-analysis", "@names": "empirical\\ analysis", "title": "Empirical Analysis", "paragraph": [{"title_reference": ["Asymptotic algorithm analysis <algorithm analysis>", "estimation"], "#text": "is an analytic tool, whereby we model the key aspects of an\nalgorithm to determine the growth rate of the algorithm as the input\nsize grows.\nIt has proved hugely practical, guiding developers to use more\nefficient algorithms.\nBut it is really an  technique, and it has its\nlimitations.\nThese include the effects at small problem size, determining the finer\ndistinctions between algorithms with the same growth rate, and\nthe inherent difficulty of doing mathematical modeling for more\ncomplex problems."}, "An alternative to analytical approaches are empirical ones.\nThe most obvious empirical approach is simply to run two competitors\nand see which performs better.\nIn this way we might overcome the deficiencies of analytical\napproaches.", "Be warned that comparative timing of programs is a difficult\nbusiness, often subject to experimental errors arising from\nuncontrolled factors (system load, the language or compiler used,\netc.).\nThe most important concern is that you might be biased in favor of one\nof the programs.\nIf you are biased, this is certain to be reflected in the timings.\nOne look at competing software or hardware vendors' advertisements\nshould convince you of this.\nThe most common pitfall when writing two programs to compare\ntheir performance is that one receives more code-tuning effort than\nthe other, since code tuning can often reduce running time by a\nfactor of five to ten.\nIf the running times for two programs differ by a constant factor\nregardless of input size (i.e., their growth rates are\nthe same), then differences in code tuning might account for any\ndifference in running time.\nBe suspicious of empirical comparisons in this situation.", "Another approach to analytical analysis is simulation.\nThe idea of simulation is to model the problem with a computer program\nand then run it to get a result.\nIn the context of algorithm analysis, simulation\nis distinct from empirical comparison of two competitors because the\npurpose of the simulation is to perform analysis that\nmight otherwise be too difficult.\nA good example of this appears in the following figure.", {"title_reference": "hash table <hash table> <HashIntro>", "math": ["y", "x"], "#text": "This figure shows the cost for inserting or deleting a record from a\n under two different\nassumptions for the policy used to find a free slot in the table.\nThe  axes is the cost in number of hash table slots\nevaluated, and the  axes is the percentage of slots in the\ntable that are full.\nThe mathematical equations for these curves can be determined,\nbut this is not so easy.\nA reasonable alternative is to write simple variations on hashing.\nBy timing the cost of the program for various loading conditions, it\nis not difficult to construct a plot similar to this one.\nThe purpose of this analysis was not to determine which approach to\nhashing is most efficient, so we are not doing empirical comparison of\nhashing alternatives.\nInstead, the purpose was to analyze the proper loading factor that\nwould be used in an efficient hashing system to balance time cost\nversus hash table size (space cost)."}], "target": {"@refid": "hashplot2"}, "raw": {"@format": "xml", "@ids": "hashplot2", "@names": "hashplot2", "@xml:space": "preserve", "odsafig": "null"}}]}}