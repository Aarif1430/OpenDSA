from django.db import models
import datetime, logging
import math
import urllib
import pickle
import random
import itertools

from django.contrib.auth.models import User
from django.core.cache import cache
import consts



# Create your models here.
class ODSAmod(models.Model):
    mod_id = models.IntegerField()
    title = models.CharField(max_length=400)
    filename = models.CharField(max_length=200)

    def __unicode__(self):
        return self.title



#KA Knowledgemap models

class Exercise(models.Model):

    name = models.TextField()
    short_display_name = models.TextField(default="")
    prerequisites = models.TextField()
    covers = models.TextField()
    v_position = models.IntegerField() # actually horizontal position on knowledge map
    h_position = models.IntegerField() # actually vertical position on knowledge map
    seconds_per_fast_problem = models.FloatField(default = consts.MIN_SECONDS_PER_FAST_PROBLEM) # Seconds expected to finish a problem 'quickly' for badge calculation

    # True if this exercise is live and visible to all users.
    # Non-live exercises are only visible to admins.
    live = models.BooleanField(default=False)

    # True if this exercise is a quasi-exercise generated by
    # combining the content of other exercises
    summative = models.BooleanField(default=False)

    # Teachers contribute raw html with embedded CSS and JS
    # and we sanitize it with Caja before displaying it to
    # students.
    author = models.TextField()
    raw_html = models.TextField()
    last_modified = models.DateTimeField(auto_now_add=True, default=datetime.datetime(2012, 1, 1))
    creation_date = models.DateTimeField(auto_now_add=True, default=datetime.datetime(2012, 1, 1))

    _serialize_blacklist = [
            "author", "raw_html", "last_modified",
            "coverers", "prerequisites_ex", "assigned",
            ]

    @property
    def relative_url(self):
        return "/exercises?exid=%s" % self.name
    
    @property
    def ka_url(self):
        return util.absolute_url("/exercises?exid=%s" % self.name)

    @staticmethod
    def get_by_name(name):
        dict_exercises = Exercise.__get_dict_use_cache_unsafe__()
        if dict_exercises.has_key(name):
            if dict_exercises[name].is_visible_to_current_user():
                return dict_exercises[name]
        return None

    @staticmethod
    def to_display_name(name):
        if name:
            return name.replace('_', ' ').capitalize()
        return ""

    @property
    def display_name(self):
        return Exercise.to_display_name(self.name)

    # The number of "sub-bars" in a summative (equivalently, # of save points + 1)
    @property
    def num_milestones(self):
        return len(self.prerequisites) if self.summative else 1

    @property
    def required_streak(self):
        return consts.REQUIRED_STREAK * self.num_milestones

    def min_problems_imposed(self):
        return consts.MIN_PROBLEMS_IMPOSED

    @staticmethod
    def to_short_name(name):
        exercise = Exercise.get_by_name(name)
        if exercise:
            return exercise.short_name()
        return ""

    def short_name(self):
        if self.short_display_name:
            return self.short_display_name[:11]
        return self.display_name[:11]

    def is_visible_to_current_user(self):
        return self.live or user_util.is_current_user_developer()

    def struggling_threshold(self):
        # 96% of users have proficiency before they get to 30 problems
        # return 3 * self.required_streak

        # 85% of users have proficiency before they get to 19 problems
        return 2 * self.required_streak

    def summative_children(self):
        if not self.summative:
            return []
        query = models.Query(Exercise)
        query.filter("name IN ", self.prerequisites)
        return query

    def non_summative_exercise(self, problem_number):
        if not self.summative:
            return self

        if len(self.prerequisites) <= 0:
            raise Exception("Summative exercise '%s' does not include any other exercises" % self.name)

        # For now we just cycle through all of the included exercises in a summative exercise
        index = int(problem_number) % len(self.prerequisites)
        exid = self.prerequisites[index]

        query = Exercise.all()
        query.filter('name =', exid)
        exercise = query.get()

        if not exercise:
            raise Exception("Unable to find included exercise")

        if exercise.summative:
            return exercise.non_summative_exercise(problem_number)
        else:
            return exercise

    def related_videos_query(self):
        exercise_videos = None
        query = ExerciseVideo.all()
        query.filter('exercise =', self.key()).order('exercise_order')
        return query

    #@layer_cache.cache_with_key_fxn(lambda self: "related_videos_%s" % self.key(), layer=layer_cache.Layers.Memcache)
    def related_videos_fetch(self):
        exercise_videos = self.related_videos_query().fetch(10)
        for exercise_video in exercise_videos:
            exercise_video.video # Pre-cache video entity
        return exercise_videos

    # followup_exercises reverse walks the prerequisites to give you
    # the exercises that list the current exercise as its prerequisite.
    # i.e. follow this exercise up with these other exercises
    def followup_exercises(self):
        return [exercise for exercise in Exercise.get_all_use_cache() if self.name in exercise.prerequisites]

    @classmethod
    def all(cls, live_only = False):
        query = super(Exercise, cls).all()
        if live_only or not user_util.is_current_user_developer():
            query.filter("live =", True)
        return query

    @classmethod
    def all_unsafe(cls):
        return super(Exercise, cls).all()

    @staticmethod
    def get_all_use_cache():
        if user_util.is_current_user_developer():
            return Exercise.__get_all_use_cache_unsafe__()
        else:
            return Exercise.__get_all_use_cache_safe__()

    @staticmethod
    #@layer_cache.cache_with_key_fxn(lambda *args, **kwargs: "all_exercises_unsafe_%s" % Setting.cached_exercises_date())
    def __get_all_use_cache_unsafe__():
        query = Exercise.all_unsafe().order('h_position')
        return query.fetch(400)

    @staticmethod
    def __get_all_use_cache_safe__():
        return filter(lambda exercise: exercise.live, Exercise.__get_all_use_cache_unsafe__())

    @staticmethod
    #@layer_cache.cache_with_key_fxn(lambda *args, **kwargs: "all_exercises_dict_unsafe_%s" % Setting.cached_exercises_date())
    def __get_dict_use_cache_unsafe__():
        exercises = Exercise.__get_all_use_cache_unsafe__()
        dict_exercises = {}
        for exercise in exercises:
            dict_exercises[exercise.name] = exercise
        return dict_exercises

    @staticmethod
    #@layer_cache.cache(expiration=3600)
    def get_count():
        return Exercise.objects.all(live_only=True).count()

    def put(self):
        Setting.cached_exercises_date(str(datetime.datetime.now()))
        models.Model.put(self)
        Exercise.get_count(bust_cache=True)

    @staticmethod
    def get_dict(query, fxn_key):
        exercise_dict = {}
        for exercise in query.fetch(10000):
            exercise_dict[fxn_key(exercise)] = exercise
        return exercise_dict

def clamp(min_val, max_val):
    def decorator(target_fn):
        def wrapped(*arg, **kwargs):
            return sorted((min_val, target_fn(*arg, **kwargs), max_val))[1]
        return wrapped
    return decorator

class UserExercise(models.Model):

    user = models.TextField() 
    exercise = models.TextField()
    exercise_model = models.ForeignKey(Exercise)
    streak = models.IntegerField(default = 0)
    _progress = models.FloatField(default = None)  # A continuous value >= 0.0, where 1.0 means proficiency. This measure abstracts away the internal proficiency model.
    longest_streak = models.IntegerField(default = 0 )
    # TODO(david): This property can be removed once we completely move off the streak display.
    streak_start = models.FloatField(default = 0.0)  # The starting point of the streak bar as it appears to the user, in [0,1)
    first_done = models.DateTimeField(auto_now_add=True)
    last_done = models.DateTimeField()
    total_done = models.IntegerField(default = 0)
    total_correct = models.IntegerField(default = 0)
    last_review = models.DateTimeField(default=datetime.datetime.min)
    review_interval_secs = models.IntegerField(default=(60 * 60 * 24 * consts.DEFAULT_REVIEW_INTERVAL_DAYS)) # Default 7 days until review
    proficient_date = models.DateTimeField()
    seconds_per_fast_problem = models.FloatField(default = consts.MIN_SECONDS_PER_FAST_PROBLEM) # Seconds expected to finish a problem 'quickly' for badge calculation
    summative = models.BooleanField(default=False)
    #_accuracy_model = object_property.ObjectProperty()  # Stateful function object that estimates P(next problem correct). Only exists for new UserExercise objects.

    _USER_EXERCISE_KEY_FORMAT = "UserExercise.all().filter('user = '%s')"

    _serialize_blacklist = ["review_interval_secs", "_progress", "_accuracy_model"]

    #_MIN_PROBLEMS_FROM_ACCURACY_MODEL = AccuracyModel.min_streak_till_threshold(consts.PROFICIENCY_ACCURACY_THRESHOLD)

    # A bound function object to normalize the progress bar display from a probability
    #_normalize_progress = InvFnExponentialNormalizer(
    #    AccuracyModel(),
    #    consts.PROFICIENCY_ACCURACY_THRESHOLD
    #).normalize

    def proficiency_model(self):
        user_data = UserData.current()
        return user_data.proficiency_model if user_data else 'streak'

    @property
    def required_streak(self):
        if self.summative:
            return Exercise.get_by_name(self.exercise).required_streak
        else:
            return consts.REQUIRED_STREAK

    @property
    def exercise_states(self):
        user_exercise_graph = self.get_user_exercise_graph()
        if user_exercise_graph:
            return user_exercise_graph.states(self.exercise)
        return None

    @property
    def next_points(self):
        user_data = self.get_user_data()

        suggested = proficient = False

        if user_data:
            suggested = user_data.is_suggested(self.exercise)
            proficient = user_data.is_proficient_at(self.exercise)

        return points.ExercisePointCalculator(self, suggested, proficient)

    @property
    def num_milestones(self):
        return self.exercise_model.num_milestones

    def min_problems_imposed(self):
        return self.exercise_model.min_problems_imposed()

    def min_problems_required(self):
        return max(self.min_problems_imposed(), UserExercise._MIN_PROBLEMS_FROM_ACCURACY_MODEL)

    # Do not transition old objects that did not have the _accuracy_model
    # property - only new UserExercise objects can use the new proficiency
    # model.
    #def accuracy_model(self):
        # TODO(david): When we fully switch away from the streak model,
        #     uncomment the lines below and refactor code to remove
        #     accuracy_model guards.
        #if self._accuracy_model is None:
        #    self._accuracy_model = AccuracyModel(self)
    #    return self._accuracy_model

    #def bingo_proficiency_model(self, test):
        # We only want to score conversions for newly-created UserExercise
        # objects that could actually use the new proficiency model behavior
        # (all existing UserExercise objects use the old streak model to
        # facilitate transitioning).
     #   if self.accuracy_model():
     #       bingo(test)

    #def use_streak_model(self):
    #    return self.proficiency_model() == 'streak' or not self.accuracy_model()

    # Faciliate transition for old objects that did not have the _progress property
    @property
    @clamp(0.0, 1.0)
    def progress(self):
        if self._progress is None:
            self._progress = self._get_progress_from_current_state()
        return self._progress

    def bingo_prof_model_accuracy_threshold_tests(self):
        if self.total_done < 5 or not self.accuracy_model():
            return

        accuracy = self.accuracy_model().predict()

        if self.exercise in UserData.conversion_test_easy_exercises:
            for threshold in UserData.prof_conversion_accuracy_thresholds:
                if accuracy >= threshold:
                    self.bingo_proficiency_model('prof_accuracy_above_%s_easy' % threshold)

        elif self.exercise in UserData.conversion_test_hard_exercises:
            for threshold in UserData.prof_conversion_accuracy_thresholds:
                if accuracy >= threshold:
                    self.bingo_proficiency_model('prof_accuracy_above_%s_hard' % threshold)

    def update_proficiency_model(self, correct):
        if not correct:
            if self.summative:
                # Reset to latest milestone
                self.streak = (self.streak // consts.CHALLENGE_STREAK_BARRIER) * consts.CHALLENGE_STREAK_BARRIER
            else:
                self.streak = 0

        if self.accuracy_model():
            self.accuracy_model().update(correct)
            self.bingo_prof_model_accuracy_threshold_tests()

        self._progress = self._get_progress_from_current_state()

        if self.use_streak_model():
            self._update_progress_from_streak_model(correct)

    @clamp(0.0, 1.0)
    def _get_progress_from_current_state(self):

        if self.use_streak_model():
            if self._progress is not None:
                return self._progress

            if self.summative:
                return float(self.streak) / self.required_streak
            else:
                return self.streak_start + (
                    float(self.streak) / self.required_streak * (1.0 - self.streak_start))

        if self.total_correct == 0:
            return 0.0

        if self.accuracy_model().total_done <= self.accuracy_model().total_correct():
            # Impose a minimum number of problems required to be done.
            # If the user has no wrong answers yet, we can get a progress bar
            # amount by just dividing correct answers by the # of problems
            # required.
            normalized_prediction = min(float(self.accuracy_model().total_correct()) / self.min_problems_required(), 1.0)
        else:
            prediction = self.accuracy_model().predict()
            normalized_prediction = UserExercise._normalize_progress(prediction)

        if self.summative:
            if self._progress is None:
                milestones_completed = self.streak // consts.CHALLENGE_STREAK_BARRIER
            else:
                milestones_completed = math.floor(self._progress * self.num_milestones)

            if normalized_prediction >= 1.0:
                # The user just crossed a challenge barrier. Reset their
                # accuracy model to start fresh.
                self._accuracy_model = AccuracyModel()

            return float(milestones_completed + normalized_prediction) / self.num_milestones

        else:
            return normalized_prediction

    def _update_progress_from_streak_model(self, correct):
        assert self._progress is not None

        if correct:
            if self._progress >= 1.0:
                self._progress = 1.0
                return

            if self.summative:
                progress_increment = 1.0 / self.required_streak
            else:
                progress_increment = (1.0 - self._progress) / (self.required_streak - self.streak)

            self._progress += progress_increment

        else:
            if self.summative:
                self._progress = float(self.streak) / self.required_streak
            else:
                self._progress *= consts.STREAK_RESET_FACTOR

    @staticmethod
    def to_progress_display(num):
        return '%.0f%%' % math.floor(num * 100.0) if num <= consts.MAX_PROGRESS_SHOWN else 'Max'

    def progress_display(self):
        return UserExercise.to_progress_display(self.progress)

    @staticmethod
    def get_key_for_email(email):
        return UserExercise._USER_EXERCISE_KEY_FORMAT % email

    @staticmethod
    def get_for_user_data(user_data):
        query = UserExercise.all()
        query.filter('user =', user_data.user)
        return query

    def get_user_data(self):
        user_data = None

        if hasattr(self, "_user_data"):
            user_data = self._user_data
        else:
            user_data = UserData.get_from_models_key_email(self.user.email())

        if not user_data:
            logging.critical("Empty user data for UserExercise w/ .user = %s" % self.user)

        return user_data

    def get_user_exercise_graph(self):
        user_exercise_graph = None

        if hasattr(self, "_user_exercise_graph"):
            user_exercise_graph = self._user_exercise_graph
        else:
            user_exercise_graph = UserExerciseGraph.get(self.get_user_data())

        return user_exercise_graph

    def belongs_to(self, user_data):
        return user_data and self.user.email().lower() == user_data.key_email.lower()

    def struggling_threshold(self):
        return self.exercise_model.struggling_threshold()

    @staticmethod
    def get_review_interval_from_seconds(seconds):
        review_interval = datetime.timedelta(seconds=seconds)

        if review_interval.days < consts.MIN_REVIEW_INTERVAL_DAYS:
            review_interval = datetime.timedelta(days=consts.MIN_REVIEW_INTERVAL_DAYS)
        elif review_interval.days > consts.MAX_REVIEW_INTERVAL_DAYS:
            review_interval = datetime.timedelta(days=consts.MAX_REVIEW_INTERVAL_DAYS)

        return review_interval

    def has_been_proficient(self):
        return self.proficient_date is not None

    def get_review_interval(self):
        return UserExercise.get_review_interval_from_seconds(self.review_interval_secs)

    def schedule_review(self, correct, now=datetime.datetime.now()):
        # If the user is not now and never has been proficient, don't schedule a review
        if self.progress < 1.0 and not self.has_been_proficient():
            return

        # If the user is hitting a new streak either for the first time or after having lost
        # proficiency, reset their review interval counter.
        if self.progress >= 1.0:
            self.review_interval_secs = 60 * 60 * 24 * consts.DEFAULT_REVIEW_INTERVAL_DAYS

        review_interval = self.get_review_interval()

        if correct and self.last_review != datetime.datetime.min:
            time_since_last_review = now - self.last_review
            if time_since_last_review >= review_interval:
                review_interval = time_since_last_review * 2
        if not correct:
            review_interval = review_interval // 2
        if correct:
            self.last_review = now
        else:
            self.last_review = datetime.datetime.min
        self.review_interval_secs = review_interval.days * 86400 + review_interval.seconds

    def set_proficient(self, proficient, user_data):
        if not proficient and not self.has_been_proficient():
            # Not proficient and never has been so nothing to do
            return

        if proficient:
            if self.exercise not in user_data.proficient_exercises:
                self.proficient_date = datetime.datetime.now()

                user_data.proficient_exercises.append(self.exercise)
                user_data.need_to_reassess = True
                user_data.put()

                util_notify.update(user_data, self, False, True)

                # Score conversions for A/B test
                self.bingo_proficiency_model('prof_gained_proficiency_all')

                if self.exercise in UserData.conversion_test_hard_exercises:
                    self.bingo_proficiency_model('prof_gained_proficiency_hard')
                    self.bingo_proficiency_model('prof_gained_proficiency_hard_binary')
                    bingo('hints_gained_proficiency_hard_binary')
                elif self.exercise in UserData.conversion_test_easy_exercises:
                    self.bingo_proficiency_model('prof_gained_proficiency_easy')
                    self.bingo_proficiency_model('prof_gained_proficiency_easy_binary')
                    bingo('hints_gained_proficiency_easy_binary')

        else:
            if self.exercise in user_data.proficient_exercises:
                user_data.proficient_exercises.remove(self.exercise)
                user_data.need_to_reassess = True
                user_data.put()



class BlobField(models.Field):
    description = "Blob"
    def db_type(self):
        return 'blob'


# UserExerciseCache is an optimized-for-read-and-deserialization cache of user-specific exercise states.
# It can be reconstituted at any time via UserExercise objects.
#
class UserExerciseCache(models.Model):

    # Bump this whenever you change the structure of the cached UserExercises and need to invalidate all old caches
    CURRENT_VERSION = 7

    version = models.IntegerField()
    dicts =BlobField() # object_property.UnvalidatedObjectProperty()

    def user_exercise_dict(self, exercise_name):
#        return self.dicts.get(exercise_name) or UserExerciseCache.dict_from_user_exercise(None)
        return UserExerciseCache.dict_from_user_exercise(None)
       
    def update(self, user_exercise):
        self.dicts[user_exercise.exercise] = UserExerciseCache.dict_from_user_exercise(user_exercise)

    @staticmethod
    def key_for_user_data(user_data):
        return "UserExerciseCache:%s" % user_data.key_email

    @staticmethod
    def get(user_data_or_list):
        if not user_data_or_list:
            raise Exception("Must provide UserData when loading UserExerciseCache")

        # We can grab a single UserExerciseCache or do an optimized grab of a bunch of 'em
        user_data_list = user_data_or_list if type(user_data_or_list) == list else [user_data_or_list]

        # Try to get 'em all by key name
        #user_exercise_caches = UserExerciseCache.get_by_key_name(
        user_exercise_caches = UserExerciseCache.objects.all()
               # map(lambda user_data: UserExerciseCache.key_for_user_data(user_data),user_data_list))

        # For any that are missing or are out of date,
        # build up asynchronous queries to repopulate their data
        async_queries = []
        for i, user_exercise_cache in enumerate(user_exercise_caches):
            if not user_exercise_cache or user_exercise_cache.version != UserExerciseCache.CURRENT_VERSION:
                # This user's cached graph is missing or out-of-date,
                # put it in the list of graphs to be regenerated.
                async_queries.append(UserExercise.get_for_user_data(user_data_list[i]))

        if len(async_queries) > 0:

            # Run the async queries
            results = util.async_queries(async_queries)
            caches_to_put = []
            exercises = Exercise.get_all_use_cache()

            # Populate the missing graphs w/ results from async queries
            index_result = 0
            for i, user_exercise_cache in enumerate(user_exercise_caches):
                if not user_exercise_cache or user_exercise_cache.version != UserExerciseCache.CURRENT_VERSION:
                    user_data = user_data_list[i]
                    user_exercises = results[index_result].get_result()

                    user_exercise_cache = UserExerciseCache.generate(user_data, user_exercises)

                    if len(caches_to_put) < 10:
                        # We only put 10 at a time in case a teacher views a report w/ tons and tons of uncached students
                        caches_to_put.append(user_exercise_cache)

                    user_exercise_caches[i] = user_exercise_cache

                    index_result += 1

            if len(caches_to_put) > 0:
                # Fire off an asynchronous put to cache the missing results. On the production server,
                # we don't wait for the put to finish before dealing w/ the rest of the request
                # because we don't really care if the cache misses.
                future_put = models.put_async(caches_to_put)

                if App.is_dev_server:
                    # On the dev server, we have to explicitly wait for get_result in order to
                    # trigger the put (not truly asynchronous).
                    future_put.get_result()

        if not user_exercise_caches:
            return []

        # Return list of caches if a list was passed in,
        # otherwise return single cache
        return user_exercise_caches if type(user_data_or_list) == list else user_exercise_caches[0]

    @staticmethod
    def dict_from_user_exercise(user_exercise):
        return {
                "streak": user_exercise.streak if user_exercise else 0,
                "longest_streak": user_exercise.longest_streak if user_exercise else 0,
                "progress": user_exercise.progress if user_exercise else 0.0,
                "total_done": user_exercise.total_done if user_exercise else 0,
                "last_done": user_exercise.last_done if user_exercise else datetime.datetime.min,
                "last_review": user_exercise.last_review if user_exercise else datetime.datetime.min,
                "review_interval_secs": user_exercise.review_interval_secs if user_exercise else 0,
                "proficient_date": user_exercise.proficient_date if user_exercise else 0,
                }

    @staticmethod
    def generate(user_data, user_exercises=None):

        if not user_exercises:
            user_exercises = UserExercise.get_for_user_data(user_data)

        dicts = {}

        # Build up cache
        for user_exercise in user_exercises:

            user_exercise_dict = UserExerciseCache.dict_from_user_exercise(user_exercise)

            # In case user has multiple UserExercise mappings for a specific exercise,
            # always prefer the one w/ more problems done
            if user_exercise.exercise not in dicts or dicts[user_exercise.exercise]["total_done"] < user_exercise_dict["total_done"]:
                dicts[user_exercise.exercise] = user_exercise_dict

        return UserExerciseCache(
                key_name = UserExerciseCache.key_for_user_data(user_data),
                version = UserExerciseCache.CURRENT_VERSION,
                dicts = dicts,
            )










class UserExerciseGraph(object):

    def __init__(self, graph={}, cache=None):
        self.graph = graph
        self.cache = cache

    def graph_dict(self, exercise_name):
        return self.graph.get(exercise_name)

    def graph_dicts(self):
        return sorted(sorted(self.graph.values(), key=lambda graph_dict: graph_dict["v_position"]), key=lambda graph_dict: graph_dict["h_position"])

    def proficient_exercise_names(self):
        return [graph_dict["name"] for graph_dict in self.proficient_graph_dicts()]

    def suggested_exercise_names(self):
        return [graph_dict["name"] for graph_dict in self.suggested_graph_dicts()]

    def review_exercise_names(self):
        return [graph_dict["name"] for graph_dict in self.review_graph_dicts()]

    def suggested_graph_dicts(self):
        return [graph_dict for graph_dict in self.graph_dicts() if graph_dict["suggested"]]

    def proficient_graph_dicts(self):
        return [graph_dict for graph_dict in self.graph_dicts() if graph_dict["proficient"]]

    def recent_graph_dicts(self, n_recent=2):
        return sorted(
                [graph_dict for graph_dict in self.graph_dicts() if graph_dict["last_done"]],
                reverse=True,
                key=lambda graph_dict: graph_dict["last_done"],
                )[0:n_recent]

    def review_graph_dicts(self):

        # an exercise ex should be reviewed iff all of the following are true:
        #   * ex and all of ex's covering ancestors either
        #      * are scheduled to have their next review in the past, or
        #      * were answered incorrectly on last review (i.e. streak == 0 with proficient == true)
        #   * none of ex's covering ancestors should be reviewed
        #   * the user is proficient at ex
        # the algorithm:
        #   for each exercise:
        #     traverse it's ancestors, computing and storing the next review time (if not already done),
        #     using now as the next review time if proficient and streak==0
        #   select and mark the exercises in which the user is proficient but with next review times in the past as review candidates
        #   for each of those candidates:
        #     traverse it's ancestors, computing and storing whether an ancestor is also a candidate
        #   all exercises that are candidates but do not have ancestors as candidates should be listed for review

        now = datetime.datetime.now()

        def compute_next_review(graph_dict):
            if graph_dict.get("next_review") is None:
                graph_dict["next_review"] = datetime.datetime.min

                if graph_dict["total_done"] > 0 and graph_dict["last_review"] > datetime.datetime.min:
                    next_review = graph_dict["last_review"] + UserExercise.get_review_interval_from_seconds(graph_dict["review_interval_secs"])

                    if next_review > now and graph_dict["proficient"] and graph_dict["streak"] == 0:
                        next_review = now

                    if next_review > graph_dict["next_review"]:
                        graph_dict["next_review"] = next_review

                for covering_graph_dict in graph_dict["coverer_dicts"]:
                    covering_next_review = compute_next_review(covering_graph_dict)
                    if covering_next_review > graph_dict["next_review"]:
                        graph_dict["next_review"] = covering_next_review

            return graph_dict["next_review"]

        def compute_is_ancestor_review_candidate(graph_dict):
            if graph_dict.get("is_ancestor_review_candidate") is None:

                graph_dict["is_ancestor_review_candidate"] = False

                for covering_graph_dict in graph_dict["coverer_dicts"]:
                    graph_dict["is_ancestor_review_candidate"] = (graph_dict["is_ancestor_review_candidate"] or
                            covering_graph_dict["is_review_candidate"] or
                            compute_is_ancestor_review_candidate(covering_graph_dict))

            return graph_dict["is_ancestor_review_candidate"]

        for graph_dict in self.graph_dicts():
            compute_next_review(graph_dict)

        candidate_dicts = []
        for graph_dict in self.graph_dicts():
            if not graph_dict["summative"] and graph_dict["proficient"] and graph_dict["next_review"] <= now:
                graph_dict["is_review_candidate"] = True
                candidate_dicts.append(graph_dict)
            else:
                graph_dict["is_review_candidate"] = False

        review_dicts = []
        for graph_dict in candidate_dicts:
            if not compute_is_ancestor_review_candidate(graph_dict):
                review_dicts.append(graph_dict)

        return review_dicts

    def states(self, exercise_name):
        graph_dict = self.graph_dict(exercise_name)

        return {
            "proficient": graph_dict["proficient"],
            "suggested": graph_dict["suggested"],
            "struggling": graph_dict["struggling"],
            "endangered": graph_dict["endangered"],
            "summative": graph_dict["summative"],
            "reviewing": graph_dict in self.review_graph_dicts(),
        }

    @staticmethod
    def current():
        return UserExerciseGraph.get(UserData.current())

    @staticmethod
    def get(user_data_or_list):
        if not user_data_or_list:
            return [] if type(user_data_or_list) == list else None

        # We can grab a single UserExerciseGraph or do an optimized grab of a bunch of 'em
        user_data_list = user_data_or_list if type(user_data_or_list) == list else [user_data_or_list]



        user_exercise_cache_list = UserExerciseCache.get(user_data_list)
        
        #print "In UserExerciseGraph.get user_exercise_cache_list==%s"%user_exercise_cache_list
        print user_data_list
        return []
        if not user_exercise_cache_list:
            return [] if type(user_data_or_list) == list else None

        exercise_dicts = UserExerciseGraph.exercise_dicts()

        user_exercise_graphs = map(
                lambda (user_data, user_exercise_cache): UserExerciseGraph.generate(user_data, user_exercise_cache, exercise_dicts),
                itertools.izip(user_data_list, user_exercise_cache_list))

        # Return list of graphs if a list was passed in,
        # otherwise return single graph
        return user_exercise_graphs if type(user_data_or_list) == list else user_exercise_graphs[0]
        
    @staticmethod
    def dict_from_exercise(exercise):
        return {
                "name": exercise.name,
                "display_name": exercise.display_name,
                "h_position": exercise.h_position,
                "v_position": exercise.v_position,
                "summative": exercise.summative,
                "struggling_threshold": exercise.struggling_threshold(),
                "num_milestones": exercise.num_milestones,
                "proficient": None,
                "explicitly_proficient": None,
                "suggested": None,
                "struggling": None,
                "endangered": None,
                "prerequisites": map(lambda exercise_name: {"name": exercise_name, "display_name": Exercise.to_display_name(exercise_name)}, exercise.prerequisites),
                "covers": exercise.covers,
            }

    @staticmethod
    def exercise_dicts():
        return map(UserExerciseGraph.dict_from_exercise, Exercise.get_all_use_cache())

    @staticmethod
    def get_and_update(user_data, user_exercise):
        user_exercise_cache = UserExerciseCache.get(user_data)
        user_exercise_cache.update(user_exercise)
        return UserExerciseGraph.generate(user_data, user_exercise_cache, UserExerciseGraph.exercise_dicts())

    @staticmethod
    def generate(user_data, user_exercise_cache, exercise_dicts):

        graph = {}

        # Build up base of graph
        for exercise_dict in exercise_dicts:

            user_exercise_dict = user_exercise_cache.user_exercise_dict(exercise_dict["name"])

            graph_dict = {}

            graph_dict.update(user_exercise_dict)
            graph_dict.update(exercise_dict)
            graph_dict.update({
                "coverer_dicts": [],
                "prerequisite_dicts": [],
            })

            # TODO(david): Use accuracy to determine when struggling
            graph_dict["struggling"] = (graph_dict["streak"] == 0 and
                    not graph_dict["proficient_date"] and
                    graph_dict["total_done"] > graph_dict["struggling_threshold"])

            # In case user has multiple UserExercise mappings for a specific exercise,
            # always prefer the one w/ more problems done
            if graph_dict["name"] not in graph or graph[graph_dict["name"]]["total_done"] < graph_dict["total_done"]:
                graph[graph_dict["name"]] = graph_dict

        # Cache coverers and prereqs for later
        for graph_dict in graph.values():
            # Cache coverers
            for covered_exercise_name in graph_dict["covers"]:
                covered_graph_dict = graph.get(covered_exercise_name)
                if covered_graph_dict:
                    covered_graph_dict["coverer_dicts"].append(graph_dict)

            # Cache prereqs
            for prerequisite_exercise_name in graph_dict["prerequisites"]:
                prerequisite_graph_dict = graph.get(prerequisite_exercise_name["name"])
                if prerequisite_graph_dict:
                    graph_dict["prerequisite_dicts"].append(prerequisite_graph_dict)

        # Set explicit proficiencies
        for exercise_name in user_data.proficient_exercises:
            graph_dict = graph.get(exercise_name)
            if graph_dict:
                graph_dict["proficient"] = graph_dict["explicitly_proficient"] = True

        # Calculate implicit proficiencies
        def set_implicit_proficiency(graph_dict):
            if graph_dict["proficient"] is not None:
                return graph_dict["proficient"]

            graph_dict["proficient"] = False

            # Consider an exercise implicitly proficient if the user has
            # never missed a problem and a covering ancestor is proficient
            if graph_dict["streak"] == graph_dict["total_done"]:
                for covering_graph_dict in graph_dict["coverer_dicts"]:
                    if set_implicit_proficiency(covering_graph_dict):
                        graph_dict["proficient"] = True
                        break

            return graph_dict["proficient"]

        for exercise_name in graph:
            set_implicit_proficiency(graph[exercise_name])

        # Calculate suggested
        def set_suggested(graph_dict):
            if graph_dict["suggested"] is not None:
                return graph_dict["suggested"]

            # Don't suggest already-proficient exercises
            if graph_dict["proficient"]:
                graph_dict["suggested"] = False
                return graph_dict["suggested"]

            # First, assume we're suggesting this exercise
            graph_dict["suggested"] = True

            # Don't suggest exercises that are covered by other suggested exercises
            for covering_graph_dict in graph_dict["coverer_dicts"]:
                if set_suggested(covering_graph_dict):
                    graph_dict["suggested"] = False
                    return graph_dict["suggested"]

            # Don't suggest exercises if the user isn't proficient in all prerequisites
            for prerequisite_graph_dict in graph_dict["prerequisite_dicts"]:
                if not prerequisite_graph_dict["proficient"]:
                    graph_dict["suggested"] = False
                    return graph_dict["suggested"]

            return graph_dict["suggested"]

        def set_endangered(graph_dict):
            graph_dict["endangered"] = (graph_dict["proficient"] and
                    graph_dict["streak"] == 0 and
                    graph_dict["proficient_date"] is not None)

        for exercise_name in graph:
            set_suggested(graph[exercise_name])
            set_endangered(graph[exercise_name])

        return UserExerciseGraph(graph = graph, cache=user_exercise_cache)


PRE_PHANTOM_EMAIL = "http://nouserid.khanacademy.org/pre-phantom-user-2"
PHANTOM_ID_EMAIL_PREFIX = "http://nouserid.khanacademy.org/"



class UserData( models.Model):
    key_name = models.TextField()
    user = models.TextField()
    user_id = models.TextField()
    user_nickname = models.TextField()
    current_user = models.TextField()
    moderator = models.BooleanField(default=False)
    developer = models.BooleanField(default=False)
    joined = models.DateTimeField(auto_now_add=True)
    last_login = models.DateTimeField()
    proficient_exercises = models.TextField() # Names of exercises in which the user is *explicitly* proficient
    all_proficient_exercises = models.TextField() # Names of all exercises in which the user is proficient
    suggested_exercises = models.TextField()
    badges = models.TextField() # All awarded badges
    need_to_reassess = models.BooleanField()
    points = models.IntegerField(default = 0)
    total_seconds_watched = models.IntegerField(default = 0)
    coaches = models.TextField()
    coworkers = models.TextField()
    student_lists = models.TextField()
    map_coords = models.TextField()
    expanded_all_exercises = models.BooleanField(default=True)
    videos_completed = models.IntegerField(default = -1)
    last_daily_summary = models.DateTimeField()
    last_badge_review = models.DateTimeField()
    last_activity = models.DateTimeField()
    start_consecutive_activity_date = models.DateTimeField()
    count_feemodels_ck_notification = models.IntegerField(default = -1 )
    question_sort_order = models.IntegerField(default = -1)
    user_email = models.TextField()
    uservideocss_version = models.IntegerField(default = 0)

    _serialize_blacklist = [
            "badges", "count_feemodels_ck_notification",
            "last_daily_summary", "need_to_reassess", "videos_completed",
            "moderator", "expanded_all_exercises", "question_sort_order",
            "last_login", "user", "current_user", "map_coords", "expanded_all_exercises",
            "user_nickname", "user_email", "seconds_since_joined",
    ]

    prof_conversion_accuracy_thresholds = [0.85, 0.90, 0.92, 0.94, 0.96]
#    _prof_model_conversion_tests = ([
#        ('prof_gained_proficiency_all', ConversionTypes.Counting),
#        ('prof_gained_proficiency_easy', ConversionTypes.Counting),
#        ('prof_gained_proficiency_hard', ConversionTypes.Counting),
#        ('prof_gained_proficiency_easy_binary', ConversionTypes.Binary),
#        ('prof_gained_proficiency_hard_binary', ConversionTypes.Binary),
#        ('prof_problems_done', ConversionTypes.Counting),
#        ('prof_new_exercises_attempted', ConversionTypes.Counting),
#        ('prof_does_problem_just_after_proficiency', ConversionTypes.Counting),
#        ('prof_problem_correct_just_after_proficiency', ConversionTypes.Counting),
#        ('prof_wrong_problems', ConversionTypes.Counting),
#        ('prof_keep_going_after_wrong', ConversionTypes.Counting),
#    ] + [('prof_accuracy_above_%s_easy' % p, ConversionTypes.Binary) for p in prof_conversion_accuracy_thresholds]
 #   + [('prof_accuracy_above_%s_hard' % p, ConversionTypes.Binary) for p in prof_conversion_accuracy_thresholds])
#    _prof_model_conversion_names, _prof_model_conversion_types = [list(x) for x in zip(*_prof_model_conversion_tests)]

    conversion_test_hard_exercises = set(['order_of_operations', 'graphing_points',
        'probability_1', 'domain_of_a_function', 'division_4',
        'ratio_word_problems', 'writing_expressions_1', 'ordering_numbers',
        'geometry_1', 'converting_mixed_numbers_and_improper_fractions'])
    conversion_test_easy_exercises = set(['counting_1', 'significant_figures_1', 'subtraction_1'])

    @property
    #@request_cache.cache()
    def proficiency_model(self):
        return ab_test("Proficiency Model", {"accuracy": 1, "streak": 9},
            UserData._prof_model_conversion_names, UserData._prof_model_conversion_types)

    @property
    def nickname(self):
        # Only return cached value if it exists and it wasn't cached during a Facebook API hiccup
        if self.user_nickname and not is_facebook_user_id(self.user_nickname):
            return self.user_nickname
        else:
            return nicknames.get_nickname_for(self)

    @property
    def email(self):
        return self.user_email

    @property
    def key_email(self):
        return self.user_email #self.user.email()

    @property
    def badge_counts(self):
        return util_badges.get_badge_counts(self)

    @staticmethod
    #@request_cache.cache()
    def current():
        user_id = None #util.get_current_user_id(bust_cache=True)
        email =user_id 

        #google_user = users.get_current_user()
        #if google_user:
        #    email = google_user.email()

        if user_id:
            # Once we have rekeyed legacy entities,
            # we will be able to simplify this.we make
            return  UserData.get_from_user_id(user_id) or \
                    UserData.get_from_models_key_email(email) or \
                    UserData.insert_for(user_id, email)
        return None

    @staticmethod
    def pre_phantom():
        return UserData.insert_for(PRE_PHANTOM_EMAIL, PRE_PHANTOM_EMAIL)

    @property
    def is_phantom(self):
        return self.user_id or self.user_id.startswith(PHANTOM_ID_EMAIL_PREFIX)

    @property
    def is_pre_phantom(self):
        return PRE_PHANTOM_EMAIL == self.user_email

    @property
    def seconds_since_joined(self):
        return util.seconds_since(self.joined)

    @staticmethod
    #@request_cache.cache_with_key_fxn(lambda user_id: "UserData_user_id:%s" % user_id)
    def get_from_user_id(user_id):
        if not user_id:
            return None
        
        query = UserData.objects.all()
        query.filter('user_id =', user_id)
        query.order('-points') # Temporary workaround for issue 289

        return query.get()

    staticmethod
    def get_from_user_input_email(email):
        if not email:
            return None

        query = UserData.objects.all()
        query.filter('user_email =', email)
        query.order('-points') # Temporary workaround for issue 289

        return query.get()

    @staticmethod
    def get_from_models_key_email(email):
        if not email:
            return None

        query = UserData.objects.all()
        query.filter('user =', users.User(email))
        query.order('-points') # Temporary workaround for issue 289

        return query.get()

    @staticmethod
    def insert_for(user_id, email):
        if not user_id or not email:
            return None

        user = email
        key = "user_id_key_%s" % user_id

        user_data1 = UserData.objects.get_or_create(
            id=random.randint(2,50000),
            key_name=key,
            user=user,
            current_user=user,
            user_id=user_id,
            moderator=False,
            last_login=datetime.datetime.now(),
            proficient_exercises=[],
            suggested_exercises=[],
            need_to_reassess=True,
            points=0,
            coaches=[],
            user_email=email
            )
        if user_data1[1]:
            user_data=user_data1[0]

        if not user_data.is_phantom:
            # Record that we now have one more registered user
            if (datetime.datetime.now() - user_data.joined).seconds < 60:
                # Extra safety check against user_data.joined in case some
                # subtle bug results in lots of calls to insert_for for
                # UserData objects with existing key_names.
                user_counter.add(1)

        return user_data

    def delete(self):
        logging.info("Deleting user data for %s with points %s" % (self.key_email, self.points))
        logging.info("Dumping user data for %s: %s" % (self.user_id, jsonify(self)))

        if not self.is_phantom:
            user_counter.add(-1)

        models.delete(self)

    def get_or_insert_exercise(self, exercise, allow_insert = True):
        if not exercise:
            return None

        exid = exercise.name
        userExercise = UserExercise.get_by_key_name(exid, parent=self)

        if not userExercise:
            # There are some old entities lying around that don't have keys.
            # We have to check for them here, but once we have reparented and rekeyed legacy entities,
            # this entire function can just be a call to .get_or_insert()
            query = UserExercise.all(keys_only = True)
            query.filter('user =', self.user)
            query.filter('exercise =', exid)
            query.order('-total_done') # Temporary workaround for issue 289

            # In order to guarantee consistency in the HR datastore, we need to query
            # via models.get for these old, parent-less entities.
            key_user_exercise = query.get()
            if key_user_exercise:
                userExercise = UserExercise.get(str(key_user_exercise))

        if allow_insert and not userExercise:
            userExercise = UserExercise.get_or_create(
                key_name=exid,
                parent=self,
                user=self.user,
                exercise=exid,
                exercise_model=exercise,
                streak=0,
                _progress=0.0,
                streak_start=0.0,
                longest_streak=0,
                first_done=datetime.datetime.now(),
                last_done=None,
                total_done=0,
                summative=exercise.summative,
                _accuracy_model=AccuracyModel(),
                )

        return userExercise

    def reassess_from_graph(self, user_exercise_graph):
        is_changed=0
        if isinstance(user_exercise_graph, UserExerciseGraph):
           print "is instance"
           all_proficient_exercises = user_exercise_graph.proficient_exercise_names()
           suggested_exercises = user_exercise_graph.suggested_exercise_names()

           is_changed = (all_proficient_exercises != self.all_proficient_exercises or
                      suggested_exercises != self.suggested_exercises)

           self.all_proficient_exercises = all_proficient_exercises
           self.suggested_exercises = suggested_exercises
           self.need_to_reassess = False

        return is_changed

    def reassess_if_necessary(self, user_exercise_graph=None):
        if not self.need_to_reassess or self.all_proficient_exercises is None:
            return False

        if user_exercise_graph is None:
            user_exercise_graph = UserExerciseGraph.get(self)

        return self.reassess_from_graph(user_exercise_graph)

    def is_proficient_at(self, exid, exgraph=None):
        self.reassess_if_necessary(exgraph)
        return (exid in self.all_proficient_exercises)

    def is_explicitly_proficient_at(self, exid):
        return (exid in self.proficient_exercises)

    def is_suggested(self, exid):
        self.reassess_if_necessary()
        return (exid in self.suggested_exercises)

    def get_students_data(self):
        coach_email = self.key_email
        query = UserData.all().filter('coaches =', coach_email)
        students_data = [s for s in query.fetch(1000)]

        if coach_email.lower() != coach_email:
            students_set = set([s.key().id_or_name() for s in students_data])
            query = UserData.all().filter('coaches =', coach_email.lower())
            for student_data in query:
                if student_data.key().id_or_name() not in students_set:
                    students_data.append(student_data)
        return students_data

    def get_coworkers_data(self):
        return filter(lambda user_data: user_data is not None, \
                map(lambda coworker_email: UserData.get_from_models_key_email(coworker_email) , self.coworkers))

    def has_students(self):
        coach_email = self.key_email
        count = UserData.all().filter('coaches =', coach_email).count()

        if coach_email.lower() != coach_email:
            count += UserData.all().filter('coaches =', coach_email.lower()).count()

        return count > 0

    def coach_emails(self):
        emails = []
        for key_email in self.coaches:
            user_data_coach = UserData.get_from_models_key_email(key_email)
            if user_data_coach:
                emails.append(user_data_coach.email)
        return emails

    def is_coached_by(self, user_data_coach):
        return user_data_coach.key_email in self.coaches or user_data_coach.key_email.lower() in self.coaches

    def is_coworker_of(self, user_data_coworker):
        return user_data_coworker.key_email in self.coworkers

    def is_coached_by_coworker_of_coach(self, user_data_coach):
        for coworker_email in user_data_coach.coworkers:
            if coworker_email in self.coaches:
                return True
        return False

    def is_administrator(self):
        # Only works for currently logged in user. Make sure there
        # is both a current user data and current user is an admin.
        user_data = UserData.current()
        return user_data and users.is_current_user_admin()

    def is_visible_to(self, user_data):
        return self.is_coached_by(user_data) or self.is_coached_by_coworker_of_coach(user_data) or user_data.developer or user_data.is_administrator()

    def are_students_visible_to(self, user_data):
        return self.is_coworker_of(user_data) or user_data.developer or user_data.is_administrator()

    def record_activity(self, dt_activity):

        # Make sure last_activity and start_consecutive_activity_date have values
        self.last_activity = self.last_activity or dt_activity
        self.start_consecutive_activity_date = self.start_consecutive_activity_date or dt_activity

        if dt_activity > self.last_activity:

            # If it has been over 36 hours since we last saw this user, restart the consecutive activity streak.
            #
            # We allow for a lenient 36 hours in order to offer kinder timezone interpretation.
            # See http://meta.stackoverflow.com/questions/55483/proposed-consecutive-days-badge-tracking-change
            if util.hours_between(self.last_activity, dt_activity) >= 36:
                self.start_consecutive_activity_date = dt_activity

            self.last_activity = dt_activity

    def current_consecutive_activity_days(self):
        if not self.last_activity or not self.start_consecutive_activity_date:
            return 0

        dt_now = datetime.datetime.now()

        # If it has been over 36 hours since last activity, bail.
        if util.hours_between(self.last_activity, dt_now) >= 36:
            return 0

        return (self.last_activity - self.start_consecutive_activity_date).days

    def add_points(self, points):
        if self.points == None:
            self.points = 0

        if not hasattr(self, "_original_points"):
            self._original_points = self.points

        if (self.points % 2500) > ((self.points+points) % 2500): #Check if we crossed an interval of 2500 points
            util_notify.update(self,None,True)
        self.points += points

    def original_points(self):
        if hasattr(self, "_original_points"):
            return self._original_points
        return 0

    def get_videos_completed(self):
        if self.videos_completed < 0:
            self.videos_completed = UserVideo.count_completed_for_user_data(self)
            self.put()
        return self.videos_completed

    def feemodels_ck_notification_count(self):
        if self.count_feemodels_ck_notification == -1:
            self.count_feemodels_ck_notification = models_discussion.Feemodels.ckNotification.gql("WHERE user = :1", self.user).count()
            self.put()
        return self.count_feemodels_ck_notification

